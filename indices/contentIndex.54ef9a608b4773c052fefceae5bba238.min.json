{"/":{"title":"Harry dB notes","content":"\n# Topics\n## FM radio\n\n- [[20220301 fm - Loop the loop.md]]\n- [[20220319 fm -  We have a lock.md]]\n- [[20220322 - Look at that Bode.md]]\n- [[20220428 FM v2 bringup.md]]\n- [[20220529 positive phaseshift.md]]\n- [[20220617 XOR.md]]\n- [[20220701 Inductance measurements.md]]\n- [[20220710 Reference loop filter.md]]\n- [[20220711 Diff amp FET Follower.md]]\n- [[20220809 NAND is better than XOR.md]]\n\n## Blindar\n- [[20220816 Blindar.md]]\n- [[20220902_blindar_cancellation.md]]\n- [[20220918 I2S woes.md]]\n- [[20220923 blindar prototype notes.md]]\n- [[20221009 Lidar+imu.md]]\n\n## Misc\n- [[20220412 Advantech debugging.md]]\n- [[20220421 Cross polarized microscopy.md]]\n- [[20220825 microwave tesla coil.md]]\n- [[20220310 Fox hunt notes.md]]\n- [[20220402 mouse measurements.md]]\n\n## Full autogenerated list:\n\n- [[20240701 Fluxgate magnetometer.md]]\n- [[20240618 Impedance network simulation.md]]\n- [[20240529 Metal detection.md]]\n- [[20240522 Plasma toroid 4 decoupling.md]]\n- [[20240424 Plasma toroid 3 Aluminium.md]]\n- [[20240423 thoughts on laser comms..md]]\n- [[20240406 Thoughts about printing..md]]\n- [[20240321 Agilent 6675A.md]]\n- [[20240306 plasma toroid 2.md]]\n- [[20240208 plasma toroid.md]]\n- [[20231209 More Vesuvius challenge.md]]\n- [[20231202 Advanced motherboard debugging.md]]\n- [[20231124 dead IR camera.md]]\n- [[20231101 Vesuvius challenge.md]]\n- [[20231022 Neural nets memory notes.md]]\n- [[20231022 faster filament extruder..md]]\n- [[20231003 Drone PID tuning.md]]\n- [[20230928 Communicating structural parts for Bambu lab.md]]\n- [[20230920 Communicating structural parts for Bambu lab.md]]\n- [[20230917 Thrust stand again.md]]\n- [[20230917 Neato D3 lidar teardown.md]]\n- [[20230914 Printified and plasticised drone.md]]\n- [[20230909 Drone wire size.md]]\n- [[20230903 Drone up and flying.md]]\n- [[20230815 New instrument new results.md]]\n- [[20230715 BetaPut.md]]\n- [[20230703 Simulation naval gazing intermission.md]]\n- [[20230701 DIY fluids.md]]\n- [[20230616 Learning to simulate.md]]\n- [[20230610 N body again.md]]\n- [[20230610 inv x squared a deep dive.md]]\n- [[20230608 Learning rate.md]]\n- [[20230604 Simulate trivialities.md]]\n- [[20230604 N body particulars.md]]\n- [[20230507 Simulation.md]]\n- [[20230408 Drone FW garbage.md]]\n- [[20230403 Laser googles.md]]\n- [[20230325 Thrust stand.md]]\n- [[20230320 Glucose meter review.md]]\n- [[20230319 wakeuplight v3.md]]\n- [[20230311 Astable multivibrator.md]]\n- [[20230305 verilog knob.md]]\n- [[20230216 strobe camera.md]]\n- [[20230204 x ray spectroscopy.md]]\n- [[20230129 DIY resin printer  PCB.md]]\n- [[20230129 Bang1 bringup.md]]\n- [[20230122 Pneumatic resin valves.md]]\n- [[20230118 Bird call identification.md]]\n- [[20230115 FMV4 bringup.md]]\n- [[20230115 attenuator.md]]\n- [[20221126 DC-26GHz Attenuator.md]]\n- [[20221103 915MHz brrr.md]]\n- [[20221025 antenna tuning.md]]\n- [[20221015 FM V3 bringup.md]]\n- [[20221009 Lidar+imu.md]]\n- [[20220923 blindar prototype notes.md]]\n- [[20220918 I2S woes.md]]\n- [[20220825 microwave tesla coil.md]]\n- [[20220816 Blindar.md]]\n- [[20220809 NAND is better than XOR.md]]\n- [[20220711 Diff amp FET Follower.md]]\n- [[20220710 Reference loop filter.md]]\n- [[20220701 Inductance measurements.md]]\n- [[20220617 XOR.md]]\n- [[20220529 positive phaseshift.md]]\n- [[20220428 FM v2 bringup.md]]\n- [[20220421 Cross polarized microscopy.md]]\n- [[20220412 Advantech debugging.md]]\n- [[20220402 mouse measurements.md]]\n- [[20220322 - Look at that Bode.md]]\n- [[20220319 fm -  We have a lock.md]]\n- [[20220310 Fox hunt notes.md]]\n- [[20220301 fm - Loop the loop.md]]\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/20220115-FM-V4-bringup":{"title":"","content":"Board is back. This time I got the JLCPCB assembly service for the vast majority of the parts.\nThe boards look like this:\n![[Pasted image 20230115182827.png]]\nThe oscillator starts up fine with no modifications (thank goodness). This board includes the 915MHz upconversion \nIn order not to cook the spectrum analyzer I am going to use the attenuator from [[20230115 attenuator]].\n\nas well as a general 915MHz amplifier. Let's try to get the amplifier working first.\n\n# The amplifier","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220301-fm-Loop-the-loop":{"title":"","content":"\n### Measuring frequency response\n2k resistor on the output of the phase detecor and it's associated frequency response. the 2k resistor more or less removed the phase shift from before\n\nThis is with no inverter, loop closed.\nLooks like the frequency response of the VCO isn't really good enough here.\n\n\n![[Pasted image 20220301194118.png]]\n\n\n\nhere is a scope trace of when the loop is closed with a switch. You can see that the applied volts initially goes crazy and the vco can't keep up:\n\n\n![[Pasted image 20220301202336.png]]\n\n\n\n### \"Designing\" a loop filter\nI think maybe one of the problems is just not enough bandwidth in the loop. Perhaps you need way more gain and bandwidth than you think, like an op amp. Tried to do a brick wall filter at 1MHz using the online filter tool:\n\n\n![[Pasted image 20220306204049.png]]\n\n\nBut to get reasonable inductance values I needed to set the impedance to 1R. \nThis resulted in a 3dB bandwidth of like 20kHz when using a 50R output impedance on the AWG. Wonder why that is.... Perhaps using the large discrete inductors is warranted.\n\nAdjusting for a 50R input and output impedance results in some still-plausible inductance values:\n\n![[Pasted image 20220307205624.png]]\n\nAn LT spice simulation with actual component values seemed to think that things would also be OK:\n\n![[Pasted image 20220307205715.png]]\n\n\n![[Pasted image 20220307205729.png]]\n\n\n[[Draft1.asc]]\n...and the oscilloscope seems to agree!\nI think this is the best plausible loop filter I can make right now, and I would hope is good enough.\nPic of the filter:\n\n![[Pasted image 20220322191914.png]]\n\n\n# Thoughts on loop filter required bandwidth:\n## Group delay aka latency aka the devil\nLet's say that the max difference in freq we want to deal with is 1MHz, and the output of the phase detector is 100mV.\nSo the sin wave phase signal inverts itself every quarter wave, or 1/1Mhz * 1/4 = 250us. We want to be _comfortably_ within that range (10%?) so let's says that the group delay of the filter needs to be below 25us over the bandwidth we are interested in, otherwise the control voltage that's supposed to be correcting the phase back to zero won't arrive in time and the phase will have inverted by then:\n\n![[Pasted image 20220307210531.png]]\n\nAccording to LT spice the 4th order elliptical filter has a flat 0.4us group delay all the way out to 500KHz.\n#TODO: measure the group delay of the circuit.\n## Bandwidth\nThis one is easy. We should just have a 3dB bandwidth that's high enough. According to LT spice this one is good out to like a MHz but a quick scope measurement with the AWG seems to say that 500KHz is closer to the mark. This should still be good enough.\n\nI think we might need more gain though. If you think about it if the maximum control voltage needs to be applied in order to correct the phase, then _a phase shift of 180deg_ needs to be applied to correct the phase, since the correction comes from the error itself. Put like that, a pissant 100mV output from the IF aint gonna cut it. We're gonna need a proper amplifier!\n### AC coupling\nThe LO and the RF signal are not going to be perfectly matched in frequency. So some constant DC offset is going to have to be provide to the VCO to make it match frequencies. That means all of the loop filters etc etc need to be _dc coupled_ which they haven't been so far (silly me). The art of electronics suggests using a differential amplifier as a DC coupled alternative to the common-emmitter amplifier.\n### Gain\nI should measure how many MHz/V the VCO is and then calculate the required gain of the amplifier so that only a phase error of say 1/100 of a wavelength is required in order to generate enough voltage to correct the signal.\nSo if the VCO is 1MHz/v (not too far off) and the IF output is 100mV, and then we want the full scale output voltage of the phase detector to be pretty big, prolly like 10V.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220310-Fox-hunt-notes":{"title":"","content":"# Model\nPower received by the antenna is proportional to the inverse square of the distance obviously. A little bit of maths later:\n\n![[Pasted image 20220310201423.png]]\n\nAnd we can see that if you make an observation of power P at a location of [x, y] then it's pretty easy to solve for the location of the transmitter [x0, y0] in a least squares fashion.\n# Radio\n\npython is a PITA as usual. Initial power spectrum using python of a radio station found with the cubesdr software:\n\n![[Pasted image 20220310195408.png]]\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220319-fm-We-have-a-lock":{"title":"","content":"## Loop gain\nAfter deciding last time that the loop of the VCO needed to be DC couples to support a mismatch in the frequencies of the RF and LO signals the art of electronics delivered with this as a good amplifier topology :![[differential.asc]]\n\n![[Pasted image 20220319125545.png]]\n\nwhich is just a fully differential amplifier with one end grounded. Hopefully the negative rail can be removed in the future, perhaps by floating the mixer since the two inputs to the mixer can obviously be AC coupled.\n\nThe above resistor values didn't seem to work so I put in a pot for R1 and R8 in the above LT spice file. The board looks like this atm:\n\n![[Pasted image 20220319130005.png]]\n\n\nAnd now the loop filter has a lock!\n\n![[Pasted image 20220319130134.png]]\n\nChannel 1: VCO\nChannel 2: \"Transmit\"\nChannel 3: output of PLL control loop\nChannel 4: AWG of the scope modulating the VCO\nIt only works modulating by up to ~200mV on the transmit side, after that the PLL seems to lose its lock:\n\n![[Pasted image 20220319130337.png]]\n\nThe chances are that this is due to some combination of not enough gain or not enough bandwidth on the part of the differential amplifier. I was able to improve things a bunch by twiddling the two potentiometer knobs of R_e and R_c and given that this is a 2D search space it seems unlikely that I've hit a local minimum. Nonetheless I think the next step is find out what the actual values are, pop them back into LT spice and try and get some more modulation bandwidth.\nMore modulation bandwidth is good for two reasons - it uses more bandwidth in the air (better SNR) and also it means that the VCO control voltage needs to be higher, perhaps enough even to mean that no post amp is needed.\n\nAside: I hit the diff amp with the hot air gun when it was marginally unstable and it didn't seem to do much, so that's points towards thermal stability I guess.\n\n### Phase margin measurement\nOr at least I think this is phase margin. We seem to be running out of it, in any case.\nHere is the raw data collected on the scope:\n\n![[Pasted image 20220319134157.png]]\n\nThis is right on the edge of stability. note the little blip at the bottom where the PLL is beginning to lose its lock.\nPulling the data down from the scope, we measure the phase of the signal directly to look like this:\n\n![[Pasted image 20220319134739.png]]\n\nTaking at close look at the best and worst portions (in red above):\n\nMinimum phase (~-120deg) | maximum phase (~50deg)\n:-----------------------:|:--------------------------:\n![[Pasted image 20220319134947.png\\|400]]  |  ![[Pasted image 20220319135054.png\\|400]]\n...Obviously the absolute values aren't so crash hot here but directionally this seems to be correct: The reason the PLL loses lock is because there is too much phase shift. Pre-registered hypothesis: this is because when messing about with the pot I destroyed the bandwidth.\n\n### Loop gain optimisation:\nState as of the above pics:\nEmmitter resistor: 3.4k\nCollector resistor: 3.4k\nInteresting! I had no Idea at the time that I was optimising them I had converged on equal values, wonder why that is.\nThe \"transmit\" VCO is at 1.4V and the PLL VCO is at 2.9V. Odd that the control voltages need to be that different, though it is quite possible that the circuits are a bit different.\nIt's possible that since the two varactor diodes are in such different regions of their capactiance(voltage) functions this is what's generating the mismatch.\nhttps://www.nxp.com/docs/en/data-sheet/BB201.pdf\n\n![[Pasted image 20220319132005.png]]\n\nMaybe there's something about the difference in the slopes of these two graphs or somesuch, idk.\n#### But wait, nothing works\nActually it seems that the above stuff may have happened when one of the connections on the circuit was broken. \nHere is the circuit attempting to do feedback with the circuit \"operating as intended\":\n\n![[Pasted image 20220319174103.png]]\n\n(note the vertical scale)\nHere Ch4 is the mixer phase difference and CH3 is the control voltage of the PLL. I think somehow a 80deg phase shift has been introduced here.\nThe behaviour of this circuit is that as you adjust the emitter resistor of the differential amp to adjust the DC setpoint of the output (and thus the PLL center frequency) you can tell that the control loop is kinda squishing up against its limits until it \"pops\" out the other side. idk if this diagram helps explain:\n\n![[Pasted image 20220319173922.png]]\n\n(Re is independant variable, PLL is dependant variable)\nThis mercury-under-your-thumb behaviour occurs when the output of the differential amplifier is taken from the positive or negative end of the scale which I feel is a big clue but am not sure what it means.\n\n### Observations and thoughts on required bandwidth\nAside from the possibility that everything is hooked up backwards it seems that something is clearly acting out of phase here - positive feedback is being created. The frequency response of the VCO seems do be dominated by the RC of the 100k resistor and the 50pF of the varactor diode, so I changed that to be 10k to spice things up.\nIt spiced them up alright, but not in a good way. \n\n![[Pasted image 20220320084921.png]]\n\n(Green is the VCO frequency sorry)\nSo what is happening here is the phase signal (Blue) feeds into the Loop filter (orange) which then affects the PLL frequency (green). At these frequencies (300kHz difference) there is clearly quite a bit of lag happening.\nThe phase as measured by the mixer vs digitally seems not to show much latency per se, although there are definitely discrepancies:\n\n![[Pasted image 20220320091157.png]]\n\nI think those are mostly due to the method of calculating the phase though , which assumes a constant frequency.\n\nSo the next step is to slow stuff down so that the VCO has enough time to react to the output of the loop filter. Perhaps just increasing the resistor that feeds the varactor diode would be enough to do that:\n\n![[Pasted image 20220320091614.png]]\n\nLet's try 10MOhm! That should give `1 / (2*pi*10e6*50e-12) = 318Hz(!!)` of bandwidth.\nHere's what that looks like:\n\n![[Pasted image 20220320093000.png]]\n\nI had to filter the RF output but I think the result is correct.\nSo essentially what is happening here is that the VCO is basically seeing the average voltage at the output of the loop filter at all times. If the average voltage tends not to reduce the frequency error, then things will just stay as they are. \nI guess that's not what we want to change here, then.\nThe latencies that exist in the system are:\n1.  Applied volts -\u003e VCO frequency\n2. VCO frequency -\u003e Phase measurement\n3. Phase measurement -\u003e Applied volts\nSo if these latencies add up to greater than the difference in frequency of the modulated and PLL signal, things will be wack.\n\n### Quick weirdo observation\nThis is with a 10meg resistor feeding the varactor diode and a ramp wave being fed into the RF input. weird. I think this arises because the signals have a tendency to injection lock anyway, and this is just a special case of that where they remain injection locked but at different relative phases depending on if the frequency is ramping up or down.\n\n![[Pasted image 20220320101534.png]]\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220322-Look-at-that-Bode":{"title":"","content":"So it turns out that my oscilloscope has a Bode diagram feature, and that all oscolloscopes these days do too. Who knew?\n\n### Passive filter\n\n^34b78a\n\nHere is the passive loop filter that's supposed to get rid of all the wacko harmonics around 10MHz:\n\n\n![[Pasted image 20220322191937.png]]\n\n\nTake a look here [[20220301 fm - Loop the loop#Designing a loop filter]] for the actual construction. I imagine the \"gain\" in this filter comes from how things aren't remotely 50R, and so the absolute level here isn't really right. The flatness of the phase should be, though.\n### Active filter\nAdding in the differential amplifier here: [[20220319 fm -  We have a lock#Loop gain]] and the response looks like this:\n\n\n![[Pasted image 20220322192537.png]]\n\n\nmeasurement looks a bit cooked at the higher frequencies there. Considering I wanted to do at least 100KHz of FM swing here we probably need to increase the bandwidth. ^a3250d\n\n### VCO bandwidth\nWe can't really do a frequency sweep of the VCO in quite the same way, but we can do a step response:\n\n\n![[Pasted image 20220322205427.png]]\n\n\nSo the 90-10 fall time here is 0.35 / (0.5483 - 0.5012) = 7.4KHz - Not really that great! Prolly should have measured this some time ago. That was with the 50k resistor talked about here [[20220319 fm -  We have a lock#Observations and thoughts on required bandwidth]].\nChanging that to 10.7k Gives this:\n\n\n![[Pasted image 20220322211254.png]]\n\n\nwhich is 0.35 / (0.5055 - 0.500) = 63KHz:  Better!\nAlthough there is a weird frequency ramp on top of that which is a bit worrying. But you gotta pick your battles.\nNow I think what we want to do is have a lowpass that's significantly below that - say 20KHz and apply that to the output of the IF. That way the VCO is guaranteed to be a lot faster than the loop filter. \n\n### Slow down the right thing\nAdding a 2.2nF cap in the diff amp to slow things down gets us this waveform:\n\n\n![[Pasted image 20220322215357.png]]\n\n\nSo close!\nIt looks like the PLL can't keep up for some reason and looses the lock. Blue and green are on the same volts/div, although blue is AC coupled. \nAdjusting thing slightly we can see that when the PLL loses the lock the error signal is around 50KHz:\n\n\n![[Pasted image 20220324080557.png]]\n\n\nThe PLL can lock on fine if the total deviation is below this:\n\n\n![[Pasted image 20220324080650.png]]\n\n\n\n### VCO is not reversible\nThe reason for this seems to be that the bandwidth required of the VCO is not the same on the transmit and on the receive.\nIf we imagine that the PLL changes frequency in about 1ms and has a 1MHz/V transfer function then that means that in response to a 1V step input it will change the output frequency by a MHz.\nThe 1MHz error signal is then produced by the mixer and in order for the PLL on the receive side to lock on _The PLL has to respond within 1/1MHz = 1us!_ So basically the VCO bandwidth has to be equal to `max signal frequency * spreading factor`. \n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220402-mouse-measurements":{"title":"","content":"# Problem\nCurrently experiments have no good way of measuring mouse health over time so they use weight as a heuristic. Mice are manually measured every day. This is clearly dumb and a bit of maths + some scales should be able to overcome this.\n\n# Idea\nMice live in a small plastic cage. Suspend the cage via three force transducers and monitor those constantly. With one mouse it's trivial to measure the weight over the time. Measuring the weight of 3+ mice over time is an underdermined problem, but is most likely possible if you attempt to estimate the positions of the mice as well and have some model of the mices movement (they are unlikely to teleport).\n\n![[Pasted image 20220402090659.png]]\n\nThis would still run into problems of unique identification of mice since two mice could weigh the same as each other and then climb on top of each other at some point.\nRFID tags is the obvious way to solve this problem, but there could be others that I haven't thought of yet, like an incredibly precise scale that is able to measure the weight of a mice to such a level that they never have the same weight.\nOne other thing that will need consideration is that the measurement of the weight is going to be _very_ noisy - if you have like 100Hz bandwidth then stuff like footsteps, standing up etc will be tricky to deal with I think.\n\n# Maths\n## One mouse, one dimension:\nStep 0: one mouse in 1D with two transducers:\n\n![[Pasted image 20220402091407.png]]\n\nI've put the origin in the middle here cause we are about to take the sum of the moments and idk what to do about that when the distance is 0 there.\nEqn 1: $$F_1 + F_2 = m$$\n$$ \\sum Moments = 0$$\nWhich leads to:\n$$ F_2 \\frac{L}{2} - F_2\\frac{L}{2} - xm = 0$$\nBlah blah blah I'm sure you can reduce this to an exact solution. Two equations and two unknowns and all that.\n## One mouse, two dimensions\nHere is the sich from the top down:\n\n![[Pasted image 20220402092007.png]]\n\nSo as before, we have:\n$$F_0 + F_1 + F_2 = M_0$$\n(duh). But now the moments get a bit more tricky. Let's do some vector notation so $\\vec{F} = [F_0, F_1, F_2]$ etc.\nThe same moment thing applies, but now in both the x and y directions:\n$$ \\vec{M}_F \\cdot \\vec{M}_x = \\vec{F}_F \\cdot \\vec{F}_x$$\n$$ \\vec{M}_F \\cdot \\vec{M}_y = \\vec{F}_F \\cdot \\vec{F}_y$$\nWhere it's important to remember that the mouse vector $\\vec{M}$ and the measurement vector $\\vec{F}$ are two different lengths, with the mouse vector probably being longer.\n$\\vec{F}_F$ is what we measure over time, $\\vec{F}_{xy}$ is the known position of the force transducers, and $\\vec{M}_{Fxy}$ is what we are trying to estimate.\nNow the measurements are going to be made multiple times per second and I think that a reasonable extra constraint to add when solving is to minimise the difference in position of the mice measured at time $t$ and $t + 1$ . \nSurely there is some off the shelf optimisation package (is this a 'convex optimisation' problem?) that can help with this but it might be easier to just diy it iteratively. Two weeks of experiments measured at 80Hz is $2*7*24*60*60*80 = 100e6$ measurements. Probably a bunch of filtering can reduce that by 10x but it isn't really that many numbers so if it can be done in a couple of lines of numpy instead it probably should be.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220412-Advantech-debugging":{"title":"","content":"# What it looks like\n\n  |  \n:-----------------------:|:--------------------------:\n\n![[Pasted image 20220412210459.png\\|400]]  |  ![[Pasted image 20220412210630.png\\|400]]\n...Obviously the absolute values aren't so crash hot here but directionally this seems to be \n\n# Debugging the power supply\n\n![[Pasted image 20220412210731.png]]\n\n### The culprit:\n\n![[Pasted image 20220412210239.png]]\n\nAn 8.2R resistor went pop:\n\n![[Pasted image 20220412210803.png]]\n\nAfter replacing that with some regular through hole resistors that shorted on the other side accidentally, another resistor went pop:\n\n  |  \n:-----------------------:|:--------------------------:\n\n![[Pasted image 20220415174018.png\\|400]]  |  ![[Pasted image 20220415174159.png\\|400]]\n\n## Debugging things that need to be redone:\n- ~~Removed 100R resistor R14~~\n- Removed one of the transformer windings.\n- remove 0.2R resistor in the corner, R15\n\n## Components of note:\n- Replaced 8.2, 10R 5W resistor\n- 2SK1217 transistor\n- JZ1AF-12V-TV relay\n\n## Catching up\nIt is now  20221126  and so I am trying to piece together  why  I did what I did. I have a variac now so I  think the strategy  is to plug stuff in and then find out  where it's shorted without the spectacular explosion and arcing of prior efforts.\nI have here a STR-83145,  I don't know  why I desoldered it.\n\nI also noticed that the resistance between VCC and GND of the M51995P:\n![[Pasted image 20221127203516.png]]\nswitcching controller was low, and so I powered it up with   20V. This caused a lot of current draw (300mA, 5V) and so I conclude it's most likely busted. I'll pull it off and power it up isolated to be sure though.\nAmazingly when pulled off the board the chip seems fine! there's no switching or anything, but the FB pin is at the right voltage and there's no short to ground or anything. There's no short on the pcb side either, which begs the question of how this fault came about. I think I will poke about more and find out.\nThe datasheet for the M51995P has a reference schematic that looks quite a lot like the power supply I am investigating:\n![[Pasted image 20221127172609.png]]\nIn particular I  think  the bajillion transformer windings are relevant. \n\n## eeproms from the internets\nGreat webpage with the manuals:\nhttp://ftb.ko4bb.com/getsimple/index.php?id=manuals\u0026dir=Advantest\n\n![[Advantest_R3271P_Spectrum_Analyzer_EPROM_G05.zip]]\n![[Advantest_R3271_Spectrum_Analyzer_EPROM_B01-R3271.zip]]\n\n## Sunk cost\nThis power supply is wayy to complicated. I clearly need to sit down and absolutely nail down the whole schematic at this point if I want to make progress, and I don't want to do that. Fortunately the manual specifies the pinout of the power supply:\n![[Pasted image 20221127210613.png]]\nAnd so all I need to do is supply all these voltages. I think I can scrape together enough power rails to get this thing to work.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220421-Cross-polarized-microscopy":{"title":"","content":"# The microscope\n  |  \n:-----------------------:|:--------------------------:\n\n![[Pasted image 20220421205438.png\\|400]]  |  ![[Pasted image 20220421205527.png\\|400]]\n\n## Stresses in plastic\nzip loc bag corner:\n\n![[Pasted image 20220421205614.png]]\n\nEdge of the bag:\n\n![[Pasted image 20220421205636.png]]\n\n\n## Contrast example\n  |  \n:-----------------------:|:--------------------------:\n\n![[Pasted image 20220421205438.png\\|400]]  |  ![[Pasted image 20220421205527.png\\|400]]\n\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220428-FM-v2-bringup":{"title":"","content":"# Board\nPopulated most of the things:\n\n![[Pasted image 20220428184452.png]]\n\nMight be a bit inconvenient to probe.\nOutput does not oscillate, of course.\n\n## Debugging\nRelevant section of the schematic:\n\n![[Pasted image 20220428184557.png]]\n\nFirst things first: check the bias on the transistor.\nI think R13 is way too low by the way. after desoldering the working oscillator it's 131R\n### Initial observations\nQ1 Vg = 1.131, Vs=1.396 =\u003e Vgs = -0.265\nSo according to datasheet:\n\n![[Pasted image 20220428185644.png]]\n\nThe current should be around 25mA. R3 is 100R and I measured 1.382V =\u003e 13mA. Seems quite low!\nThe quiescent current of the JFET seems roughly similar to the working set so I think it's most likely the C4/C5 values that are off, and I don't know what the right ones are. Time to use the VNA!\n## What's that capacitor:\nTest setup 1: using the above PCB to easily connect components to the VNA over a UFL connector:\n\n![[Pasted image 20220501141447.png]]\n\n- 56pF is measured at about 61pF\n- The cable by itself (even after calibrating) seems to be about 3.4pF. Maybe I need to have a more stable test setup.\n- 9.1pF is measured ass 13.6pF. subtracting, that's 10.4pF. Aliexpress \"tolerance\" is 5% so that may well be right\n- C2 on the above schematic was measured at 105pF\n- Adding some flux changed the open circuit capacitance to 3.7pF\n- C4 on the above schematic (soldered as two in ||) was 325pF\nNow to resolder the above values to the new pcb!\nThis gets the oscillator running just fine.\nNote: decreasing R13 to 65R stops the oscillation.\n\n## First mixing\nHere is an image of the phase output, and then the output of the diff amp that amplifies that phase:\n\n![[Pasted image 20220501213136.png]]\n\n\n![[Pasted image 20220501213302.png]]\n\nAll of this is looking pretty spiffy so far.\n\n## Measurements of inductor\nThe big coil inductor works but the small 0603 inductor does not. Why?\n\nI *think* that this measures the inductance:\n\n![[Pasted image 20220507133257.png]]\n\nIncomprehensible chart:\n\n![[Pasted image 20220507133317.png]]\n\nIt's unsurprising that the small inductor works better at higher frequencies, but it's a bit surpriing that it works that well. Both inductors measure about 10uH at 50kHz.\nHere's what it looks like at 50kHz-900MHz:\n\t![[Pasted image 20220507134632.png]]\n\n\tAllegedly the small inductor (L0603B100KDWFT) is also wire wound so I would have thought it would have the same overall shape as the larger inductor. \n## Things stop working\nThe first new asembled board stopped working for some reason. 2.124V across the drain resistor of 100R =\u003e 21mA VDSS. Datasheet says it should be 35mA but there are some resistors in the way. The transitor on the working one is 2.181V, so clearly transistor isn't busted. Things started working again. I think it's cause if the VCO is not at a defined voltage then things get wack.\n### Response time of VCO:\n\n^eed27d\n\nMax F dev: 6.05e5. Min: 2.8e4. =\u003e 90% = 5.47e5. 10% = 8.5e4\nt_90: 1.493ms, t_10 = 1.544ms. =\u003e Bandwidth = 0.35/(1.544e-3 - 1.493e-3) = 6.8KHz. This would seem rather too low. That's with a 50k. Resistor. Should go back to 10.7kOhm \n10.7kOhm leads to 68kHz bandwidth:\n\n![[Pasted image 20220508104443.png]]\n\n### Slowing things down (dumb version)\nAs per before we now need to slow down the response of the loop filter to be slower than that of the VCO. I did this like so:\n\n![[Pasted image 20220508133147.png]]\n\nSo that should be 30kHz bandwidth.\n\n### Bandwidth of loop filter\nHere is the bandwidth of the loop filter after adding the 30kHz mod:\n\n![[Pasted image 20220510211453.png]]\n\nHit the nail on the head there. You can also see that the diff amp has oodles of gain.\nBut wait!\nThis is the bandwidth of just the passive component of the loop filter\n\n![[Pasted image 20220510195950.png]]\n\nThat's a bit surprising. This completely passive filter has a gain of 13dB? Time to collect my nobel prize for violating thermodynamics.\n\n![[Pasted image 20220510200352.png]]\n\n...Yep. Now that's what I call resonance! Take note of the y scale.\n\nThis is the diff amp by itself:\n\n![[Pasted image 20220510201412.png]]\n\n...I feel like it should have more bandwidth than this. LT spice agrees and says it should be 1MHz. Probing around does not reveal anything noteworthy. It might be worth doing a common emitter amplifier configuration just to check against the spice model.\n\nAlthough the \"3dB\" point of this system is 30Khz, it still has 20+dB of gain at 60kHz. So to get \u003c\u003c0dB of gain at 60khz I think moving the elliptical loop filter to a much lower bandwidth is in order.\nThe filter tool says this:\n\n![[Pasted image 20220510211848.png]]\n\n\n![[Pasted image 20220510211857.png]]\n\n(adjusted the impedance to get 1mH inductor value.)\nThat did not seem to be good enough. This works better:\n\n![[Pasted image 20220512185819.png]]\n\n\n![[Pasted image 20220512185924.png]]\n\nWhere C3 is the passive filter + diff amp and C1 is just the passive filter.\nThe output crosses 0dB gain at about 30kHz and is at ~-10dB at 60kHz so hopefully this will be good enough. If this doesn't work then reducing the rather large gain of the diff amp would be a good next step.\n\n...This produces utter trash:\n\n![[Pasted image 20220512202614.png]]\n\nIn the above trace Channel 2 is the phase output as a result of sending in a 17mVpp ramp wave in. Changing the offset by 10mV is enough to render the signal borderline unusable and so I take it from that that the control output would also be like 10mV.\nSo I think increasing the bandwidth of the loop filter a whole bunch and going back to a lower gain amp is the way to go.\n\n## Quick note: phantom lock\nWe have a lock:\n\n![[Pasted image 20220515210602.png]]\n\nSituation: control loop switch is _open_.\nChannel 1 and two are the RF and LO signal respectively. CH3 is the VCO voltage, about 7.5V. CH4 is VCC (7.97V)\nV_lo = 1.395V, V_\nThe circuit is like this:\n\n![[Pasted image 20220515210934.png]]\n\nIt's clearly coupling in through the air somehow, waving a screwdriver around nearby can make it lose the lock. I think the key takeaway here is that the required voltage to lock (7.5Vish) is _way_ higher than makes sense at first glance, it should be like 2V. I suppose given the fact that the control loop is open the actual DC voltage is not important, it's how it affects whatever dynamic nonsense is being used to close the loop through the aether.\n####\n- Disconnecting the output of the diff amp completely still allows the PLL to lock. \n- After doing the above the switch (that is connected to the varactor diode but not the output of the diff amp) still prevents the circuit from locking when the switch is closed. This is weak evidence for that long trace running across the board acting as an antenna.\n- Desoldering the resistor that attaches to the VCO has no effect, it can still lock. I now presume that the locking is occuring through the mixer somehow. It only happens over a tiny (10's of mV MAX) voltage range as you would expect.\n\n### Quick note: phase shift\nHere is the output of the loop filter with a nice big capacitor and resitor for lowpassing. As you can see this has apalling phase performance. So I think going to the example filter in \"Introduction to radiofrequency design\" is a good idea as a sanity check.\n\n![[Pasted image 20220516220123.png]]\n\n\nNote that the filter in the textbook is designed assuming a 1000x divider on the output of the VCO before it goes into the mixer.\n\n![[Pasted image 20220516220240.png]]\n\n\nThe circuit has been built:\n\n![[Pasted image 20220528143515.png]]\n\nNote that a 10Meg resistor was added across the cap for the required DC path, and a 100R resistsor was added as an output load in an attempt to stabilise the DC output point of the amplifier, which varies by many V depending on cable positioning etc.\n\n\n![[Pasted image 20220528143247.png]]\n\n\n![[Pasted image 20220528143200.png]]\n\nThe red shaded area above is due to the 10 Meg resistor.\nHere is the bode plot:\n\n![[Pasted image 20220528143348.png]]\n\nLooks vaguely the same, exept that the phase shift component from the 10Meg resistor is missing. Suspicious...\nI'm also a bit worried that the phase shift goes up by a fair bit before the amplifier crosses zero gain.\nThe textbook says it should look like this (I think):\n\n![[Pasted image 20220528143628.png]]\n\nThe main troubling thing here is that the phase shift in the book is 180deg (negative feedback) but the sims and real life show 90 degrees. What gives?\n\n### Results\nNeedless to say, this does not work. It seems to get into the state where the F(VCO) \u003e F(RF), and then you can adjust the RF frequency up and down with the VCO frequency sitting at some extra frequency above that, say +300kHz. I really think this must have something to do with the phase shift still for some reason. The whole point of this filter was that it was supposed to be out-of-the box working and given the phase shift is wildly different from what the author thinks it should be, it's time to move on I think.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220529-positive-phaseshift":{"title":"","content":"\nThis is a 10kHz sine wave that has a phase shift from output to input of -42 degrees according to LT spice. So a delay is a negative phase shift.\n\n\n![[Pasted image 20220529191020.png]]\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220617-XOR":{"title":"","content":"# XOR gate as phase detector\nMaybe the problem is with the mixer, not any phase response stuff in the loop filter. \nI have wired up the SN74AHC1G86 as a phase detector.\nInitially I was worried about getting enough swing on the output of the VCO's to properly hit the logic levels but this turn out not to be strictly necesary, if you AC couple things into a vcc/2 voltage divider on the inputs then a few hundred mV is enough.\nI did need to turn down the power rail to 5V from 7V for compatibility, but I was gonna do that anyway.\nHere is what it look like with one input being a VCO output and the other coming from the AWG on the scope:\n\n![[Pasted image 20220617115345.png]]\n\nCH1: output of VCO\nCH2: output of AWG\nCH3: output of XOR\nLooks great!\nThe interference from the rising/falling edgess on CH1 seems to be mostly probing related (it's on a 100:1+ divider so as to not interfere with the actual circuit too much)\nNow to lowpass it. I hope that there aren't too many problems here as the nominal 'zero phase' is at vcc/2.\nTaking the loop filter from here: [[20220301 fm - Loop the loop#Designing a loop filter]] once again and making sure to terminate the output of the filter at 50R, we get this:\n\n![[Pasted image 20220617144220.png]]\n\nNoice.\nOnly problem is the measurement of the two input frequencies is super corrupted from the xor edges. I probed the actual inputs though and again this seems to be a probing artefact.\n\n\n### Bad tuning range\nPerhaps as a result of reducing the supply voltage to 5V I notice that one of the VCO's does not want to tune above about 10.5MHz without the amplitude dropping off a whole bunch. Perhaps adding more to C2 to increase the amount of feedback?\n\n![[Pasted image 20220618134226.png]]\n\n...Adding 100pF to C2 stops the oscillation entirely.\n\nscratchpad:\nR13 to 300R. increased DC point, did not increase modulation amplitude\nC4 to 100pF. This increased the modulation to 1.5V\nI notice that probing the output increases the modulation amplitude slightly. Perhaps that means that I've gone too far, and C4 should be increased a bit? It did not. 1.4-\u003e1.13vpp.\nC4 back to 100pF, increasing C2 by 47pF stops modulation entirely.\nNote: impedance of 100pF is 159R at 10MHz. that actually sounds a bit low, so maybe a very small C4 is what's required.\nCHange C4 to 20 or 50 pF results in no oscillation.\n\n### Fiddling with locking\nPerhaps one of the reasons that the thing doesn't lock is that the control output is in the wrong wrange (maybe it's 3-4v output but 2v is needed). Changing R35\n\n![[Pasted image 20220618170951.png]]\n\nto a potentiometer allows the DC point of the output to be adjusted. Swinging over the full range does not result in a lock, but it does result in two interestingly distinct phase oscillations:\n\n![[Pasted image 20220618171224.png]]\n\nand\n\n![[Pasted image 20220618171125.png]]\n\nas a result of wiggling the output up and down.\nTo me this kind of looks like the feedback is the wrong way round and the two modes above are the input signal being above and below the VCO.\nTaking the opposite sign outputut from the diff amp (R26 instead of R25) we get:\n\n![[Pasted image 20220618180819.png]]\n\n...A locked PLL! ta-dah!\nI had assumed previously that it did not matter if positive or negative feedback was taken from the output of the diff amp, as that would jusst change whether the loop locked on the rising or falling edge of the phase detector output. This isn't a conclusive investigation but it seems I was wrong about that.\nThe lock ranges from the state:\n- 900mV, 10.05MHz(ish)\n\n\nWhen the pot that gives the VCO a sensible voltage while the loop is disconnected is itself disconnected, the PLL fails to lock at any frequency and looks like this:\n\n![[Pasted image 20220618180530.png]]\n\nThe persistence view of the scope suggests there is some locking adjacent behaviour going on here.\n\n## Better isolation\nOverall though even though the lock is quite stable itcan still be disrupted with the aerial screwdriver technique. I had removed the buffers on the output o f the oscillators so maybe putting those back in will help. \nThe BCX70K doesn't really have any appreciable gain at 10MHz apparently, so I have switched to the BFR106 which according to LT spice will do just fine.\nThe following circuit also does quite well in practice:\n\n![[Pasted image 20220619175006.png]]\n\n\n![[Pasted image 20220619175100.png]]\n\n(green is the output.)\n\nI did this on both oscillators and although there are now nice large distorted square waves going into the XOR gate, the circuit still has the same screwdriver susceptibility. You can even turn the lock on and off with the right gesture.\nThe circuit also has quite a bit of screwdriver velocity sensitivity also.\nCurrent state of the circuit btw:\n\n![[Pasted image 20220619181407.png]]\n\n\n## Where's that field?\nBeing quite a lot longer than the circuit itself, the screwdriver is a rather nonspecific way of finding the location of this external interference susceptibility. A small magnet does quite a lot better. Couple of observations:\n- The circuit seems to be most sensitive around the actual VCO. When the magnet is moved over that bit (irrespective of the magnets orientation) then the PLL losess the lock.\n- the big inductor changes its inductance a _lot_ in the presence of the magnetic field! the frequency goes from 10-\u003e14MHz!\n- Hot gluing a ~2mm chip of neodymium magnet on the end of a platic spatula reveals that it is definitely the inductor and only the inductor that is susceptible to external interference. The two circuits have two different sized 10uH inductors on them and the smaller one is much more susceptible. Perhaps this is why shielded inductors are a thing...\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220701-Inductance-measurements":{"title":"","content":"Following the revelation previously that the reason that the circuit was sensitive to screwdrivers was the unshielded inductor we need to switch to some unshielded inductors. I have purchased some but they don't work. Time to find out why with the nanoVNA.\n# Inductance measurement principle.\n\n![[Pasted image 20220701084450.png]]\n\nWho knows how smith charts work? Not me, but let's proceed anyway.\nIt's known that real world inductors turn into capacitors at some point which is the point where the inductor crosses the 'x' axis on the smith chart. It'ss probably highly nonideal before it gets there, though.\n\nBig wirewound OG unshielded inductor:\n\n![[Pasted image 20220701182813.png]]\n\nNRH2410T100N (Big SMD):\n\n![[Pasted image 20220701183149.png]]\n\nSWPA3012100MT (Small SMD):\n\n![[Pasted image 20220701183415.png]]\n\nAIML-0603-100K-T (0603 SMD):\n\n![[Pasted image 20220701212232.png]]\n\n\n## Those were the wrong graphs.\n\n^80ed77\n\nAccording to [here](https://robs-blog.net/2020/06/02/using-nanovna-to-measure-inductor-q/) I should have been using the R+JX graph to measure the inductor Q, since inductor Q is defined as X / R.\n\nHere again is the AIML-0603-100K-T:\n\n![[Pasted image 20220701214014.png]]\n\nAt 10MHz it is 19+j743R. =\u003e 39Q\nThe big inductor at that 10MHz is 36.9+j758R =\u003e21Q. There's clearly a much higher spiky bit for the big inductor. I'm not sure why a \n\n### Attach a magnet to the big inductor:\n\n![[Pasted image 20220702120227.png]]\n\nAs mentioned before [[20220617 XOR#Where's that field]] This changes the frequency of the VCO from 10 to 14 MHz.\nThe parameters of the magnetised inductor are:\n\n![[Pasted image 20220702120438.png]]\n\n## Actually everything is fine. \nIt turns out that the AIML-0603-100K-T and the NRH2410T100N actually work fine - the circuit oscillates with both. with about 600mV on the varactor diode they ocsillate at 10 and 12 MHz respectively. That's a bit high, it would be nice if they oscillated starting with a decent amount of control voltage on the varactor diode.\nThe second copy of the circuit does not oscillate though. Once again we have a mismatch... \nTime to go through and find the differences... ...I ended up needing to change the bottom feedback capactor C4 to 100pF and the emitter resistor R16 to 330R.\n\nAfter all that though the circuit is only slightly less susceptible to perturbations with a screwdriver. The PLL won't actually lose its lock. \n\n## We have a lock (again)!\nThis time you can play music through it. Beethoven comes through crystal clear, although there is a bunch of EMI if the music is played from a PC rather than an isolated source like a phone.\nThe maximum modulation depth on the input that can be tolerated is about 180mV:\n\n![[Pasted image 20220702182942.png]]\n\nBut any more than that and it starts to lose its lock:\n\n![[Pasted image 20220702183023.png]]\n\nNot quite sure what the cause of that is. This is a fairly narrow range though. \n\nTaking a zoomed in look at the PLL with the maximum amplitude lockable sine wave:\n\n![[Pasted image 20220702193823.png]]\n\nWe can see that there is a great deal of phase shift between the two outputs. I think that means that we need a lot more (10x?) open loop gain in the loop filter so a smaller error is needed to get our control voltage. Back to the Bode plots! ^3f8215\n\n## Loop filter gain (again)\nCurrently the loop filter is sitting at a rather comfortable 30dB of gain as before:\n\n![[Pasted image 20220702195632.png]]\n\nI would have thought that this would be plenty to get a lock over quite a wide range of voltages - perhaps there is something more going on here, like the lowpassed phase signal being unreasonably small.\n\nDisconnecting the feedback from the PLL the phase looks like this in open loop mode with a small difference in frequencies:\n\n![[Pasted image 20220702201556.png]]\n\nWhere green is the lowpassed input to the diff amp and blue is the output. It looks like the gain is quite low for the positive sections of the green waveform, but quite high for the negative sections.\nThe DC level of the diff amp can be adjusted with a potentiometer in place of R35. \nInterestingly if you adjust it low enough there is a bit of \"reflection\" at the bottom of the waveform where the gain goes positive again:\n\n![[Pasted image 20220702202528.png]]\n\nProbably best to avoid that...\n\nRemembering that this is a _differential_ amplifier, the correct thing to do for adjusting the DC input level is not to adjust where the negative rail is, but to adjust the voltage of the base of the other transistor (Q5):\n\n![[Pasted image 20220703095414.png]]\n\nPutting a potentiometer between VCC and -5V is the obvious way to do this. From LT spice only a _very_ small DC offset creates a very large effect thoough.\n\n![[Pasted image 20220703113926.png]]\n\nVunderbar! Adjusting the base of Q5 to be ~250mV (half of CH4) results in this lovely symmetric square wave. no wonder the PLL had trouble locking before...\n\n## Proper things don't work.\n....And now the PLL won't lock. It exhibits that \"popping\" behavious described before where you can adjust the frequency of the input signal to match that of the VCO and then the VCO jumps to the other side of the input signal :(\n\n![[Pasted image 20220703114444.png]]\n\nLooks like there's some coupling between CH2 and the phase signal. Probing the output of the colpitts oscillator (before the buffer) look like this:\n\n![[Pasted image 20220703114755.png]]\n\nSo there is some definite coupling. Not great.  Perhaps this is just the frequency dependent amplitude of the VCO though.\nRemembering from before that the phase signal seemed to switch from positive to negative gain at some point I switched from the negative output of the diff amp back to the positive. This did not help.\nIt is once again possible to get things to lock with the loop open though. ^39d225\n\nLet's go back to when things worked and take more detailed measurements:\n\n![[Pasted image 20220703181158.png]]\n\nThe above measurements were taken with the loop switch open.\nSwitching back to the diff-amp-works-great-but-pll-doesn't-lock state things look about the same for the various DC levels.\nSince the difference in voltage between the two bases seems to be critical here I put R35 back to a fixed 8k resistor and put a voltage divider pot on Q5 base to adjust the base voltage there. If the parameters [Input frequency, negative supply voltage, Q5 base voltage] are all precisely aligned then the loop locks no problem. Any deviation from that and it won't.\nHere is the input vs output of the diff amp with the above working configuration but in open loop:\n\n![[Pasted image 20220704104242.png]]\n\nAt this point the above parameters are [10.5MHz, -6V, -300mV].\nInvestigating each parameter in more detail: ^4bc1e2\n- Q5Base: \n\t- highly negative voltage like -3V is not a problem.\n\t- From the locked state 170mV will unlock. The top part of this waveform has way higher gain as you would expect.\n\t- From the unlocked state -41mV will lock (there is hysteresis). -41mV looks more or less like the triangle wave above. [[20220701 Inductance measurements#^fccd30]]\n\t- When adjusting Q5Base across the range of good voltages there is no phase shift between the two waves prior to unlocking, it is an abrupt transition.\nThe Q5Base observation shows that the feedback loop just straight up doesn't like a high gain feedback loop. In both the working and nonworking states the feedback is negative, it's just that when Q5base voltage is adjusted to the average phase voltage to get proper gain on the positive and negative phase swing things just refuse to lock. \nI always though that when it came to feedback loops more open loop gain was always a good thing. This seems to be contradicting that.\n\n### Side note: harmonics??\nWith exceedingly careful knob twiddling I got this to occur:\n\n![[Pasted image 20220704112053.png]]\n\nThis shows the locking to one of several(8?) different phases. To me this is indicative of the feedback occuring at a higher frequency harmonic. If things locked at an 8x harmonic then the fundamental would appear at 8 different phases like this. The waves in this circuit are deliberately large amplitude and highly distorted so I suppose this is possible, although it's also what loop filters and whatnot are supposed to prevent.\n\n## Loop filters (again^2)\n\nI think that I need a pot on both R35 and Q5base is needed. Fiddling around with the pots, voltages and frequencies for a while I was not able to gradient descent to a proper solution. So I took a look through the literature again and was reminded that everyone is like \"yeah nah yeah nah a plain ol RC is all you need\". (Note: plain ol RC does not invert signal of course). So I took the lowpasssed output of the phase detector and put it straight back onto the varactor diode, bypasing the diff amp section entirely. \nThe phase detector output is [only 500mV in amplitude]([[#^4bc1e2]]) and so I had to adjust the input frequency to something that required a varactor diode voltage of \u003c500mV but after doing that things locked fine and pretty robustly (could put in a 300mVpp modulation signal before losing the lock).\nNote however that this time the PLL locks on the rising edge of the VCO:\n\n![[Pasted image 20220705171004.png]]\n\nYellow: Incoming signal, Magenta: VCO. It was different [here]([[#^3f8215]]).\nSo in order to lock to the full vcc range I think either:\n- Going back to the noninverting output of the diff amp to apply some hopefully non-phaseshifted gain to the passive filter\n- Or bearing in mind the XOR phase detector should theoretically be able to go all the way from 0-\u003eVCC just redesigning the passive filter to have less of a voltage drop.\nThe latter seems more efficient as the reason that I put in the diff amp in the first place was back when the mixer phase detector was being used.\nOption 2 filter looks like this:\n\n![[Pasted image 20220704195402.png]]\n\n...But I can't seem to get the PLL to lock at that frequency. Same [popping]([[#^39d225]]) behaviour as before.\nTime to take a bode diagram of this filter to compare it to the [other one.]([[20220322 - Look at that Bode#^34b78a]])\nNew RC filter:\n\n![[Pasted image 20220704200052.png]]\n\nOld filter measured again with realistic load on the output of the filter (75R):\n\n![[Pasted image 20220704200750.png]]\n\nWell the LC filter is certainly more dramatic but I don't exactly see why it works and the other doesn't.\n~~From the above observation about being able to lock on the rising or falling edge of the VCO, I gather that I have achieved a lock on both the rising and falling edges of the XOR phase response. So presumably what is left over is to divine what's wrong with the above loop filter. I think that the response time of the VCO itself is probably about [60Khz]([[20220428 FM v2 bringup#^eed27d]]). \nAt that frequency both of the filters aren't doing much, altough the plain RC one has a 30deg phase shift. Maybe that's it?\nAlso it's not in the bode diagram for some reason but the p2p amplitude of the RC filter is a fair bit higher (1-4Vish) than the LC one (180-420mVish).~~\nI also discovered that a lock can be achieved if the RC filter _and_ LC filter is connected, with the output of the RC filter going to the varactor diode and the LC filter just acting as a load. So presumably either a phase shift or an amplitude shift needs to be induced, and this is a starting point to find out which.\n\nHere is the output of the phase detector when unlocked and with both the RC and LC filters attached. Green is raw XOR output and Blue is filter output.\n\n![[Pasted image 20220705183330.png]]\n\nHere just the RC output:\n\n![[Pasted image 20220705183614.png]]\n\nNext step is to load down the RC filter until it has the same amplitude as the LC version.\nHere is the output of the RC filter with 70R loading it down (exactly the same resistance as the loading on the output of the LC filter incidentally).\n\n![[Pasted image 20220705185933.png]]\n\n(Note the vertical scale for CH3 in this picture).\n\nThis filter results in a PLL that can track 410mV worth of frequency swing which is [more than before]([[#^3f8215]]).\n\n![[Pasted image 20220705190604.png]]\n\nThe intention of this experiment wass to plain ol divide down the voltage, not change the impedance as actually happened. This could be done with a high input impedance buffer followed by a voltage divider. I don't have such a thing on hand though so that particular experiment shall be put on the shelf for later. Instead we can add a bunch of gain to this waveform and see if the PLL can still lock with it.\nHere we are:\n\n![[Pasted image 20220705204732.png]]\n\nLots of gain but apparently a fair bit of phase shift, too. \nI think the next step will be to reduce the gain to something like 2x and see if that still works. ^744b71\n\n## Gain reduction\n\n![[Pasted image 20220708185534.png]]\n\nChanging R33 and R34 modifies the gain to about 2x:\n\n![[Pasted image 20220708185622.png]]\n\nHowever the PLL does not seem to lock in this configuration either. It doesn't seem to have much bandwidth:\n\n![[Pasted image 20220708185816.png]]\n\nAnd when the bandwidth drops off the output tends to the DC output level which is of course at the wrong voltage. \nLT spice seems to think the amp should have a bandwidth of like 1MHz and previous experience agrees so I'm not sure what's going on.\n\n## A lock(barely):\nI did get the PLL to lock with the diff amp (barely). Adjusting the DC output, the lock frequency, or the Q5base voltage by even the merest of whiffs loses the lock and then a great deal of fiddling is required to get it back. You can't just throw the lock/unlock switch back and forth and have it lock repeatedly.\nHere is the amplifier performance:\n\n![[Pasted image 20220709112644.png]]\n\nUtter trash. No wonder it locks over such a narrow range.\nRecalling that the original purpose of this was to find out whether having even a perfect amplifier was a bad thing I think switching to an op amp amplifier just to eliminate variables would be a good thing.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220710-Reference-loop-filter":{"title":"","content":"# AD8606 amplifier\nI constructe a noninverting amplifier per the art of electronics basic circuit:\n\n![[Pasted image 20220710120248.png]]\n\nAnd it looks like this:\n\n![[Pasted image 20220710120455.png]]\n\nWorks great.\nWith this amplifier I can get the PLL to lock with a whopping 1.5Vpp input, up from the previous [410mV]([[20220701 Inductance measurements#^744b71]]). I think this is satisfactory for the overall design. You can see that the VCO (CH2) is close to its limit:\n\n![[Pasted image 20220710120750.png]]\n\nAny higher frequency and it would stop oscillating entirely.\nCH3 is the input to the VCO. Notice how it requires an offset. The amount of offset required increased with the modulation depth. This seems like it could be to do with maintaining a more constant % modulation.\n## Performance\n~~Here are the performance stats. These were measured with a ramp waveform of amplitude 1.6V:\n\n![[Pasted image 20220710142656.png]]\n\n### Input vs output voltage\n\n![[Pasted image 20220710141906.png]]\n\nOver a MHz of swing there - Noice.\n## Nonlinearity\n\n![[Pasted image 20220710142118.png]]\n\nInteresting difference in the response on the ramp up vs ramp down. And the wiggles on the ramp up seem to pretty persistent - you can change the input waveform frequency and amplitude, and get much the same response.~~\nActually all of the above is garbage cause I was not probing the proper input. Whatever, it looks good to me.\nOn to measuring the actual amplifier.\n## Noninverting amplifier performance\n\n![[Pasted image 20220710143413.png]]\n\nLovely. So it looks like the closer to the perfect amplifier it is, the better. From previous testing though I know that more gain than this is deleterious.\n## Diff amp performance\nHere is the diff amp in its current state:\n\n![[Pasted image 20220710164535.png]]\n\nI have adjusted the voltage of Q5base to be at ground and then adjusted the supply voltage so that the output is centered at ground too. This required a supply voltage of -15V, but we can just decrease the resistor there later and that should be fine.\n\n![[Pasted image 20220710165010.png]]\n\nHere is what LT spice says the bandwidth should be of this configuration:\n\n![[Pasted image 20220710165128.png]]\n\nI don't know what the cause of the difference is. I've been abusing these transistors a fair bit but I would be surprised if they were damaged. The output goes straight into the scope - it's not even loaded down by the VCO.\nThe 3dB bandwidth appears to be about 100KHz, so that wwould imply a capacitive loading of about 265pF, much more than plausibly exists.\nThe only previous result I can find in the notes is this one [here]([[20220322 - Look at that Bode#^a3250d]]) which also says that the bandwidth should be about 1MHz. Maybe I just need to build another one then.\n### The parable of the cable\nWow.\n\n![[Pasted image 20220710173416.png]]\n\nREF1 is CH4 before the cable for CH1 was connected. Now that CH1 has been connected CH1 is quite a bit lower in amplitude! This is with my several meter long BNC cable.\n\nThis calls for a VNA capacitance measurement!\n\n![[Pasted image 20220710173945.png]]\n\n\n![[Pasted image 20220710173952.png]]\n\n350pF!!! Wow.\nNow I gotta go measure some other cables!\nMy 1m long SMA cable is still a whole 100pF:\n\n![[Pasted image 20220710174234.png]]\n\nGiven that even the small cable is 100pF and the high output impedance of the diff amp (6kR) I think this makes probing the loop with a regular cable a no-go unfortunately. \n\nI attached the scope probes with the clippy thing and got this bode plot:\n\n![[Pasted image 20220710180751.png]]\n\nBetter, certainly. Good? Questionable. I could reduce the resistor values but the varactor diode doesn't really need any current to speak of and so this would just waste power when it comes time to plug it into a battery.\nMay as well give it a shot on the real circuit anyway.\n\n## PLL performance with diff amp\nOverall it works pretty well. Locking range is 860mV.\nInput/output ocillation with maximum modulation in:\n\n![[Pasted image 20220711184731.png]]\n\nCorresponding actual inputs/outputs:\n\n![[Pasted image 20220711184927.png]]\n\nNoice!\nHere is the above waveform saved and analysed for nonlinearities:\n\n![[Pasted image 20220711190710.png]]\n\nThe voltages on the varactor diodes are actually in kind of a different place which might account for some of the nonlinearity here.\nHere is a 500Hz sine wave with 750mVpp modulation:\n\n![[Pasted image 20220711191529.png]]\n\n\n### Damping:\nNote that when sharp edge are put in the system such as with a square wave the locking range is a fair bit lower, like 500mV instead of 1V.\nThings are rather underdamped, to say the least:\n\n![[Pasted image 20220711184437.png]]\n\nMaybe we can tune that later but at this point I think that things are working pretty well. Time to whip up a FET input follower so the diff amp isn't loaded down too much and we should be off to the races.\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220711-Diff-amp-FET-Follower":{"title":"","content":"# Consult the book of armaments!\n\n![[Pasted image 20220711204013.png]]\n\nThe art of electronics can't seem to get over JFET's. So 1970. Fortunately for them I already got hooked with the JFET colpitts oscillator, so it isn't any more BOM lines for me to add one in.\n\n## Circuit\nThis circuit here is class A and draws 30mA quiescent, but I think I'll spend a whole design cycle on power efficiency so let's just get this out the door:\n\n![[Pasted image 20220711204616.png]]\n\nPerformance:\n\n![[Pasted image 20220711204644.png]]\n\n...Should be adequate for our 0-\u003e10KHz operation. The egregiously sized AC coupling capacitor is in face a 5x10mm electrolytic so it shouldn't be too bad.\n\n## Real world, real results\n\n![[Pasted image 20220711212351.png]]\n\nWorks Like a charm. Listening to music or a podcast has no discernable distortion. It is a bit quiet though, so adding a touch (3dB?) of gain would be nice.\nTaking a look at the inputs/outputs only about 100mV is being output by my phone so putting that on the transmit side to increase the modulation depth would be best.\nThere is still the matter of the negative rail of the diff amp though. I came across some art of electronics current sink schematics, perhaps one of those can be used instead as it will require quite a lot less voltage headroom, maybe enough even not to need that negative rail.\nFigure 3.26 has the details:\n\n![[Pasted image 20220711213706.png]]\n\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220809-NAND-is-better-than-XOR":{"title":"","content":"It isn't but it does require many fewer transistors. Two, to be precise. \nThe only difference between a NAND gate as a phase detector and an XOR gate is this:\n\n![[Pasted image 20220811205524.png]]\n\nWhich actually works just fine for me, since I was having lots of trouble making an amplifier where the input goes down to the negative rail.\nThe whole thing put together in the simulation looks like this:\n\n![[Pasted image 20220811210028.png]]\n\n(Commit hash: eac9e150ca7f149b245ef8dea28d842c9a3f5f63)\n\nThe two input transistors are responsible for providing a bunch of gain to make the output a nice big square wave. That goes into the NAND phase detector, which then goes into a diff amp.\nThe saturated output of the first gain stage looks like this:\n\n![[Pasted image 20220811210222.png]]\n\nThe second one isn't very high amplitude cause it's going straight into the base of the bottom transistor.\nThe NAND output looks like this:\n\n![[Pasted image 20220811210323.png]]\n\nBefore/after filtering.\nAnd then with gain it looks like this (I reduced the frequency difference by 10x here):\n\n![[Pasted image 20220811210426.png]]\n\nI made the gain of the diff amp about the same as last time (just under 10x) but I think it might need more this time because the phase detector output is lower amplitude by quite a bit. We'll see.\n\n## Current source\nThe art of electronics comes to the rescue as usual with a \"current mirror\" as a great programmable current source:\n\n![[Pasted image 20220812193510.png]]\n\nRemembering that according to the ebers-moll model of a transistor the collector current of a bjt is programmed according to the base-emitter voltage of the transistor. R30 sets the collector current of U10 (and thus also it's base voltage) and then the base voltage of U10 is connected to U9's base, thus also programming it's collector current, the currentwe actually care about.\nThis seems to work pretty well:\n\n![[Pasted image 20220812193744.png]]\n\nI think this has gotten good enough that it's time to build it!\n\n## Preliminary problems\n\n![[Pasted image 20220813152122.png]]\n\nThe output of the buffer (REF1) has too low of a duty cycle. I attribute this to the output of the buffer having too _high_ of a duty cycle, and that being because it's hitting the rail.\nSo I should reduce the biasing on the base of that transistor. Because this transistor is intended to operate rail to rail (high gain) I think we have fallen into the trap of having a circuit that depends on a particular value of transistor gain. Maybe biasing _all_ the amplifiers with current mirrors would work well, like this:\n\n![[Pasted image 20220813203010.png]]\n\nSince we already have a current mirror we can amortise the cost of this transitor across all the places we need a bias!\n### Aside: probing\nProbing the collector of U1 above is a bit tricky by default for a 10MHz signal. Even 10pF of capacitance changes the output quite a bit, and a cable can have 100pF+! So putting a 50kr resistor out from the collector of the transistor and 50R terminating at the scope gets rid of the vast majoraity of the capacitance. The signal amplitude isn't too bad either since it was originally 5vpp.\n## Phase output offset\nIt seems that the phase output doesn't match the simulation, the output is too close to ground. It's 0-\u003eXXXV rather than vcc/2-\u003evcc. This means that things clip after the buffer because of the $V_{be}$ drop.\n\n![[Pasted image 20220814133846.png]]\n\n\n![[Pasted image 20220814133647.png]]\n\nI don't know why exactly. Decreasing R19 here to 100R improves the offset but it looks like the phase clips at the top and bottom of the range now:\n\n![[Pasted image 20220814133622.png]]\n\nGreen: 'ph_buf' node (after U6 buffer)\nPink: 'ph' node.\nSo the goal here would be to reduce the quiescent current of U6.\nWe can do this by:\n- Increasing R27 ( changes loop filter rolloff)\n- Putting new resistor from U6base to ground (also degrades signal)\n- Increasing the bias on U1/U2 so that they have lower output current into the NAND gate. The whole biasing scheme of these tranistors seem bad but I applied the heat gun and nothing much happened.\n\nInstead of doing the above I changed component values to the following (Notice how I got rid of the buffer):\n\n![[Pasted image 20220814150154.png]]\n\nThis leads to the following output:\n\n![[Pasted image 20220814150215.png]]\n\nWhich is great! The minimum output voltage from the diff amp is about 1.2V but that was always the plan. Just put a diode or two on the output and voila!\n## Diode on the output\nAbout 3 diode drops are needed in order to get an output that goes to the negative rail. But if you do that there's a bunch of capacitance and whatnot and the bandwidth is garbage (I think). So instead just doing an emitter follower with some exta npn's in the way is the way to go:\n\n![[Pasted image 20220814171526.png]]\n\nWhich produces this waveform:\n\n![[Pasted image 20220814171641.png]]\n\nWhere green is the vout_p node and blue is the vout node.\nI think this means that it's ready for prime time in a loop!\n(A crude measurement indicates it has a 150kHz 3dB bandwidth. This actually seems to be limited by something upstream. Gee, that wouldn't be R27/C5 would it?)\n\n# Prime time\n## Problem 1\nI noticed that closing the loop switch caused one of the oscillators to stop oscillating. The control output was at the positive rail (3Vish cause of diode drop) when this happened. I adjusted the pots connected to the varactor diodes for each oscillator to ~2V/11.1MHz. This caused the DC level of the phase detector to shift a lot!\n\n![[Pasted image 20220814175321.png]]\n\nI think this is happening because there is an amplitude-frequency dependence to the VCO and this translates to a frequency-duty cycle dependence on the input to the NAND gate. Since the phase is the lowpassed version of the output of the NAND gate, the duty cycle of the input is very important. \nPerhaps this means that my gung ho \"36k to the rail\" transistor biasing was just as terrible as I'd feared. It should be possible to get it to the point where there is a 50% duty cycle output even with changes in the amplitude of the input.\n## Attempt #1: biasing\nHere is how the art of electronics says you should bias a common emitter amplifier with a second transistor:\n\n![[Pasted image 20220814180210.png]]\n\nThis looks like the regular current mirror that was used on the diff amp:\n\n![[Pasted image 20220814180240.png]]\n\nexcept for the addition of the resistors. Those resistors are there because unlike before you can't connect the bases directly together (that would wreck the input impedance).\nWorks great:\n\n![[Pasted image 20220815210744.png]]\n\nThe above are the two buffered outputs with the 1000:1 divider. There is a 43% duty cycle that's basically independent of LO frequency!\nI used these values to do the baising:\n\n![[Pasted image 20220815210850.png]]\n\nand one BRF106 can be used to bias two amplifiers no problemo.\n## Back to the phase detector\nClosing the loop on the phase detector makes things get pretty wild:\n\n![[Pasted image 20220815213304.png]]\n\nI haven't seen that particular pattern of wackery before. Not sure what's going on. It's not the popping behavious from before I think.\n\n# Boom. Locked.\nI noticed before that the bandwidth was only 150KHz. I  also noticed that the gain was a fair bit higher than it needed to be. Increasing the 3dB bandwidth to 1MHz by changing R27/C5 to 1kR/150pF:\n\n![[Pasted image 20220818200252.png]]\n\nIncreasing R26 only to 1kR changed the gain to ~2. I correctly decided that R25 is not very important.\n\n![[Pasted image 20220818200358.png]]\n\nHere is an image of the thing locked with a 1.4V modulation amplitude:\n\n![[Pasted image 20220818200514.png]]\n\nThe shape of the modulation is garbage cause of the 1000:1 divider.\nHere is the input/output shape:\n\n![[Pasted image 20220818200750.png]]\n\n...obviously needs a tad more lowpass on the output there but otherwise hunky dory.\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220816-Blindar":{"title":"","content":"# Idea\nInstead of a walking cane that blind people use to feel their way around, there should instead be a laser cane that measures distance to stuff and then informs the user instead.\n\n![[Pasted image 20220816191953.png]]\n\nThe lidar would have the same form factor as a regular torch, only it would be a lidar instead. Distance measurements could be fed back to the user by vibration or maybe audibly, perhaps with the kind of audio modulation that metal detectors use.\nThen the user could use the lidar by waving it around rapidly to scan where potential obstacles might be. I think this manual scanning creates the opportunity for the meat based neural net to do some good learning and come up with a proper map of the surroundings.\nIt's pretty trivial to create a lidar with a range of 20m, and that would already be more than enough for a laser cane. \n# Implementation\nGiven the pretty low performance requirements I think a coaxial design with a regular ol 905nm laser diode and silicon APD would work fine. Something like this:\nSide view:\n\n![[Pasted image 20220816192454.png]]\n\nFront view:\n\n![[Pasted image 20220816192533.png]]\n\nThen a regular ol pulse detector of some kind could be used instead of a proper ADC.\n# Problems\nOne of the main problems here is going to be close range detection. I'm not sure how to get around this one. Perhaps some kind of baffling can be made between the tx and the rx to get the crosstalk down to an acceptable level. Failing that maybe a second tx lens, although that's quite undesirable from a complexity/size/alignment/general terribleness POV.\nI don't think it would be a good idea to go to an ADC and try and subtract out the waveform. That would require expensive electronics that would prolly consume 1W+ and make it infeasible.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220825-microwave-tesla-coil":{"title":"","content":"## The coil\nWound from the fan motor:\n\n![[Pasted image 20220825181021.png]]\n\nInto this:\n\n![[Pasted image 20220825180953.png]]\n\n...misjudged the amount of wire a bit.\n\n### Inductance measurement:\n\nHere is the R+Jx plot a la from [[20220701 Inductance measurements]]:\n\n![[Pasted image 20220825184412.png]]\n\nI don't know what this means really but those are some big numbers and thin spikes!\n\n## Resonance thereof\nThe planned schematic of the tesla coil goes something like this:\n\n\n![[Pasted image 20220826201849.png]]\n\nHere LC circuit A must of course be matched in resonant frequency to LC circuit B for maximum energy transfer and whatnot.\nSince the VNA only goes down to 50KHz I decided to make this circuit to measure the resonant frequency:\n\n![[Pasted image 20220826202154.png]]\n\nWhen we do a frequency sweep there should be a sharp drop in amplitude measured by the scope. Fortunately this seems to have worked great, here's a bode plot from the scope of circuit B:\n\n![[Pasted image 20220826202432.png]]\n\n387KHz is pretty high for a tesla coil I believe but then again it's a small coil.\nBy the way I disconnecte the scope from the measurement and the dip went away, so this is definitely a measurement of the coil.\nThe measurement setup looks like this:\n\n![[Pasted image 20220826202642.png]]\n\nWith the probes just barely visible in the corner.\n\n### Circuit A\nThis one was probed like so:\n\n![[Pasted image 20220826134401.png]]\n\nWhich yielded this plot:\n\n![[Pasted image 20220826134431.png]]\n\nResonance at 65KHz, and wayyy lower Q in this plot. I think it's supposed to be like that though, lookss like a classic \"capacitor down 20dB/dec + inductor up 20dB/dec\".  Who knows why the other one is higher Q, then.\nThe capacitor was a 0.75uF+-3% one rated to 2100V.\nResonant frequency of a LC circuit is:\n\t$$f = \\frac{1}{2\\pi\\sqrt{LC}} =\u003e L = \\frac{1}{{C(2\\pi f)}^2}$$\nAnd so with a capacitance of 0.75e-6 and freq of 65e6 that gives us an L of 8$\\mu$H exactly. That seems rather high...\n## Resonant frequency adjustments\nThe primary side has the resonant frequency of 65kHz, the secondary 387KHz. Gotta make them meet.\nAdding a hat to the tesla coil:\n\n![[Pasted image 20220826155502.png]]\n\nMoves the frequency from 430KHz to 380KHz:\n\n![[Pasted image 20220826155545.png]]\n\n(Why did the frequency go up again? idk)\n\nHere is the plot of the microwave oven capacitor straight to ground:\n\n![[Pasted image 20220826165547.png]]\n\nSince the minimum impedance here is already around 300KHz. Any turns on the secondary at all will just pussh that down more. Not much hope, then.","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220902_blindar_cancellation":{"title":"","content":"# Coaxial small lidars.\nAll small lidars are designed for short range. Short range lidars need to have a very close minimum detectable range(duh).\nI have noticed that every single small lidar I've seen uses a biaxial system. It might on some level be easier to manufacture these, but I believe one major reason for this is that a coaxial/monostatic system would suffer too much from crosstalk from the lens etc.\nNormally the way crosstalk is removed is by sampling the waveform and subtracting a known crosstalk reference. But ADC's fast enough to do this are expensive and high power, and this is another point against using them in small systems.\nCrosstalk-free systems can use simple digital edge detection for their waveforms, which is _much_ cheaper.\n\n# Solution\nIt should in principle be possible to cancel the crosstalk pulse from the receiver in the real analog domain. This could be done a number of ways.\n- Play back a known waveform with a DAC to subtract things out.\n    - DACs are cheaper than ADC's but this is still most likely fairly expensive.\n    - This has the advantage of guaranteeing no interference from the real signal\n- Measure the current flowing through the photodiode and use that as a reference for subtraction\n    - This assumes the current-\u003ephotons transfer function is linear, which it isn't. Especially with these high power pulsed lidars the relationship may well be garbage. Experiments needed!\n    - There will be a small time delay between the measured current and the received crosstalk. Should be sub-ns and fixed, but still would most likely require addressing. I think a delay line of some kind may be appropriate here\n- Measuring the crosstalk with a separate photodiode and subtracting that\n    - Have to make sure that the signal photons don't hit the 'reference' photodiode. This could perhaps be done by putting the reference photodiode in a different location and then having a couple of baffles and perhaps even a reference surface on the tx side to get a measurement. This would work well I think when perfectly aligned but would be prone to drift with very small mechanical changes (inevitable in a cheap plastic consumer product). A feedback loop might be able to take care of things here. \n    - Has by far the highest potential for best cancellation - same photodiode, same frontend etc etc.\n    - Depending on whether the subtraction is done pre or post first stage amplification this could have a sensitivity impact.\n    - Lidars use avalanche photodiodes, and avalanche photodiodes have mighty poor linearity. This will be a problem for any cancellation scheme (since we are cancelling a noisy signal) but will be an especially large problem when trying to cancel one noisy signal with another. There might be some implicit sensitivity hit here since the excess noise of a APD goes down a lot with the gain.  \nHobbs' building electro-optical systems has some good words to say on this (section 18.6), especially the use of what looks an awful lot like a current mirror for cancellation.\nIt worrys me a bit though that he says:\n\"\nIn a measurement whose sensitivity is limited\nby laser residual intensity noise (RIN), the noise canceler can improve the SNR by as\nmuch as 70 decibels at low frequencies, and by 40 dB up to 810 MHz or so, as shown\nin Figure 18.21.\n\"\nWe want hundreds of MHz! That sounds like things will just stop working by the time we get there!\nMaybe that's because his system doesn't have a cascode-like property, and the bandwidth can be easily increased? I don't know, and I need to understand the circuit better.\nThe guy also likes to go on about \"etalon fringes\" and whatnot for the circuit. tbh I don't even know if he's assuming a coherent system, alhough it for sure looks like regular intensity cancellation is what's going on.\nThe guy also claims to have used it for a fmcw lidar...\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220918-I2S-woes":{"title":"","content":"# Goal\nI have a esp32 board called a \"TTGO LoRa32-OLED\" here that I am trying to output an I2S signal from into a breakout board based on a PCM5102A i2s auidio DAC.\nI noticed a problem though when generating a sin wave signal, there was a 'pop' a couple of times a second. Outputting a ramp test pattern:\n\n![[Pasted image 20220918144613.png]]\n\nInto a scope reveals this:\n\n![[Pasted image 20220918144735.png]]\n\nThere's a bunch of glitches in the output!\nThis tells us that the glitch is not caused by the loop not being serviced regularly though (I think) since that would cause a flatline presumably.\n\n## Drilling down\nTaking a look at the decoded protocol we see this:\n\n![[Pasted image 20220918144653.png]]\n\nYou can see that along the bottom the i2s decoded numbers continue to increase even though there is a discontinuity downwards.\nPerhaps then it's the amplifiers problem? There are a bunch of modes in i2s that I don't really understand so maybe we are uing the wrong one and the timing iss marginal or something.\n### Check yourself before you rek yourself\nHere is a screenshot of the signal on a *normal* falling edge:\n\n![[Pasted image 20220918151417.png]]\n\nThis also has the samples ascending!\nLooking at the datasheet it talks about filtering and latency a bunch, so that's probably what' going on here.\n\n## The solution\nIt turns out that the arduino library I was using here had some circular buffer mutex freeRTOS synchronisation stuff going on. I wrote my own simple version based of some stuff on the internets and that works fine.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20220923-blindar-prototype-notes":{"title":"","content":"# System setup\nArduino TTGO lora oled jobbie attached to a tf mini plus and a pcm5201a audio i2s thingo.\n\n# Images\n\n![[Pasted image 20220926193645.png]]\n\n\n![[Pasted image 20220926193659.png]]\n\n\n## Jitter fixes\nI discovered that writing to the I2C OLED display took about 25ms and made the CDF of my processing time graph look atrocious:\n\n![[Pasted image 20220926194317.png]]\n\nSomething simply must be done.\n\n### New thread\nBut after moving the display write to another thread my processing time looked like this:\n\n![[Pasted image 20220926194049.png]]\n\nExquisite.\nI think I can even hear a difference in the sound too. If I were an audiophile I'd describe it as more of a liquid burble when sweeping around. Good job I'm not.\n\n## Frequency to distance\nThe blindar measures distance. That's the easy bit. The hard bit is passing that information to the user in an intuitive way.\nThe most naive wait to do it is a straightforward frequency mapping: higher distance, higher frequency.  This is good enough for someone to not bump into things like walls but is entirely inadequate for a number of reasons:\n- The user doesn't really know a priori what this mapping is. \"The pitch is quite low right now, but is the wall 30cm away or 1m away?\". The answer to that is both important and not apparent. It gets better with use, but not that much.\n- Small shifts  in distance are imperceptible. A 10cm jump in distance 2m away is  inaudible as a frequency shift (it might correspond to something like a 200-\u003e220Hz shift). But this distance jump is very important! That's the road kerb we're talking about here! You can't miss that!\nI have addressed the latter issue by attempting to measure small jumps in frequency and then apply in _distortion_ to the sound wave (going from sin wave to square wave). Here's an example distance sweep back and forth over a smooth area and then over some cables I put on the  ground:\n\n![[Pasted image 20221006214254.png]]\n\nZooming in to the cables:\n\n![[Pasted image 20221006214324.png]]\n\nThis is in essence just a highpass filter, detecting fast changes in distance. If you sweep the lidar in front of your like a blind person with a stick as I have done in the above image then it works quite well. \nIf you wave the lidar around willy nilly it works appallingly. Small changes in the pitch axis of course produce large changes in distance and so the user can't really flick it up and down.\n### More information\nI think that adding an imu and doing some basic short term pose tracking could work quite well here. That should easily be able to distinguish between a large change in distance due to pitching up the lidar vs actually hitting an object. Data must be collected...\n\n\n\n\n\n\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20221009-Lidar+imu":{"title":"","content":"# Idea\nAs mentioned [[20220923 blindar prototype notes|before]] because the lidar does not have any notion of pose it makes it difficult to detect the difference between:\n - A spike in distance that is due to the lidar scanning over an obstacle (side view):\n\n![[Pasted image 20221010184137.png]]\n\n- The lidar scanning over a different point in the floor by pitching up with the lidar (top view).\n\n![[Pasted image 20221010184012.png]]\n\nOne of these is obviously a problem, and the other isn't. If we knew the pose of the lidar then it would be easy to do this by projecting the points into the world frame.\n## Orientation integration\nWe can use an IMU to do this though (kind of). I have a MPU-9250 which is a 9-DOF sensor. As a quick test over time, let's try integrating just the orientation of  the sensor and rotating the sensor about a single point to scan a nice box.\nI took some random rotation matrix thing from [wikipedia](https://en.wikipedia.org/wiki/Rotation_matrix#Basic_rotations):\n![[Pasted image 20221108201847.png]]\nand plugged it into the measurements I had made alongside the lidar, and voila:\n![[Pasted image 20221108202011.png]]\n![[Pasted image 20221108202025.png]]\nA point cloud of a box:\n![[Pasted image 20221108202125.png]]\nLooks pretty excellent to me!\n## Flaw\nAlthough I think that this is a good extra source of information that could  be used to do stuff like fit the last 500ms of data to a plane and calculate the deviations from that plane it seems to me like it would suffer from the problem of constant velocity. Since a person is already travelling at constant velocity the imu can't really measure that, and so I think that this would cause problems. \nAs an aside I wondered whether or not it was possible to use the earths magnetic field to sense ones velocity in the same way that it is possible that you can use it  to sense your orientation. You would think  that waving a  conductor around would cause a current to be induced but not so apparently! You need the field to be changing. That's why  this isn't already a thing.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20221015-FM-V3-bringup":{"title":"","content":"# Off the bat\n\n^b68437\n\nIt seems that straight off the bat  the oscillator oscillates. One small problem though, it only does that at a _very_ specific range of temperatures. Here is the circuit deciding whether or not it is at the right temperature:\n![[Pasted image 20221015190411.png]]\nI recall seeing in the art of electronics that JFETs have a large variability in their gain and Vgs and whatnot from sample to sample. So it's a good guess that's what's going on here. From the third edition:\n\n![[Pasted image 20221015190723.png]]\n\nGoing off the general principle that more bias current is good for everything except power consumption, let's try increasing it.\n\nAs a reminder, here is the circuit:\n![[Pasted image 20221016230908.png]]\nSince $I_d$ is set by $V_{gs}$ and $V_g$ is set by the R1/R8 divider we can say that:\n$$ \\frac{V_{cc}R_{8}}{R_{8} + R_{1}} = V_{gs} + I_d*R_{13} $$ Note  that in practice $V_{gs}$ is a negative voltage.\n\n## Sanity check\nAt this point it occurs to me to measure the drain current and look at where it sits on  the characteristic curves in the datasheet...\nVg is 716mV. Vs is 1.40V. Vd is 4.18V. So Id is (4.6 - 4.18) / 100 = 4.2mA, or 1.4 / 330 = 4.2mA. \n=\u003e $V_{gs}$ is -0.684V, and we sit here on the operating curves:\n![[Pasted image 20221016180811.png]]\nSeems about right to me.\n\nNote: when I adjust vcc up to 5.0V things become unstable in the same way as described in the [[#^b68437|beginning]] . Good way to check for better stability later. Adjusting the oscillator frequency to 10.0MHz from 10.2 also makes it more stable. This required a varactor voltage of 1.18V.\n\n## Circuit B\nI assembled two:\n![[Pasted image 20221016181135.png]]\nOf these boards (Henceforth known from the top down as A and B) and the bottom one does not oscillate at all. We shall measure the same  JFET parameters. I think maybe I am being bitten here over and over again by the JFET variability and I need a proper current source on the source of the JFET, taking the output of the oscillator from the drain. I don't know if this would actually work though.\nVs = 1.36V, Vg = 0.705V, basically the exact same. y u no oscillate?\nI desoldered the next stage of gain from both A and B to try and find differences. This just caused A to stop oscillating as well. I really gotta figure out the whole stability thing here so I can solve this once and for all.\n\n# Colpitts oscillator phase margin.\nI should figure out this phase margin thing. I don't really know how to measure it though, that's the main problem.\nSome textbook called \"Foundations of oscillator circuit design\" has this to say on the topic:\n\n![[Pasted image 20221016184338.png]]\n![[Pasted image 20221016184407.png]]\nI believe $g_m$ is the gain of the transistor. $w_o$ is fixed (10Mhz) and I don't particularly want to decrease $R_s$ because that would mean I needed more collector current for the same output swing.\nI also don't find this model intuitive. The way I have thought about things before is that C1/C2 are a feedaback divider, and so increasing C2 would put more of the RF output to ground, lessening the phase margin. But here they are saying that C1 and C2 affect the output of the circuit in exactly the same way, which I find very suspicious.\nThe textbook overall seems to be of the rather common \"giant pile of useless algebra\" variety, failing to mention, for example, how one might measure the phase margin of a circuit.\n\n## Split the loop\nOne thing that I have noticed consistently comes up in textbooks when discussing phase margin and stability etc for PLL's and oscillators is the concept of \"splitting the loop\" where the circuit is split at some point and it's verified that the output of the circuit is both higher and in phase on one side of the split than the other. \nSeems like a good idea to try here. I think in this case it would look like this:\n![[Pasted image 20221017174748.png]]\n### Results\nI used the nanovna to get these results. I put a 500R resistor on the output though so as not to load down the circuit. Here they are in a smith chart that I don't understand but seems to show something important (maybe my circuit is the same as a capacitor?):\n![[Pasted image 20221017185747.png]]\nAnd here are the the more intuitive S21 gain and phase plots:\n\n![[Pasted image 20221017190034.png]]\n\n![[Pasted image 20221017190107.png]]\n\nThe reference trace here is the attenuation in the system. So in the gain plot everywhere the gain is above the reference line it is above 0dB gain.\nOne thing that struck me was the S11 return loss:\n![[Pasted image 20221017190210.png]]\nI *think* this means that the output of the amplifier sees a dead short basically at 9.34MHz. That doesn't sound great.\nRegardless it looks like the max gain is +5dB at 9.48MHz, and overall I think the plots more or less make sense. The gain is \u003e0dB (but not by much) and the phase is close to 0 degrees (but varies wildly).\nNext I think I will take another measurement with the varactor at a higher voltage. In the above measurements it is at 1.19V. Here it is at 4V:\n![[Pasted image 20221017191622.png]]\n![[Pasted image 20221017191634.png]]\n![[Pasted image 20221017191644.png]]\nAs expected things have shifted to a higher frequency. The peak gain is only like 3dB now though.\n\nI did some LT spice simulations and from looking at that I came to the conclusion that reducting the drain resistor is what is needed here. This is because the impedance applied to the gate of the JFET is the sum of the impedance of the drain resistor and the resistor between the source and the gate (R3 + C2):\n![[Pasted image 20221019030548.png]]\nWhich just like everything else in life makes total sense in retrospect.\nLT spice confirms that this should increase the \"open loop\" gain, let's take  a look irl by changing R3 to 10R.\n....And that makes practically no difference. I guess my assumption that the CPH3910 itself was low impedance compared to 100R was false.\nAfter consulting the \"High Frequency VCO Design and Schematics\" page it seems that increasing  the coupling between the LC network D1/L1 and the transistor by increasing C1 can also help. This seems to work OK, the gain increased to a peak of -11.7dB. I think perhaps that increasing C1 to the point where it is very low impedance increases the sensitivity of the circuit to the absolute values of C2 and C4. 150pF is 106R at 10MHz and 8.5nF is 1.5R.\nI connected the ends together and it oscillates pretty stably though. The amplitude drops considerably from the heat gun but it still oscillates so that's OK I think. Sensitivity to vcc is also down so I shall call it a day and change the value permanently.\n### Circuit B\nThe day was not called. Circuit B was oscillating unreliably. Changed R3 to 10R (probably not important) and C4 to 200pF, then replicated changes on circuit A. Crossed fingers that's enough\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20221025-antenna-tuning":{"title":"","content":"# Main goal\nThis fm radio project has dragged on long enough. If I could build one of those antennas with inductors at the bottom that work at low frequencies then I could avoid the planned upconverting step to 915MHz and just operate the system directly at 10MHz.  Not particularly FCC compliant, but for desk-\u003eheadphone transmission the power should be low enough that it's OK.\n\n## Initial tests\nI stuck a piece of wire to a pcb like so:\n![[Pasted image 20221025203615.png]]\nThe S11 return loss looks like this:\n![[Pasted image 20221025203639.png]]\nwith a minimum at 612MHz, which sounds about right. -25dB means that 95% of the energy gets transmitted I think.\nAdding a 10nH inductor to the base makes it look like this (I changed the settings):\n![[Pasted image 20221025203909.png]]\nit dropped the frequency a bit, but not by that much!\nTime to 10x the inductor. 100nH looks like this:\n![[Pasted image 20221025204223.png]]\nstill not even close to being low frequency enough, and the transmission has dropped to like 6dB / 50% of the energy.\nI've heard that there's this thing called \"impedance matching\" that you are supposed to do too, so I added a 5pF cap to ground like so:\n![[Pasted image 20221025212908.png]]\nWhich results in this:\n![[Pasted image 20221025212939.png]]\nPretty nice!\nCut-and-try seems like a bad policy here, even if the state space is really small. You are supposed to like balance the the capacitance with the reactance, or something. Now for the question of how much \"capacitance\" equals how much \"reactance\".\nSurely this can be measured with a VNA!\n![[Pasted image 20221025213523.png]]\nI believe on the smith chart where the trace crosses the horizontal axis is where the impedance is purely real (what we want, I think). This is actually pretty close already to the best S11 loss (denoted by the red 1). Deviations along the horizontal axis are away from 50R but I don't think we care about that so much since we are making our own amplifier anyway.\nTime for our first hypothesis: since the red 1 is in the inductive half, we want to add some more capacitance to bring it towards the capacitive half!\n![[Pasted image 20221025213842.png]]\n![[Pasted image 20221025213854.png]]\nI am a tuning genius. \n## Measuring real antenna impedance\nTo calculate the matching network I think we need to measure the antenna impedance at our target frequency. This will be approximately infinity ohms I think.\n![[Pasted image 20221025215046.png]]\nThis is the R+Jx impedance plot from 1-20MHz. at 10Mhz it's basically NaN - 3.2kR. Does that mean that I need an inductor that's Z=3.2kR at 10MHz? without bothering to actually look the answer up I'm going to go ahead an say yes!\nSo according to $X_l = 2fL$  that means my inductor should be 3200/(2*pi*10e6) = 50uH. That sounds... reasonable?\nAnd then I think I'll need to add a capacitor in order to match the impedances to the output of my amplifier. Maybe.\n### Scrounging about for inductors (again):\nHere is a promising inductor 100uH that I could have had two of in parallel:\n![[Pasted image 20221025223441.png]]\nSRF is 7MHz though :(\nStacking 5 of a [[20220701 Inductance measurements#^80ed77|Previous resistor]] (AIML-0603-100K-T0 in series gives this:\n![[Pasted image 20221025223917.png]]\n![[Pasted image 20221025224029.png]]\nHonestly I don't see why people call antenna design hard, this is all going according to plan. Suspiciously so, in fact.\nSince our antenna is basically an open circuit, I think adding a 2.3kR capacitor might be what is required. That's a 1/(2\\*pi\\*2.3e3\\*10e6) = 7pF capacitor. Since we are adding all these whopping great  inductors in I kinda expected something bigger, but OK.\n![[Pasted image 20221025224446.png]]\nwelp that just moved the resonant frequency down to 9.8MHz and did nothing to the S11. Not that surprising  really. \nAs a sanity check I removed the actual antenna to make sure that it was having an effect. Here is an A/B:\n![[Pasted image 20221026080931.png]]\nSeems like it is the inductor!\n## Transmission between antennas\nTo really check if the antennas are doing something and I don't just have some loss at a certain frequency I think the best thing to do is make two of the same antennas and transmit between them. here is an initial attempt:\n![[Pasted image 20221026083020.png]]\n...Not great, but not too hard to adjust I would think.\nTurns out just having the antenna on vs off the desk can make this much difference:\n![[Pasted image 20221026083608.png]]\n\n### Sitting next to each other:\n![[Pasted image 20221026084735.png]]\n![[Pasted image 20221026084556.png]]\n![[Pasted image 20221026084605.png]]\n\u003c10dB of loss seems crazy good tbh. There's also clearly a split in the S11 return loss peak so the antennas are influencing each other.\n\n\n## 2m away\n![[Pasted image 20221027213706.png]]\n![[Pasted image 20221027213713.png]]\nS21 looks quite good but the S11 is clearly bad (should never be positive for a passive device!) and so perhaps it can't be trusted.\nRegardless I think we can try and transform the impedances now. The impedance of the antenna at the resonance point is acctualy quite real, 216+4.3JR. I suppose that's energy transmission requires a real impedance. \n### 50R matching.\nAppendix H of the art of electronics is a good help here:\n![[Pasted image 20221027214020.png]]\nMatching to a 50R system means that our Qel is sqrt(200/50 - 1) = 1.73. So our inductor value should have an impedance of 200 / 1.73 = 113R. That means the value is 113/(2\\*pi\\*10e6) = 1.79uH.\nThen we should have a capacitor with impedance 50 \\* 1.73 = 86.5R, or 183pF.\nLet's try it out!\nI used two 910nH inductors in series and a 180pF capacitor to get this plot:\n![[Pasted image 20221028182452.png]]\nWith an impedance of:\n![[Pasted image 20221028182515.png]]\nAbsolutely spot on. Very high Q though.\n### The next day...\nI come back the next day and measure this:\n![[Pasted image 20221028182606.png]]\n49.9+6JR.\nIt seems like the resonant frequency moved by about 1MHz overnight, and the Q dropped as a result too!\nI don't know why this would be. Taking the antenna off the bench and leaving it free hanging gives this plot:\n![[Pasted image 20221028182805.png]]\nWhere the reference is on the bench and the poper measurement is off it.\nThis is terrible! The antenna bandwidth is going to shift around so much based on what it's sitting next to the entire passband will move away!\nRegardless let's proceed with matching the other antenna and see if we get better transmission anyway.\n...And after messing about with variable inductors trying to get things to line up I realise that it isn't really possible to make a useable system with this. Tolerances in components and how the antenna is situated with respect to the other antennas etc just make too much difference. This is my first time measuring an antenna though so I shall go and make a proper 1/4 wavelength 915MHz antenna and see how sensitive that is to the environment.\n## \"915MHz\" antenna.\nThe antenna looks like this:\n\t![[Pasted image 20221029174430.png]]\nAnd has an S11 that looks like this:\n![[Pasted image 20221029174451.png]]\nWhere the two traces are with/without hand.\nThis is the smith chart:\n![[Pasted image 20221029174520.png]]\nOverall this has made me thoroughly disillusioned with the whole antenna thing. Maybe consumer grade antennas are designed to be especially wideband to let in frequencies no matter how close/far the unit is to the meatbag? Unclear. \n\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20221103-915MHz-brrr":{"title":"","content":"ird party plugins or themes, we highly encourage you to check for updates bFollowing the [[20221025 antenna tuning|previous]] antenna tuning debacle it seems that a 10MHz antenna won't work not because it doesn't transmit necessarily, but because it's passpand jumps around a lot based on what  the antenna  is next to. So the time has come to build a 915MHz oscillator and try and mix stuff in. \nThe only piece of equipment that I have that can detect 915MHz stuff is a RTL-SDR software defined radio. It will be hideously slow to sweep out a full spectrum, but should do the job.\nFortunately there is a [great webpage](https://www.qsl.net/va3iul/High_Frequency_VCO_Design_and_Schematics/High_Frequency_VCO_design_and_schematics.pdf) on the topic which has just what I need. To minimise the chances of anything going wrong I will go with the high frequency oscillator that has the same topology as my current one:\n![[Pasted image 20221103212705.png]]\nWhich once it is working we should be able to adjust down to 915MHz no problem. I even have the BFP420 and some SMV123*4* diodes.\nThis is what the circuit looks like assembled on the [[20221015 FM V3 bringup]] pcb:\n![[Pasted image 20221105180719.png]]\nI used a 27nH inductor though.\nStraight out of the box it oscillates between and  520 and 730MHz! it's only a 500MHz scope but it shows up great nonetheless:\n![[Pasted image 20221105180906.png]]\nAssuming the signal is within the scopes frequency range that would put the amplitude at about 1.5V, too. I guess this guy really knows what he's doing.\nThe circuit only has a 730/520 = 1.5:1 tuning ratio though  compared to the claimed \u003e2:1. not sure what the cause of that is. Could well be parasitics, since we are talking about single digit pF here.\nApparently the frequency of oscillation in the above circuit is given by 2 L = 1/(C2+Cvar)+(1/C3)+(1/C4). So since I want a frequency 50% higher that means I should divide the L by 1.5^2 = 2.25, right?\nSwapping out for a 12nH inductor gives a low frequency of 720MHz and a high of something that is north of 1GHz (this is a 2GSa/s scope):\n![[Pasted image 20221105182146.png]]\nExcellent! Only one problem - I only bought two of those diodes so I can't make another receiver circuit straightaway. To digikey!\n\n#  Mixing\nNext step is to do the upconversion. Since it turns out my scope can see 720MHz just fine, let's do it there. The seupt is  the output of the oscillator tuned to 750MHz on the dot sent into an ADE-2ASK+ mixer as the \"LO\", with the \"IF\" being a 5MHz sin wave coming from  the function generator (amplitude only 56mV here).\nHere is an FFT of before mixing (white) and after mixing (orange):\n![[Pasted image 20221105203324.png]]\nIf we zoom in on the time series we can see the modulation of channel 3:\n![[Pasted image 20221105203458.png]]\nI don't know what the deal is with the three spikes in the frequency domain. This is outside the proper operating region of the scope so it might just be a measurement thing but if not this is something to worry about I think.\n\nThis all looks fairly reasonable, now the question is if it can be downconverted back to the original signal. \n\n## Handy graph for what things go where\n![[Pasted image 20221112113028.png]]\nFrom [here](https://www.markimicrowave.com/assets/appnotes/mixer_basics_primer.pdf).\n### Pinout that infineon was too lazy to make\n![[Pasted image 20221112115657.png]]\nBFP420H\n\n## Oscillator 2\nI made this one out of an old FM V2 PCB because it still had the footprint for the ADE-2ASK+ mixer on it. Here are the two outputs side by side with the same varactor voltage:\n![[Pasted image 20221112143528.png]]\nWhy  is the second oscillator so much lower than the first? Well because it _isn't actually wired up to the output of the oscillator_:\n![[Pasted image 20221112143729.png]]\nAnd it still gets that much signal!\nActually wiring it up and making sure that I am measuring the same thing for both oscillators doesn't actually seem to change anything. In addition to this the amplitude falls off super fast with increasing frequency so by the time I am tuned up to the range of the first oscillator the amplitude is very low. It does form a spontaneous PLL though, which is cool:\n![[Pasted image 20221112151241.png]]\nI don't know why this amplitude fallin off thing is happening. I checked the DC levels everywhere and didn't find   anything. I double checked and replaced the feedback capacitors  and they are fine. \nInterestingly probing the emitter of the transistor with a multimeter lead has very different results. For the well behaved circut the results look like thiss:\n![[Pasted image 20221112152544.png]]\nI interpret this to mean that the impedance the emitter sees to ground kind of moves around with frequency because the multimeter lead is a transmission line or whatever. This effect disappears when I touch ground with my other hand btw.\n... This whole thing turned out to be the AC coupling capacitor coming out of the oscillator being desoldered on one end :shrug:.\n## Mixing again\nPutting a 10KHz square wave into the 10MHz VCO which then gets upconverted in the 750 MHz VCO like so:\n![[Pasted image 20221113184227.png]]\nI tuned the high frequency to be at 750MHz rather than 915MHz cause that was what was easy to do at the time.\nThis results in the following spectrum:\n![[Pasted image 20221113184544.png]]\nLooks pretty reasonable to me, now  to take that output and put it into the next mixer to downconvert it. This is the part that should theoretically cross the air gap to the headphones.\n## Results of downconversion:\nUnforturnately it looks like if I put the two LO's at the same 750MHz frequency they just phase lock:\n![[Pasted image 20221113185338.png]]\n...That's not what I want. Right?\nI think the next version of my board should include a usb connector to make it easier to power the things separately, and a long way away from the bench.\nI think I will adjourn here and make that pcb. Parasitics and whatnot are bound to be important so I  may as well order it now.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20221126-DC-26GHz-Attenuator":{"title":"","content":"# Problem\nI have  a  [[20220412 Advantech debugging|Spectrum Analyzer]] that doesn't work.  The frontend attentuator  for it also does not work. Opening up the attenuator, we can see this:\n![[Pasted image 20221126142350.png]]\nIt looks like a pretty straightforward setup.  A set of latching solenoids depress the black plungers on either side, either bypassing (bottom path) the attenuator, or switching in (top path) different valued attenuators. Only one  problem: there is no connection on the right hand side to the connector!\nThis should  be a simple matter to fix,though. A small amount of spring steel in the right spot combined with a dab of plastic and cyanoacrylate:\n![[Pasted image 20221126142559.png]]\nAnd boom - fixed.\n## Or is it?\nThe two regular attenuators turn out to be flat -20 and -40dB attenuations as measured by my NanoVNA, but the replaced one looks like this:\n![[Pasted image 20221126143621.png]]\n...That aint so great.\nFurther inspection reveals that the attenuator seems to have burnt out -  it's open circuit across the attenuator and to ground on one side.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230115-FMV4-bringup":{"title":"","content":"The FM4V pcbs have arrived. This time I used the jlcpcb assembly service. The PCB's look like this:\n![[Pasted image 20230115192501.png]]\n\nThe oscillator comes up without any prompting thankfully. The first thing that I want to look at is the 915MHz amplifier.\nIn order not to cook the spectrum analyzer I am going to use the attenuator from [[20230115 attenuator]].\n\n## Assembly problems\n![[Pasted image 20230115193957.png]]\nSome dingus soldered a 0R resistor onto R65 which understandably. Once that was removed the amplifier turned itself into a 700MHz oscillator. Nice. Since the VCO is right next to the amplifier I'm going to turn it off by desoldering R53 and then trying again.\nThat fixed the oscillation, but there is now a bunch of crosstalk coming somewhere from the 10MHz system. The fastest edges there come from the NAND gate, and indeed the interference concides directly with an extremely sharp falling edge there. Disconnecting the phase detector by desoldering R5 gets rid of it entirely.\nThe amplifier has huge attenuation. Perhaps this has something to do with how someone put a 0R resistor in R64.\nRemoving that resistor we get this:\n![[Pasted image 20230116113736.png]]\nThis is with 20dB attenuation from the attenuator, bottom line is ref through a THRU trace on the ufl RF demo kit.\n\n## Optimising\nThe BFP420 should have way more gain than this though:\n![[Pasted image 20230116114145.png]]\n\nSo let's measure some important parameters:\n- Vbe = 0.951V\n- Ic = 2.79 / 50 = 55mA\n- Ib = 3.59 / 4700 = 0.76mA\n...This seems like it's being driven rather hard.\n![[Pasted image 20230116114826.png]]\nAnd indeed we seem to have travelled off the end of the x axis. Absolute maximum is 60mA though and transistor doesn't seem to be _too_ toasty, so we should be still OK.\nI think I want this amplifier to have a fairly low output impedance so as to be able to drive the mixer nice and hard, and so instead of increasing R71 I will increase R57:\n![[Pasted image 20230116120237.png]]\nI think we want somewhat less than a factor of 10 less bias current, so I'll go with 33kR.\n...aaand the transistor seems to be blown. I resoldered another one, but for future reference the current draw without the transistor attached is 91mA. Since the regulator is a linear one, any deviation from this is the current consumption of the circuit.\n\nWith R57=33k and R71 still 50R the Ic is 11mA, Ib is 3.6 / 33k = 0.1mA. Looks like this was the desired Ic adjustment, but the gain looks like this now:\n![[Pasted image 20230116151913.png]]\nWhich is quite a bit worse. The S11 smith says that the input impedance is 55+j20R. I'm not sure but that sounds pretty close to 50, sufficiently close anyway that the 20dB performance gap is not explained by it. \nThe application note has a pretty big inductor (about 50R at the target freq) in series with the input for 50R matching though, and I also notice that the input impedance of this thing barely changes with turning the device on and off. Also the app note for 'high impedance input' has basically the same circuit as I do, so I think there might be something fishy going on here.\n...Measuring the input capacitor, it's 5pF. I should check the BOM that got sent out cause it sure looks like the JLCPCB people got a lot wrong here. Using a 300pF capacitor gives this input impedance (0-915MHz):\n![[Pasted image 20230116155442.png]]\nWhich looks much more like the application note (high input impedance at 100MHz).\n\n## Input matching\nI think that I should initially run the system at 300MHz, to be comfortably within the scopes 500MHz bandwidth.\nAt 300MHz the input inpedance of the amplifier is 0-128jR. ~~~Referring to [[20221025 antenna tuning#50R matching.]] this means:~~~\nAdding in an inductor of ~128R cancels the impedance at 300MHz:\n![[Pasted image 20230116173634.png]]\nBut that's not really what I want cause the impedance is wayy too large. Doing the maths in the Hagen textbook I don't really see how it's possible to match a purely imaginary impedance to a real 50R system. The imaginary bits just shuffle around. But there is an example in an [application note](https://www.infineon.com/dgdl/Infineon-Design_Guide_for_low_noise_TR_in_FM_radio_FE-ApplicationNotes-v01_00-EN.pdf?fileId=8ac78c8c7e7124d1017f0227976a6c9d)\n![[Pasted image 20230116173837.png]]\nSo I will try to assemble this and then see what I measure. \nThe exact transistor I am using isn't one of the examples, and the match is supposed to be at 100Mhz. This is what I get:\n## Impedance measurements\n![[Pasted image 20230116175258.png]]\nWhere the impedance cr\n\n## 20230415 Back in da game\nBack debugging things. Kick this off with the pinout of the BFP420, which I have forgotten:\n![[Pasted image 20230415182152.png]]\nThe datasheet requires way too many layers of indirection to read this imo.\nAlso the app note makes very little sense:\n![[Pasted image 20230415185932.png]]\nSince I haven't actually gotten the amplifier working at all at any point and the example schematics in this app note aren't quite what I laid out initially I took the opportunity to whip up a pcb:\n![[Pasted image 20230415200349.png]]\nThat duplicated the schematics in the app note exactly.\nHere is the pcb (it got left in the etchant too long):\n![[Pasted image 20230418190956.png]]\nand here are the results for the 50R matched one (The one with Q1):\n![[Pasted image 20230418184138.png]]\nThe gain (+20dB because I put 20dB of attenuation on):\n![[Pasted image 20230418184343.png]]\nThis looks more or less in line with the app note, which had gains of 15-18dB with different but similar transistors.\nJust like the app note the gain seems to increase with increasing vcc too, which is nice. I wonder why that is though.\n## Impedance measurements (again)\nNow that we have a good starting point the time has come to try to get it to work for higher frequencies. The matching looks like this from 50-1000MHz:\n![[Pasted image 20230418184828.png]]\nSo I think we are all good there. The gain looks like this:\n![[Pasted image 20230418184850.png]]\n\nwhich obviously needs to be changed. Let's see what happens when we remove the Feedback resistor R4:\n![[Pasted image 20230418185108.png]]\n![[Pasted image 20230418185507.png]]\nWell that seems to have improved things across the board but not by nearly enough. \n## A moment of attenuated brain function\nThe reason that the matching was so good over the whole frequency range was because the setup went vna-\u003eattenuator-\u003eamp-\u003evna. I did this because I was avoiding damage but of course this also meant that's all I measured. Here's the real input matching:\n![[Pasted image 20230418190719.png]]\nMuch more in line with what I have come to expect: egregiously bad.\nOne thing I just noticed in the datasheet is this:\n![[Pasted image 20230418192158.png]]\nMy Ic is according to my power supply less than 1mA. So I should bump that up to 10mA. the app note says that it will be 3.5mA and the transistors aren't _that_ different I would have though so I'm not sure what's going on here.\nHonestly other than providing a design that probably works I'm getting the impression that this app note is BS for the most part. It gives zero information on how to actually do the input impedance matching, for example.\nHere is the smith chart for the input to the amplifier with the inductor L1 shorted and the capacitor C1 removed:\n![[Pasted image 20230418194400.png]]\nSince C2 is 330pF and DC blocking I think this should be a valid way to measure the input impedance? I don't really know how to go about doing this, the textbooks don't really say how you measure an active device like this much.\n### Attaching components for matching.\nRegardless the impedance is 10-j2.6R. So First off I need a 40R inductor. That's 40/(2*pi*900e6) = 7nH apparently. Soldering that on did not lead to much of a change. The impedance of this component directly to ground on a separate test board is this:\n![[Pasted image 20230419192241.png]]\ninterestingly it basically gets the inductance right, but impedance seems to be too low. Looks like I need to roughly double that. ---Record-scratch---\n![[Pasted image 20230419192750.png]]\nThat's a dead short to ground looks like my cal is a bit off. After re-calling things stuff looks more sensible. Here is the input to the amplifier now:\n![[Pasted image 20230423171103.png]]\n\nThat's... not what I expected.\nThe smith chart changes radically when I put a finger near it. Here is what it changes into when I attach the feedback network of R4 and C6:\n![[Pasted image 20230423173712.png]]\nutterly different. The fact that the trace lies outside the smith chart I think is an indication that this is a powered circuit that is adding energy to the system.\n--Record scratch++--\nJokes there was a disconnected cap. Here is the real input impedance:\n![[Pasted image 20230423174238.png]]\nMuch saner.\n### Some progress.\nI found a [cool website](https://www.will-kelsey.com/smith_chart/) where you can put in an impedance and see how a smith chart moves it around. I added in my impedance and calculated what would be required to bring it into 50R:\n![[Pasted image 20230423184730.png]]\nIt seems the component sizes required are really small!\nI added just this piece of wire to the circuit:\n![[Pasted image 20230423184928.png]]\nAnd it did this to the smith chart!:\n![[Pasted image 20230423184952.png]]\nThe S11 return loss now looks like this:\n![[Pasted image 20230423185010.png]]\nI think -10dB is really about as good as necessary here; I've proved that some amount of matching is possible. Now to test the amplifer performance. This will require a 2 port cal on the vna and also I will need to put the attenuator on the output of the vna to be able to measure the gain properly.\n## Gain meassurements:\nHere is the gain with the same components values as the 100MHz reference design:\n![[Pasted image 20230423190433.png]]\nI'm assuming this looks bad from terrible output matching. From a plain no-parasitic no-nonsense reading of the schematic the amplifier should have an output impedance of R2+R3 == 100R ish which doesn't sound so bad. So I will remove L2 and C5 from the schematic:\n![[Pasted image 20230423190948.png]]\nThis results in a gain of about 10dB at 900MHz. I added an additional 50R resistor on to the output and it dropped by about 4dB which indicates that in fact the output is in fact fairly well matched at this frequency. If the output impedance was far above 50R then it would drop by a lot, and if it was far below 50R (unlikely!) then it would drop below that. I think maybe I should be looking at the s21 phase at this point but not sure how to use that to come up with a complex output impedance.\nAdding loop wires to the output like I did with the input seems to make things quite a bit worse though.\nIdea: remove the negative feedback. That seemed to help a tiny bit but not much.\n# Design guide update\nAs usual I did not do a proper literature search. [Here](https://www.infineon.com/dgdl/Infineon-Design_guide_for_RF-transistors_and_diode_in_Low-Noise-Block-ApplicationNotes-v01_00-EN.pdf?fileId=8ac78c8c7e7124d1017f01f071aa5b8f) is a reference circuit for the exact transistor that I had:\n![[Pasted image 20230423201031.png]]\nIt's kind of gratifying to see that both I and they converged on not really having any specific impedance matching components. I also decreased R2 a bunch which is also good to see. Let's go ahead and switch out the components.\nThis is what I see (I gave up on using the attenuator):\n![[Pasted image 20230423205232.png]]\nAs opposed to app note:\n![[Pasted image 20230423205305.png]]\nGee, that's never happened before. \nOh wait it's probably compression from the VNA's high output amplitude. Setting 30dB of attenuation gets this:\n![[Pasted image 20230423205544.png]]\nWhich is much more reasonable, but also still only 10dB of gain. \nThat's enough for today I think. I don't know what to try next other than a different PCB layout, but I can't help but think that's not the problem.\n### Small experiment\nI tried measuring the gain with and without the supply decoupling cap and it made basically no difference. In retrospect this is not too surprising i suppose since there's an inductor in line with the collector of the transistor but still this is evidence I suppose that the current layout is bad.\n## Inductor quality\nIt's quite possible that the inductor I am using on the collector of the transistor (L1 above) does not do well at 900MHz. So I made some handwound ones. Here is a 100nH one:\n![[Pasted image 20230427204342.png]]\nBlue is handwound 150nH, normal is 30nH chip inductor.\n![[Pasted image 20230427211024.png]]\nSo the inductors do seem to get a bit squiggly around 900MHz. When I attach various handwound inductors from 0 to 150nH the gain changes a tiny bit (1dB?) but not really that much.\n\n## Conclusion\nEverything makes so little sense that I think I need to start from a known working example like an eval board. If even the most basic single transistor amplifier doesn't work something is very wrong. The infineon eval boards are all \"available on request\". Just give me the gerbers at least!!!\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230115-attenuator":{"title":"","content":"I purchased recently one of these\n[DYKB 1MHZ-3800MHz RF Digital Programmable RF Attenuator 0-31DB Adjustable Step 1dB PC Software Control FOR Spectrum Analyzer](https://www.aliexpress.us/item/3256802165268535.html?spm=a2g0o.order_list.order_list_main.27.645b1802EMwgHZ\u0026gatewayAdapt=glo2usa\u0026_randl_shipto=US)\n![[Pasted image 20230115182549.png]]\n\nLet's take a look at how good it is with the nanoVNA.\n\nTest range: 50kHz-1.5G.\n### 5dB\n![[Pasted image 20230115181917.png]]\n## 10dB\n![[Pasted image 20230115181943.png]]\n## 20dB\n![[Pasted image 20230115182025.png]]\n## 30dB\n![[Pasted image 20230115182054.png]]\n\nThe top line is reference 0dB attenuation going through the attenuator. It's wiggly I think mostly cause I didn't bother to do a proper cal.\nhere is 0dB through the attenuator vs a sma-sma straight passthrough:\n![[Pasted image 20230115182511.png]]","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230118-Bird-call-identification":{"title":"","content":"# Problem\nIt would be good to stick a recorder in a forest to monitor bird calls. That way you could get population density estimates and so on and so forth. There are [some existing](https://www.macaulaylibrary.org/2021/06/22/behind-the-scenes-of-sound-id-in-merlin/) approaches that do this already but they all require labelled data, which is pretty sparse and of course limits you to stuff you have already seen.\nThe question is whether or not you can train a system to be able to identify bird calls _without_ human labelled data. I think this might be possible. \n\n# Idea: Multiple Microphone Math\nThe overarching idea here is that by placing many microphones in a section of forest bird calls will be audible from multiple microphones and hence locatable in space and amplitude since the position of the microphones are known (think gps satellites in known locations solving for receivers in unknown locations).\nThis means that for a given call the microphones will receive bird call recordings that are a bit different in time, volume, and  background noise. However as the organiser of this system we know that the bird call recordings belong to the same bird making the same call. So whilst we don't know necessarily what the bird is in these recordings, we do know that it is the same one.\n\nNote that if there are fewer bird calls then there are microphones it's possible to solve uniquely for the location of the bird and extract the bird call itself from the other bird calls and background noise. This would help a great deal I think in creating clean recordings for training. \nOnce you have a large set of these clean recordings you can then easily simulate many bird calls at once by mixing your pristine recordings together to create a big synthetic bird chorous, and then train your net on this. Then you can go back to the real mucky bird chorouses and run the identification for real.\nYou'll need buckets of data for this I suspect, but that's exactly what a system like this is supposed to provide.\n\n## Problem: splitting recordings \nWhat gets recorded will of course be N streams of audio from the N microphones. This needs to be split into discrete chunks around bird calls. Undoubtedly this will require piles and piles of disgusting heuristics but once again our multiple receivers will help here. \nA proposal: find a loud identifiable bit of the recording via a simple threshold or something.  With all the microphones you can then locate this recording in space _and create a synthetic microphone that listens only to that point in space_. This is very cool but also understandably makes it much easier to tell when the call started and stopped since it solves the problem of the end of one call overlapping with the start of another that you don't really have any way to solve with a single microphone.\n#### 20230703 note\nMaybe what we want here is \"contrastive\" learning?\n\n## Problem: $crow_t == crow_{t+1}$ ??\nThe above notes show how to locate, separate and label a call that happens at a certain time by a certain bird. But it does not give insight as to how a bird that calls on two separate occasions gets  labelled the same thing both times. I do not know how to solve this. I think that with a sufficient number of examples it's pretty likely that different occurrences of the same call will end up in similar places in the embedding space, so maybe a traditional clustering algorithm could be used?\nThis is I think the biggest flaw with this method, though. I'm sure that there are many many examples of how to do this in the literature though since this problem is the same problem as identifying different pronounciations of the same word in a speech dataset, and there's loads of research one speech recognition.\n\n# More maths\n## Simplest case first\nLet me try and get down some problem statements first. Consider the simplest scenario: there is a single bird that sends a single pulse of sound to a bunch of microphones.\n\n![[Pasted image 20230119044226.png]]\nRemembering that distance is the same as time here what we observe in this case is that microphone $M_1$ hears something, then $M_2$, then $M_3$. So the input to our system/our observation is $[0, d_1 - d_2, d_1 - d_3]$. Call the microphone array $M = [M_1...M_3]$. Since we know the positions in M I do believe we are one linear equation away for writing down the location of the bird $B$ which one can solve in a least squares fashion in numpy.\nIf you write down the matrices in the right way you can just keep adding more $M$ and $B$ provided that $M$ is sufficiently bigger than $B$. I'm sure you could put down like 10 microphones in practice, so that's enough to get quite a few birdcalls. \n\n### How many birds?\nThe above is how to calculate where the birds are given how many of them exist, but not how many of them there are. I think you could do this iteratively by looking at how well the solution fits when you assume one bird, then two, then three etc. This will be greatly confused by bird calls with quite different volumes, and also by background noise.\n\n## More assumptions\n- When a bird is far away it might be audible to only a subset of the microphones.\n- Do birds call whilst moving?\n- The positional accuracy here prolly won't be that great what with all the trees and stuff. So birds that are close together will cause problems.\n- Perhaps real recordings just have so many sources all the time that it's hard to get enough single-call data to train on. ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230122-Pneumatic-resin-valves":{"title":"","content":"# Background: underlay+overlay\nA common process in biology is something called an \"underlay\" (or its cousin the overlay). This is  a process of separating cells from other gunk by density. This is done like so:\n![[Pasted image 20230129181721.png]]\nSay the  cells are density x and the surrounding garbage   is all significantly higher or lower density. by having  two fluids sitting on top of each other and then centrifuging hard for a long time, the cells will float to the _middle_ of the tube, where they can be collected. \nSetting this up is a tedious, time consuming and manual process  that is prone to error. For an underlay, you first fill the tube halfway with fluid density $x - \\Delta$,  gently insert a pipette  to the bottom of the  tube, and sloooowly inject the fluid of density $x+\\Delta$. You do the reverse with an overlay, which a lot of people prefer. $\\Delta$ is very small. Idk how small, but small.\nThis seems to  me to be a process that could be automated fairly easily. Some nice flow control  on a pump and a barometer to sense fluid levels should be all that's required I would think.\n\n# Valves and such\nI have acquired a resin printer (elegoo mars) and so am now  capable of printing airtight structures  with tubes and such going through them. This should be perfect for the job. The first thing I did was print up a very simple manifold that directed the air around so I could either pump air in or  out of a pipette. That looked like  this:\n![[Pasted image 20230129182329.png]]\nWhich had the following circuit diagram:\n![[Pasted image 20230129182532.png]]\nWhere green are  hoses and purple is the thing that I printed. That worked well, but had loads of hoses going all over  the place. What I really want is a single block of printed stuff that I attach moving bits to that then does the  job flawlessly. \nThe first step in achieving this goal is to make some  printable valves. Here is  what I came up with:\n![[Pasted image 20230129183002.png]]\nThe air wants to flow from left to right from the red to the orange channel. But it can't because the rubber sheet (light blue) is being pressed down over the junction by a  solenoid (dark blue).\nIn CAD it looks like this:\n Top view | Side view\n:-----------------------:|:--------------------------:\n![[Pasted image 20230129183223.png\\|200]]  |  ![[Pasted image 20230129183710.png\\|200]]\n![[Pasted image 20230129183836.png|400]]\n\n![[Pasted image 20230129183856.png]]\nAnd it works!\nhttps://photos.app.goo.gl/qWQjEG1SU8D5AsPk7\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230129-Bang1-bringup":{"title":"","content":"Schematic:\n![[Pasted image 20230129184412.png]]\n\nIt seems that  the FET drive has a lot of ringing. Probing R2: \n![[Pasted image 20230129184447.png]]\nI added a 10R resistor and this helped.\n\nThe next step was to debug for a long long time and then realise I hadn't connected all my grounds together in the layout. Oops. After that I get this:\n![[Pasted image 20230201181734.png]]\nGreen: input\nYellow: top side of thin (~50um, 20mm) wire.\nRef: bottom side of said wire.\nVCC is 32V here.\nTime to crank up the volts.\n---\nI believe the main problem that I am having here is that my capacitor is garbage. I have ordered some more.","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230129-DIY-resin-printer-PCB":{"title":"","content":"# Idea\nResin printers are nothing but and LCD screen with a UV printer behind it. So why not use the LCD screen to expose some PCB's? [Some other people](https://www.youtube.com/watch?v=RudStbSApdE) have tried this already so it isn't new, but it would be pretty handy to be able to get a new pcb in \u003c1hr. \n\n# Implementation\n## Workflow\nThere are a few tutorials on the internet on how to do this, but they all involve tedious manual tasks like exporting to blender etc etc. I am pretty sure that the file format that the printer itself  accepts is a bunch of images, and a gerber file is basically an image, so why can't I go directly?\nI found [A great guide](https://github.com/cbiffle/catibo/blob/master/doc/cbddlp-ctb.adoc) on the internet written in rust with good documentation (apparently this person is the same person that founded loon) and indeed, this is what the file format is. \nMy code to convert the  svg output from kicad to the cbddlp file is [here](https://github.com/Oscilllator/Resin-printer-pcb/blob/main/print_info.py). \nI bought some presensitized PCB panels from amazon [here](https://www.amazon.com/dp/B01N5W07AM?psc=1\u0026ref=ppx_yo2ov_dt_b_product_details).\n\n## Chemicals\nThe basic process was expose-\u003eNaOH wash-\u003eHCl+H2O2 wash.\nIt took quite a few tries to dial in the process. In particular the exposure time and NaOH concentration took a while to dial  in. I ended up putting in half spoonfuls of NaOH to gradually increase the concentration (and I think  it still could be a little higher) and so unfortunately I don't have a proper number. But in the end I got good results. Here is an image of the washing:\n![[Pasted image 20230129175756.png|400]]\nAnd an image of  the etched results:\n Before removing photoresist | The final PCB\n:-----------------------:|:--------------------------:\n![[Pasted image 20230129175950.png\\|400]]  |  ![[Pasted image 20230129180146.png\\|400]]\n\nZooming in, let's  take a look at the resolution vs what the printer tried to  put out:\n LCD printer image | The final PCB\n:-----------------------:|:--------------------------:\n![[Pasted image 20230129180340.png\\|200]]  |  ![[Pasted image 20230129180440.png\\|200]]\nYou can just barely see here that  the gap at the top of the \"a\" here is 1 pixel wide, and there is just barely a gap at  the top of the a in the printed product. That makes it basically pixel perfect!\nThe assembled PCB:\n![[Pasted image 20230129180807.png]]\nSuccess!\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230204-x-ray-spectroscopy":{"title":"","content":"# Background\nIn biology there is currently (to my knowlege) no way to track the position of a certain cell type in the body of an animal live.\nPeople often detect the presence of a certain cell via the general method of finding an antibody that attaches to that cell, and then attaching something to the antibody. Much of the time people attach something fluorescent, or something that changes color, or even sometimes a heavy metal to the antibody. This works well once you have extracted the tissue and you want to measure the concentration of the cells. \n\n# Idea\nPut some heavy-metal attached antibodies into a mouse or other organism. Then bombard the mouse with hella x-rays so that the heavy metal atoms emit their own characteristic x-rays, that are then picked up by a detector. \nThis will give you a signal proportional to the amount of heavy metal atoms in the beam. But it will not of course tell you where the atoms were located. I think using some kind of vision system combined with knowledge about the x-ray beam profile alongside the pose of the mouse should help here. Either the mouse or the x-ray beam need to move around a bunch in order to get good sampling of the location of the atoms within the mouse.\nI don't imagine it would be possible to get spatial resolution much better than a mm or two, enough to localise to an organ but not any better than that.\n\n# Constraints\nThe total number of heavy metal atoms in the mouse will be very small since only one (or a few?) atoms will be attached to each antibody, and an antibody has an enormous atomic mass ([150e3 atomic mass units](https://www.ncbi.nlm.nih.gov/books/NBK27144/#:~:text=IgG%20antibodies%20are%20large%20molecules,3.2)). This means that a lead atom with a weight of 207 will comprise 207/150e3 = 0.1% of an antibody already. That's before you even inject it into the mouse and dilute it again.\nSo it seems very unlikely that there will be enough signal, but I suppose it's worth figuring it out.\nIf we can find a wavelength of x-ray that water is extremely transparent to but some other element is extremely opaque to, then this might work out I suppose.\n\n## Calculations\n[NIST](https://physics.nist.gov/PhysRefData/XrayMassCoef/tab3.html) has a great table of x-ray attenuation coefficients as a function of material and of x ray energy. \nFor a given element E we can take the ratio of the element absorbtion spectrum / water absorbtion spectrum, then take the max of that array. If that ratio is something _huge_ like 1e6 then maybe we can say that the mouse is transparent enough to the x-ray and the element is opaque enough that we will get a signal.\n\n### Uranium / water\nMice are mostly made out of water, and it seems that the heavier the element the better. So let's do uranium vs water. Here is a plot of the energy absorbtion coefficients of water an a couple of elements spread over the periodic table:\n![[Pasted image 20230204135512.png]]\nAnd the ratio of uranium and water:\n![[Pasted image 20230204123703.png]]\n\n## How many x-rays to kill a mouse?\nApparently [4-5 Sieverts](https://www.nrc.gov/reading-rm/basic-ref/glossary/lethal-dose-ld.html). A sievert is 1J/kg scaled by some factor. Fortunately for photons, [that factor is 1](https://www.ccohs.ca/oshanswers/phys_agents/ionizing.html). \nA mouse weighs about 20g. Let's say we are using the photon energy of 0.05MeV = 0.05 / 1.60218e-13 = 312e12 photons to kill the mouse.\n## How many uranium atoms in the mouse?\nLet's say there is 1 uranium atom per antibody. How many antibodies can attach to the surface of a b cell?\n![[Pasted image 20230204141831.png]]\n^This is the best answer I could find. Call it 10. Prolly ChatGPT isn't that wrong.\nLet's say we want to track B cells. How many B cells are there in a mouse?\nApparently there are [about 0.5e9](https://assets.thermofisher.com/TFS-Assets/LSG/brochures/I-076357%20cell%20count%20table%20topp_WEB.pdf) B cells/L in blood. Let's say that a mouse [has 2ml](https://www.ksvdl.org/resources/news/diagnostic_insights_for_technicians/october2015/blood-collection-in-mouse.html) of blood. So that's 0.002 * 0.5e9 = 1e6 B cells. Or 1e7 Uranium atoms. Approximating a mouse to be 0% uranium, that's equivalent to 1e7 * 220 = 2.2e9 water-equivalent atoms (maybe, we might be out by a factor of uranium density / water density here).\nIf a mouse is all water there is basically 1 mole of water molecules in it, or 6e23 molecules. So that means that 312e12 * (2.2e9 / 6e23) = 1.1 photons will be absorbed by all the uranium in  the mouses body in the time it takes to kill the mouse. Don't you just love it when the numbers work out so neatly?\n\n## How many photons would we need?\nI don't really know how to calculate this but I think I can put a reasonable lower bound. Suppose you wanted to detect the concentration of the stuff in the mouse to 0.1mm, and a mouse is 20^(1/3) = 2.7cm on a side. that means a mouse is made from  (27/0.1)^3 = 20e6 voxels. You are most definitely going to want to measure a bunch of photons per voxel (it's not so straightforward to locate a measured photon to a voxel), so it seems unlikely that  you could do this with less than 1e8 photons.\n\n# Conclusion\n1 != 1e8\n\nI guess this explains why people inject many grams of contrast when doing CT scans and suchlike.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230216-strobe-camera":{"title":"","content":"# Idea\nI would like to 3d print some propellers. Propellers have a tendency to flap about, so it would be good to film them to see if that's happening. But you can't do that with a regular camera.\nSolution: a strobe camera. I have a realsense camera D435i that has a strobe input, so that combined with a flashy LED thing should get me what I need. \n![[Pasted image 20230216190150.png]]\n# Flashy bit\nI tried to [[20230129 DIY resin printer  PCB|Make some more pcbs]] but it seems the developer solution has gone off so I went and found MikesElectricStuff's guide on pcbs and bought some sodium silicate. In the meantime I will use the [[20230129 Bang1 bringup|Bang1]] circuit to drive my COB LED like so:\n![[Pasted image 20230216190506.png]]\nWe can see that the strobing is working rather well!\nHere is a more quantified measurement of the light output:\n![[Pasted image 20230216190624.png]]\nGreen = pulse trigger. Red = drain of the FET. Yellow: 1k resistor from 5v biased photodiode to ground.\n## Output\nHere is an image of a propeller spinning at 50Hz or so:\n![[Pasted image 20230217203039.png]]\nThe bars are cause there were a couple of strobes over the camera exposure time (phone camera). \n\n# Measuring\nThe next step is to bounce a laser off the propeller and measure what comes back to phase lock tothe propeller. I had the brilliant idea to use a solar panel instead of a photodiode for that phat detection area, no lens required. \nHere is my detection circuit:\n![[Pasted image 20230217203339.png]]\nand irl:\n\nOnly one problem: It's a nice 90MHz oscillator:\n![[Pasted image 20230217203540.png]]\nThis oscillation seems dependent on the ambient light level and also the supply voltage. On further inspection this is cause I attached the cathode of the solar panel to the collector of the transistor. Also, it seems that there is a fair bit more sensitivity if you just attach the solar panel anode to ground and cathode to the base of the transistor. Maybe solar panels aren't photodiodes after all?\n\n\n## Wait\nActually this whole idea is dumb. Since I have my own test setup I can just point the light from one side of the propeller to the other. Or stick a retroreflector on the ceiling, or something.\n\n# PCB setup\nHere is what I came up with:\n![[Pasted image 20230304131630.png]]\n![[Pasted image 20230304132013.png]]\nTad bit of trouble getting things up and running but it's going nicely now. The photodiode is the rectangle being shielded by the copper tape from the light coming from the LED.\nResults are looking good. Pretty hard to photograph. Quick calcs about how long to make the pulse. let's say we want 0.1mm of blurring. Prop radius = 80mm =\u003e circumference 500mm. Prop goes past every 8ms. so we want an exposure time of 0.1 / 500 * 8 = 1.6us. That's pretty short! I have the fpga emitting a 5us pulse and that results in this waveform:\n![[Pasted image 20230304165516.png]]\nyellow = MOSFET drain, Pink = optical propeller detector, Blue = MOSFET gate, Green = FPGA trigger out.\nSo unless I want to mess about with the driving circuit this is about as good as it's going to get I think. Should keep an eye on the Yuge spike in the supply voltage too.\n\n![[output 1.mp4]]\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230305-verilog-knob":{"title":"","content":"## Problem \nI want a knob that I can twiddle in my FPGA design to adjust a constant. But I don't want to wire up some kind of digital potentiometer or encoder or anysuch garbage\n## Solution: capacitor + resistor + inout\nThe circuit:\n![[Pasted image 20230305164801.png]]\nWe'll get the FPGA to charge a capacitor through a variable resistor and measure how long that takes. Then we discharge the capacitor quickly through the measuring port and repeat the process.\n### Verilog\nThe code is this simple:\n```\nmodule usr_knob (\n    input clk,\n    inout gpio_drv,\n    inout gpio_meas,\n    output reg [63:0] period_out,\n);\n    parameter MEASURING = 1'b0;\n    parameter DISCHARGING = 1'b1;\n    reg [1:0] state;\n    reg [63:0] period_meas;\n\n    assign gpio_meas = (state == MEASURING) ? 1'bz      : 1'b0;\n    wire in_meas = (state == MEASURING)     ? gpio_meas : 1'b0;\n    assign gpio_drv = (state == MEASURING)  ? 1'b1      : 1'bz;\n    wire in_drv = (state == MEASURING)      ? 1'b1      : gpio_drv;\n\n    always @(posedge clk) begin\n        case(state)\n            MEASURING: begin\n                if (in_meas) begin\n                    period_meas \u003c= 0;\n                    period_out \u003c= period_meas;\n                    state \u003c= DISCHARGING;\n                end else begin\n                    period_meas \u003c= period_meas + 1;\n                end\n            end\n            DISCHARGING: begin\n                // Once the capacitor has been discharged we reset the state:\n                if (!in_drv) begin\n                    state \u003c= MEASURING;\n                end\n            end\n        endcase\n    end\nendmodule\n```\nThe results look like this:\n### Analog\nThe driving pin looks like this:\n![[Pasted image 20230305165321.png]]\nand the capacitor node looks like this:\n![[Pasted image 20230305165415.png]]\nWorks with a frequency range of 16kHz-1.5MHz. Nice! The 16kHz frequency has a jitter of about 600ns. Seems pretty good to me and might be comparable with the oscillator jitter itself, if I bothered to measure.\n\n# Analog meets digital\nInterestingly when I connect this circuit to other stuff in the fpga to actually do something useful, the jitter increases _enormously_:\n![[Pasted image 20230307200708.png]]\nlike 10us of jitter!\nAll I did was hook it up to a counter like so:\n```\n\n    reg [63:0] usr_knob_period; \n    usr_knob usr_knob_instance(\n        .clk(clk48),\n        .gpio_drv(usr_knob_drv),\n        .gpio_meas(usr_knob_meas),\n        .period_out(usr_knob_period),\n        .state_(rgb_led0_b)\n    );\n    assign led_strobe = rgb_led0_b;\n\n    reg [63:0] wave_generated;\n    wire wave_reference = wave_generated \u003e= usr_knob_period;\n    counter_64bit rate_generator(\n        .clk(clk48),\n        .out_value(wave_generated),\n        .reset(wave_reference)\n    );\n    assign pulse_out = wave_reference;\n```\nthe interaction between the two modules is through the usr_knob_period variable. So I thought that if I could mutate the variable in between the two modules, then they wouldn't be hooked up directly any more and wouldn't interact directly. Adding 1 to the `usr_knob_period` doesn't help, but multiplying it does! not enough to solve the problem, but a fair bit.\n\n## Metastability??\nApparently this is a thing, and it affects fpgas and me in particular. When sampling an incoming signal that is not synchronous with the clock you must sync it up first. [handy diagram](https://nandland.com/lesson-13-metastability/):\n![[Pasted image 20230313210816.png]]\nThe adjusted code:\n```\n...\n    assign gpio_meas = (state == MEASURING) ? 1'bz      : 1'b0;\n    wire in_meas_raw = (state == MEASURING)     ? gpio_meas : 1'b0;\n    assign gpio_drv = (state == MEASURING)  ? 1'b1      : 1'bz;\n    wire in_drv_raw = (state == MEASURING)      ? 1'b1      : gpio_drv;\n\n    reg in_meas_metastable;\n    reg in_drv_metastable;\n    reg in_meas;\n    reg in_drv;\n    always @(posedge clk) begin\n        in_meas_metastable \u003c= in_meas_raw;\n        in_drv_metastable \u003c= in_drv_raw;\n        in_meas \u003c= in_meas_metastable;\n        in_drv \u003c= in_drv_metastable;\n...cont\n```\nThis should just delay things by a couple clock cycles but not affect the program otherwise.\nHere is a histogram of when the edges occur for the default user knob with nothing attached to it (blue), the knob with an output attached (orange, and the aforementioned high jitter), and a knob with an output attached and also input latching (green):\n![[Pasted image 20230313213623.png]]\nLooks like adding in the metastability stuff didn't have much effect other than slowing down the period. I am surprised that it was slowed down by that much, but there you go.\n\n### TL;DR\nJust like ESD and reinterpret_casts, you don't need to worry about metastability.\n\n\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230311-Astable-multivibrator":{"title":"","content":"Following along from [[20230305 verilog knob]] it would seem like a good idea to generate a variable frequency without using the fpga at all. Blindly copying a nice guide [here](https://www.electronics-tutorials.ws/waveforms/astable.html) I end up with this:\n![[Pasted image 20230311201701.png]]\n![[Pasted image 20230311201715.png]]\nIt turns out that the waveform at the gate is actually a bit higher amplitude and nicer:\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230319-wakeuplight-v3":{"title":"","content":"I need a light to wake me up since daylight savings mean the sun isn't doing a good job. I've been getting some great mileage out of my LED driving circuit. Here it is again:\n\n![[Pasted image 20230319112415.png]]\n\nOnly thing of note here is that I changed R3/R7 to 100R for smaller minimum pulse widths, as it's important that the LED has a really low minimum brightness.\nI also made one using a FET driver but it didn't arrive on time:\n\n![[Pasted image 20230319112523.png]]\n\nAnd of course the circuit is reverse polarity protected:\n\n![[Pasted image 20230319112547.png]]\n\nI also have a [Yuuuge LED](https://store.yujiintl.com/products/cri-max-cri-95-150w-high-bay-ufo-led-light-4000k-5000k) that takes a 0-10V analog input to control it. The minimum brightness is too high for a wakeup light but I would still like to be able to control it from the pi, so this circuit is in order:\n![[Pasted image 20230319113615.png]]\n\n..OK maybe I shouldn't popular R13 like that.But the circuit works well. ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230320-Glucose-meter-review":{"title":"","content":"","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230325-Thrust-stand":{"title":"","content":"# Goal\nI would like to build a drone that has a long flight time, ideally like 1hr. Also it should be small (\u003c500g)\n## Tradeoffs\nThe most efficient propeller is one that is large and spins slowly. The most efficient Motor is one that spins very fast.\nThese are in tension, and so what you want for a hovering drone is a large propeller with low pitch. \nThe practical limit on how low would be the minimum of (propeller tensile strength, increased parasitic drag as result of high tip velocity, flutter and suchlike).\nPerhaps it is possible to print and measure some 3d printed propellers. This post is about measuing propellers.\n\n# Hardware\nThe thrust stand is very simple and looks like this:\n![[Pasted image 20230325172939.png]]\n\nA regular 1kg load cell attached to one of those HX711 things attached to a esp8266 that spews out the raw load cell data.\n## Current measurement\n\n^8e3601\n\nThe only way I could rig up current (and thus power) measurement was to query my Hantek PPS2320A. Unfortunately the serial interface is utter trash. The serial link is 9600 baud only and drops packets all the time. The current measurement updates at like 1Hz and takes several seconds to settle. So the resulting data has to be heavily filtered to remove all the jank.\nI have ordered some current sensors which should help out a lot when they arrive.\n\n# Calibration\nThe 24 bit ADC in the strain gauge measurement chip has no calibration or notion of any weight, so I had to do that bit myself. Pretty easy though, just put a bunch of weights on a kitchen scale across the strain gauge range. Results looks like this:\n![[Pasted image 20230326113708.png]]\nI'm pretty sure most of the error in the low range is just my shoddy measuring technique but whatevs, it's more than good enough.\nFeaturing an 800g weight:\n\n![[Pasted image 20230326113837.png]]\n\n\n## Raw data\nTo collect the data I just recorded the current and thrust over time while twiddling a servo tester knob to get different thrust levels. Here is the raw data as a function of time:\n![[Pasted image 20230326111901.png]]\n\nEvery time there is a gap in the data followed by a drop in the power supply measurement is a dropped uart transaction from the power supply.\nAs a scatter graph of efficiency (blue: raw, red: filtered):\n![[Pasted image 20230326112427.png]]\n\nDisgusting. Getting rid of all the garbage and judiciously cropping the y axis it looks like this:\n\n![[Pasted image 20230326112551.png]]\nMuch better!\nHere is what a normal efficiency curve looks like:\n\n![[Pasted image 20230326112943.png]]\n\nSo this is more or less in line with that. The \u003e10g/w efficiency number is pretty good, too. \nThis data was taken with an 8040 propeller at 8V motor voltage. The [manufacturers data](https://sunnyskyusa.com/products/sunnysky-x2204-brushless-motors) looks like this:\n\n![[Pasted image 20230326113215.png]]\n\nI have no idea how I managed to beat the manufacturer efficiency ratings. I did not bother to subtract the weight of the motor + propeller for my calculations but I doubt that's it.\nRegardless, with my current calculated weight of ~370g for the drone this actually works out to bang on 60 mins hover flight time. Pretty noice if you ask me. The max thrust is a little low though cause it works out to a 2.7:1 ratio. Would be nice to see if we could get that up to like 4, we shall see how adding a bigger propeller helps with that.\n\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230403-Laser-googles":{"title":"","content":"I bought some laser google off aliexpress but who knows if they are any good.\n\nHere is an image from a realsense d435i, which has no ir filter and also a 16 bit grayscale output:\n![[Pasted image 20230403203351.png]]\n\n## Laser off, no googles:\nImage is totally black, value of about 0x1400\n\n# Laser on, no googles:\nWith the camera gain at 0 I adjusted things to be just before saturating:\nThis is with a laser current of 10mA. Note that the threshold current for this laser is 600mA and so this will be mostly stimulated emission. Still mostly the right wavelength though I would think.\n![[Pasted image 20230403192233.png]]\n\n## Laser on, googles:\nThe image is totally black with the goggles in front. Turning the gain from minimum to 248 gets the laser to the point where it is juuust barely detectable if you turn off the power supply. Prolly ~100 magic sensor counts. Fun fact: if you turn a Hantek PPX2320 off and on a bunch abesntmindedly it might change the voltage and currents to maximum (31V/3A) and then the next time you turn it on it will apply that to your 10W laser diode, making the tip of the fiber catch on fire. Oops. Probs should have had another layer of safety on that one. Should have learnt my lesson on the firmware quality from how it applies 5V to the 1.8V line and has a [[20230325 Thrust stand#^8e3601|Garbage]] current measurement feature.\nBallpark estimate though is that it attenuates the light by (65536 / 100) * 248 = 1e5 which given the egregiously bad testing is in line with the claimed OD6+.\nNonetheless I think I need a second line of defence to be doing anything properly eyedangerous here.\n","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230408-Drone-FW-garbage":{"title":"","content":"\nTrying to set up a drone and there are way too many things:\n\n- Betaflight - Firmware that runs on the flight controller itself to control escs etc.\n- OpenTx - Firmware that runs on the handheld transmitter\n- ExpressLRS - wireless protocol used between flight controller and handheld transmitter\n- ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230507-Simulation":{"title":"","content":"# Idea \n## Justification\nSo far nobody seems to know about how to make an enzyme from scratch that achieves a given task. Being able to do this is one of those \"duh, worth trillions\" ideas so presumably people are working on it. But there don't seem to be that many.\nThere do seem to be pieces scattered about that form part of the solution though. There's that one protein folding paper, of course. But there have also been many examples of the use of NN's to perform physics simulations which seems to me to be a highly understudied area. \n## Approach\nIt seems like a fairly obvious idea to me that one could create a net that was capable of quite good high level chemistry simulations via doing something like this:\n- Get a lot of small-scale but accurate data (e.g. burning methane) using existing simulations. Then you could train a net on these small sections in such a way that it scaled better to larger simulations, since one of the problems with existing simulations is the scaling laws that they follow (e.g. N body simulation naively grows with N^2, but it's obvious it doesn't have to really) and one of the things that neural nets can be good at is paying _attention_ to stuff that is important.\n- Such a neural net might be good at small stuff but it would presumable fail on something larger. I analogise this to a pretrained LLM that's good at nitty gritty but lacks directedness. The analogy is not really that good though. \n- So then one could then train it on larger datasets. Even telling it \"This protein here is an enormous molecule but it's stable. Stop predicting that it catches fire\" would probably help a fair bit.\n- This is where the unclear and hard parts come in. I don't know how good existing datasets cover the functioning of enzymes, or how one would train such a thing. You would have to explain to the net that \"carboxylic acid just sits here but carboxylic acid + enzyme gets reduced to aldehyde\". Where \"enzyme\" is expressed as the actual structure of the enzyme, not just the sequence.\n## Possibility\nFundamentally I just don't think that the operation of enzymes are that complicated. A typical enzyme has like 10k-100k atoms in it. You would probably need to simulate a total of 1e6 atoms or so to cover the environment the enzyme is in and stuff but the interactions between atoms are not that complicated in the informational sense - the number of bytes required to write down the physics equations that describe chemical reactions is not large, it's just tremendously nonlinear.\nSo I think a device that can do like 1e12 operations per second could probably crank out some good simulations of this stuff. If you needed to simulate like 1e6 enzymes to find the one that worked then I think things would start to get infeasible, but that's not really how modern NN's work - ChatGPT does not search millions of sentences to output, it just outputs one. \n## Architecture\nIt's clear though that great care is going to need to be put into the architecture of the net. In particular because the whole point of this net is computational efficiency (not something nets are known for), the net is going to need to learn to rearrange the internal data structure to fit its needs. It will have to be able to move the weights for adjacent atoms next to each other and then _not even perform calculations_ on far away atoms, or at least do so at some aggregate level. There's no other way to avoid this N^2 scaling behaviour. I just went and watched karparty's GPT lectures to try and find out exactly how this attention mechanism works. It's not totally clear to me but it seems the main way is that the \"attention\" is done via applying different weights to different sections of the data rather than actually fetching different parts of the data. If that's the case it won't work for this situation since 0\\*0 takes the same number of flops as 3\\*4, although only the latter is useful.\nAgain, the necessity and utility of this data fetching approach is obvious. So it either already exists, or is hard to make. So one of the first things to discover is how feasible it is.\n### Keep the bitter lesson in mind\nThinking about this stuff there are already a whole bunch of weirdo index fetching frankenstein hand tuned architectures that are coming to mind. I need to make sure not to spend too much time trying to implement them - The history of neural nets is the history of \"gpu go brrrr\", and I need to respect that. Having learned efficiency seems like it could be a huge win, though.\n\n# Trivial example: n body simulation\nI know that people have already done this before, but I think that a good first step would be training a model to simulate N body graviational physics. \n- It's easy to make such a simulation. F = Gmm/r^2 bro.\n- It has N^2 scaling when you add more bodies. A naive gpu simulation takes 70ms to simulate one 5k body timestep using pytorch.\n- If you look at the simulation by eye you can tell if it's egregiously wrong. e.g. if you make a cloud of spinny stuff it should orbit.\nSo if  I can't get this to work in a reasonable amount of time I should probably just give up. From there we can work up to something more complicated - I imagine just wrangling the datasets and simulation stuff for small molecule simulations is pretty complicated so this is a good sanity check I think.\n\n## Small aside: ChatGPT is great for this stuff\nI have never used pytorch before. So having all the syntax explained and predicted is a huge help here. I don't think it would be worth doing this project without it, it would just take me too long to futz about looking at docs and stuff. Same goes with doing visualizations - I have used pyqtgraph before a bunch but getting a net to write out all the API stuff is a performance boost on the order of 2-10x. If you know what you want the code to look like, but just don't know the magic incantation to get it to work, LLM's are brilliant.\n\n\n# After actually googling stuff\n\nPeople have definitely been looking at this but it seems my central point about nobody having actually achieved it is correct. \n\n#### Large language models generate functional protein sequences across diverse families\nThis paper seems to have gotten the furthest. They actually synthesised the proteins they generated, but their goal seemed to be \"generate protein that does a previously-known task with a different sequence\".\n\n\n\n## Ideas for specfic enzymes\n- Carbon nanotube polymerase\n- Light + H2O -\u003e O2 + H2\n- ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230604-N-body-particulars":{"title":"","content":"# N body simulation: Basics\nWe all know this, $F = GM_1M_2/r^2$  right? Here it is implemented in pytorch in a batched fashion:\n```python\n\n# def n_body_step(state: torch.Tensor, G: float = 6.674e-11, dt: float = 1e-3):\ndef n_body_step(state: torch.Tensor, G: float = 10, dt: float = TIMESTEP):\n    add_batch_dim = True if len(state.shape) == 2 else False\n    if add_batch_dim:\n        state = state.unsqueeze(0)\n\n    assert len(state.shape) == 3\n    assert state.shape[-1] == NUM_STATES\n\n    # state is a B * N * 5 batched tensor of masses, positions, and velocities.\n    # dt is the time step\n    N = state.shape[1]\n    x_diff = (state[:, :, X_IDX].unsqueeze(-2) - state[:, :, X_IDX].unsqueeze(-1))  # B * N * N\n    y_diff = (state[:, :, Y_IDX].unsqueeze(-2) - state[:, :, Y_IDX].unsqueeze(-1))  # B * N * N\n    x_diff_sq = x_diff ** 2 # B * N * N\n    y_diff_sq = y_diff ** 2 # B * N * N\n    range_ = torch.sqrt(x_diff_sq + y_diff_sq)\n    inv_range_sq = 1 / (x_diff_sq + y_diff_sq)\n    # mask out self-interactions without using multiplication because that gives nans:\n    inv_range_sq = inv_range_sq.masked_fill(torch.eye(N, dtype=torch.bool), 0)\n\n    accel_mag = 0.5 * G * state[:, :, M_IDX].unsqueeze(-1) * inv_range_sq\n\n    # We need to find the direction of the acceleration:\n    direction_vec = torch.stack([\n        (x_diff / range_),\n        (y_diff / range_),\n    ], dim=1)  # 2 * N * N\n    direction_vec = direction_vec.masked_fill(torch.eye(N, dtype=torch.bool).unsqueeze(0).unsqueeze(0), 0)\n    accel = accel_mag.unsqueeze(1) * direction_vec\n    accel = accel.sum(dim=-2)  # B * 2 * N\n    accel = -accel.transpose(-1, -2)  # B * N * 2\n\n    # update velocities:\n    state[:, :, 3:5] += dt * accel\n    # update positions:\n    state[:, :, 1:3] += dt * state[:, :, 3:5]\n    state[:, :, 5:7] = accel\n\n    if add_batch_dim:\n        state = state.squeeze(0)\n    return  state\n```\nThis works pretty well, apart from the one small problem that when two objects are close together terrible floating point things happen and they fly off. I figure instead of doing this they should seamlessly pass through each other when interacting. To do this I calculate whether or not the distance from one object to another is comparable to the amount that it would be accelerated by in one timestep. If it is, then the acceleration should be 0 instead. Here is the accelleration code:\n```python\n    # Derate the acceleration if the objects are too close:\n    expected_movement = (0.5 * accel_mag * dt ** 2) / (1e-9 + range_)\n    accel_derating = 1/(torch.exp((100 * expected_movement)**2))\n    accel_mag *= accel_derating\n```\nWhich looks like this if you plot it:\n![[Pasted image 20230604181515.png]]\n## Results\nHere is a visualisation (Thanks ChatGPT) of what the population statistics look like before this derating is put in:\n![[Pasted image 20230604181713.png]]\nAnd after:\n![[Pasted image 20230604181802.png]]\nRather dramatic, wouldn't you say?\nThis seems to have a fairly large effect on training, especially if you use something like a mean _squared_ error loss, like I was.\n\n### Small aside: fiddling with this made the simulation look a lot better:\n![[Screencast from 06-04-2023 065602 PM.webm]]\n\n## Noisy noisy results\nHere are the results trianing for a bit with a batch size of 1, using L1 loss:\n![[Pasted image 20230604182419.png]]\n2+ orders of magnitude differences in the error rates seems kinda high, no? When I use a batch size of 1000, I get this:\n![[Pasted image 20230604182649.png]]\nWhich looks significantly more intelligble to me. There is a [paper](https://arxiv.org/abs/2002.09405) which I have read all the way through and downloaded the source code for etc, and one of the things that they did was actually train the net to predict only the accelerations, then use a simple $x_{t+1} = x_t + v\\Delta t + 1/2 a\\Delta t^2$ to actually calculate the positions. This intuitively makes sense here because it is indeed the forces on the particles that we are actually trying to calculate, but it also does not make sense to me because if you look at the statistics of the accelerations above, the acceleration is extremely high variance. Maybe we should try and predict the log of the acceleration?\nHere is the training loss predicting acceleration with L1 loss (note x axis):\n![[Pasted image 20230604183224.png]]\n...Not very good, as you might think.\n## Predicting log(acceleration)\nLet's make the net try to predict log2(accel.abs() + 1). \nThe augmentation looks like this:\n```python\n        timesteps = torch.randint(0, num_timesteps - 1, (batch_size,))\n        trajectories = torch.randint(0, num_trajectories, (batch_size,))\n        data_start = dataset[timesteps, trajectories, :, :].squeeze().clone()\n        data_end = dataset[timesteps + 1, trajectories, :, :].squeeze().clone()\n        data_start[:, :, -2:] = torch.log2(data_start[:, :, -2:].abs() + 1)\n        data_end[:, :, -2:] = torch.log2(data_end[:, :, -2:].abs() + 1)\n\n        out = model(data_start)\n\n        loss = F.l1_loss(out[-2:], data_end[-2:])\n```\nThe histogram looks like this:\n![[Pasted image 20230604183752.png]]\nWhich seems wayyyy nicer.\nThe results looks like this:\n![[Pasted image 20230604184342.png]]\n...Which seems a bit better, maybe? It obviously trained a bunch more but we are kinda taking the log of the loss here, so I'm not that impressed. It does seem to be learning though so bumping up the batch size to 10k we get this:\n![[Pasted image 20230604184238.png]]\n...Doesn't seem to be much gain from increasing the batch size 10x.\n\n## Sanity check: Cheat\nPerhaps the reason this is all going so poorly is there is some kind of horrific bug. Perhaps I have forgotten to torch.zero_grad? or switched the desired and predicted in the loss? So to see if that is the case, I concatenated the desired state as an input to the net to see if it could learn to do a passthrough OK.\n```python\ndef forward(self, x):\n    orig_shape = x.shape\n    x_next = nbody.n_body_step(x)  # calculate the desired state\n    x = x.reshape(x.shape[0], -1)\n    x_next = x_next.reshape(x.shape)\n\n    x = torch.cat([x, x_next], dim=-1)  # Add the desired output to input\n    x = self.act(self.input_conv(x))  # All this nonsens just has to do a passthrough.\n    x = self.act(self.hidden_conv1(x))\n    x = self.act(self.hidden_conv2(x))\n    x = self.output_conv(x)\n    return x.reshape(orig_shape)\n```\n![[Pasted image 20230604185129.png]]\n...So that's not the problem, then.\n\n## \"Quick\" experiment: maybe we just need more flops?\nEveryone knows that nets take lots of compute to train. So I trained this net:\n```python\nclass NbodyManual(torch.nn.Module):\n    def __init__(self, num_features: int):\n        super().__init__()\n        hidden_size = 100\n        expansion = 2\n        self.input_conv = Linear(num_features * expansion, hidden_size)\n        self.hidden_conv1 = Linear(hidden_size, hidden_size)\n        self.hidden_conv2 = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, num_features) \n        self.act = ReLU()\n\n    def forward(self, x):\n        orig_shape = x.shape\n        if x.ndim == 2:\n            x_next = nbody.n_body_step(x.clone())\n            x = x.flatten()\n            x_next = x_next.reshape(x.shape)\n        else:\n            x_next = nbody.n_body_step(x.clone())\n            x = x.reshape(x.shape[0], -1)\n            x_next = x_next.reshape(x.shape)\n        x = torch.cat([x, x_next], dim=-1)\n        x = self.act(self.input_conv(x))\n        x = self.act(self.hidden_conv1(x))\n        x = self.act(self.hidden_conv2(x))\n        x = self.output_conv(x)\n        return x.reshape(orig_shape)\n```\nFor a bit over a day and got 25e6 epoches with a batch size of 1000. So 1e10 forwards passes of the net, which took about 24 hours. Learning rate of 3-e4, naturally. Here is what the loss function looks like:\n![[Pasted image 20230605211957.png]]\nSo it was still improving the whole time!\nThat's impressive and noteworthy. Notice something about the model though? I concatenated the expected output onto the input, so all it had to do was learn to pass it through, and it didn't even seem to be that good at doing that!\nHere is what it looks like against the ground truth:\n![[Screencast from 06-05-2023 092503 PM.webm]]\nI can't escape the feeling that something is subtly wrong here. There's no way that this can be that bad, I must be missing something. Recalling [this blog post](http://karpathy.github.io/2019/04/25/recipe/) neural net bugs often look like performance that's just a little bit worse. But that's why I did [[20230604 Simulate trivialities|this]], so that I could verify that I had no such obvious bugs.\n\n## Quick aside: Loss functions that go up again:\nHere is the result of training the net on an input of [x, x_next] so all it has to learn is to do a passthrough of the second half of the net:\n![[Pasted image 20230607080848.png]]\nWhy does the loss function jump up to such a high result after a while???? what's going on here? This seems important. I hear that the adam optimiser has some momentum, maybe that caused it to overshoot and then for some reason it can't get back again? so weird.\nThis is what happens when I decrease the learning rate by a factor of 10 to 3e-5:\n![[Pasted image 20230607081129.png]]\nSo it doesn't looks like a learning rate problem. \n\n# Loss statistics\n\nWe have looked at the [[20230604 N body particulars#Results|state statistics]] before, but what about the loss statistics? Here are the L1 and mse losses for a single step of the simulation:\n```python\n    states = states.re`shape(-1, states.shape[-2], states.shape[-1])\n    states_next = nbody.n_body_step(states.clone())\n    l1 = (states - states_next).abs().mean(dim=(-1, -2)).cpu().detach().numpy()\n    mse = ((states - states_next)**2).mean(dim=(-1, -2)).cpu().detach().numpy()\n    l1 = np.log10(l1); mse = np.log10(mse)\n```\n![[Pasted image 20230607083155.png]]\nAnd if you don't include the acceleration:\n![[Pasted image 20230607083334.png]]","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230604-Simulate-trivialities":{"title":"","content":"# n body is not so trivial\n[[20230507 Simulation|Before]] I said that an n body simulation would be trivial. But it turns out that it might be quite so much as I had thought. I wrote a simple n body simulation: \n\n![[Screencast from 06-04-2023 075012 AM.webm]]\nThat whilst not particularly accurate because of floating point shenanigans, nonetheless behaves in a predictable way. \n\n## State\nThe state of each particle is a 5 dimensional vector - [mass, x, y, vx, vy]. So a 10-particle system is a 10x5 matrix.\n\n## Initial attempt\nI initially copy/pasted hacked together a trivial Graph convolutional neural net using the pytorch geometric framework:\n### GCN\n```python\n\n\nclass GCNConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n        self.project_in = Linear(in_channels, out_channels, bias=False)\n\n        # self.edge_lin = Linear(2 * out_channels, out_channels)\n        self.message_join = Linear(2 * out_channels, out_channels, bias=False)\n        self.edge_mlp = Seq(Linear(2 * out_channels, out_channels),\n                       ReLU(),\n                       Linear(out_channels, out_channels))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.project_in.reset_parameters()\n        self.message_join.reset_parameters()\n\n    def forward(self, x, edge_index):\n        x = self.project_in(x)\n        # Step 4-5: Start propagating messages.\n        messages = self.propagate(edge_index, x=x)\n        out = self.message_join(torch.cat((x, messages), dim=1))\n\n        return out\n\n    def message(self, x_i, x_j):\n        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n        return self.edge_mlp(tmp)\n\n\nclass GCN(torch.nn.Module):\n    def __init__(self, num_features: int):\n        super().__init__()\n        hidden_size = nbody.NUM_STATES\n        self.input_conv = GCNConv(num_features, hidden_size)\n        self.hidden_conv1 = GCNConv(hidden_size, hidden_size)\n        self.hidden_conv2 = GCNConv(hidden_size, hidden_size)\n        # self.output_conv = GCNConv(hidden_size, num_features)\n\n    def forward(self, x):\n        # ChatGpt special to generate edge index for fully connected graph:\n        edge_index = torch.combinations(torch.arange(x.shape[0]), with_replacement=False).t().contiguous()\n        edge_index = torch.cat((edge_index, edge_index.flip(0)), dim=1)\n\n        x = self.input_conv(x, edge_index)\n        x = F.relu(x)\n        x = self.hidden_conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.hidden_conv2(x, edge_index)\n        return x\n```\nBut this totally fails. I then backed things off a a bit to an even simpler case. If that doesn't work, then perhaps a hardcoded 3 body problem would:\n### Fully connected MLP\nSo I put together this. Obviously it would not generalise to more particles, but nonetheless you would think it would works as a hardcoded example. No, though. it's terrible. \n```python\nclass NbodyManual(torch.nn.Module):\n    def __init__(self, num_features: int):\n        super().__init__()\n        hidden_size = 500\n        self.input_conv = Linear(num_features, hidden_size)\n        self.hidden_conv1 = Linear(hidden_size, hidden_size)\n        self.hidden_conv2 = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, num_features) \n    def forward(self, x):\n        orig_shape = x.shape\n        if x.ndim == 2:\n            x = x.flatten()\n        else:\n            x = x.reshape(x.shape[0], -1)\n        x = self.input_conv(x)\n        x = F.relu(x)\n        x = self.hidden_conv1(x)\n        x = F.relu(x)\n        x = self.hidden_conv2(x)\n        x = F.relu(x)\n        x = self.output_conv(x)\n        return x.reshape(orig_shape)\n```\n\nHere is what it looks like:\n![[Screencast from 06-04-2023 080721 AM.webm]]\nYuck. \nThe way that I trained things was by generating 10e3 trajectories of 1e3 timesteps each, and then randomly sampling from these at training time. For the MLP I also used a batch size of 1000 and learning rate of 3e-4. I messed about for many of these parameters but nothing changed anything. Even having fewer layers didn't.\n\n# Go simpler - y = x\\*\\*2\nHere is a neural net that is trying to do y = x\\*\\*2:\n```python\n    class Net(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            hidden_size = 10\n            self.input_conv = Linear(1, hidden_size)\n            self.hidden_conv = Linear(hidden_size, hidden_size)\n            self.output_conv = Linear(hidden_size, 1) \n            self.act = LeakyReLU()\n        def forward(self, x):\n            x = self.act(self.input_conv(x))\n            x = self.act(self.hidden_conv(x))\n            x = self.output_conv(x)\n            return x\n```\nAnd here are the training results:\n![[Pasted image 20230604100237.png]]\nHere the vertical line denotes the limits of the training data. It's pretty clear from looking at the residual that the output is a piecewise linear approximation of the input. This is all very well and good but as expected it generalises super poorly outside the training distribution, which we can also see.\nThe reason that this is the case is of course that multiplications + relu cannot take the input of a neural net and multiply it by itself - This would enable it to learn the true function being approximated here. When simulating physics and stuff there are many types of relationships (like gravitation) where the relationship is a very simple one when expressed as multiplications and whatnot. But something like this can really only do linear approximations, and so it will never generalise very well. \nIt's been pointed out to me that one of the things you can do here is perform various interesting functions, x\\*\\*n, sin(x), exp(x) etc etc as inputs to the net so that it can learn how they work.\n## The bitter lesson\n[The bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) is that all attempts to add human knowlege into the system are irrelevent compared to adding moar weights. The question is whether or not adding these fancy functions as inputs counts as this kind of optimisation. I suspect this comes down to how easy they are to approximate in practice. If you can do the job of an exp(x) with another layer or two it won't matter. But if you can't, then it does matter.\nAnother problem with such things are exploding gradients. 1/x, exp(x) etc etc all have this habit of going to infinity. Some very initial results here suggest that this is going to be a problem, since the opposite of the vanishing gradient problem will occur. The optimiser will spend all its time making sure that the exponential doesn't so anything funny and output 1e12 all of a sudden that it cannot actually approximate the desired function.\n\n### Small experiments adding spiciness\nAdding x\\*\\*2 to the input of the \"mlp\" so all it has to do is select the right input gives us this:\n```python\n    class Net(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            hidden_size = 1\n            self.input_conv = Linear(2, hidden_size)\n            self.output_conv = Linear(hidden_size, 1) \n            self.act = ReLU()\n        def forward(self, x):\n            x = torch.cat((x, x**2), dim=1)\n            x = self.act(self.input_conv(x))\n            x = self.output_conv(x)\n            return x\n```\nAnd here is the result:\n![[Pasted image 20230604110559.png]]\nSo if you constrain stuff enough, things do generalise but of course the model has no way to know that the Relu kicking in one the right hand side will cause things not to work when it generalises.\n#### Muddying the waters\nHere is what happens when I add an exp(x) as an input to the network:\n```python\n    class Net(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            hidden_size = 3\n            self.input_conv = Linear(3, hidden_size)\n            self.output_conv = Linear(hidden_size, 1) \n            self.act = ReLU()\n        def forward(self, x):\n            x = torch.cat((x, x**2, torch.exp(x)), dim=1)\n            x = self.act(self.input_conv(x))\n            x = self.output_conv(x)\n            return x\n```\nNote that I also messed about with the hidden size etc to get the result that I wanted, as is [standard practice](https://xkcd.com/1838/) for ML.\nHere is the result:\n![[Pasted image 20230604111110.png]]\nwe can see that the loss absolutely explodes after a little bit. This is the effect I was looking for [[#The bitter lesson|before]] and I think it will mean that adding this kind of stuff will cause problems.\n### Inverse\nHere are the results of trying to simulate this:\n```python\n    def fn(x): return 1 / (1e-3 + x**2)\n```\nWith an x2 available on the input:\n![[Pasted image 20230604115435.png]]\nwithout:\n![[Pasted image 20230604115341.png]]\nwithout, but with a single hidden layer:\n![[Pasted image 20230604120024.png]]\nI suppose this experiment is a point in favour of the universal approximation theorum.","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230608-Learning-rate":{"title":"","content":"I still haven't gotten the [[20230604 N body particulars|N body simulation]] to do anything useful at all really so I am going back to simulating particulars. I have noticed that learning rate is very important (duh) and so far I have only used a constant one. Pytorch has lots of \"learning rate schedulers\" though that adjust it over time to various criteria.\n\n## Exponential decay\nLet's train a neural net to model this function:\n```python\n    def fn(x):\n        out = x[:, -1] * x[:, -2] / (1e-3 + x[:, -3]**2)\n```\nHere is is the structure of the net:\n```python\n    class Net(torch.nn.Module):\n        def __init__(self):\n            super().__init__()\n            hidden_size = 100\n            self.input_conv = Linear(3, hidden_size)\n            self.hidden_conv = Linear(hidden_size, hidden_size)\n            self.output_conv = Linear(hidden_size, 1) \n            self.act = ReLU()\n        def forward(self, x):\n            x = self.act(self.input_conv(x))\n            x = self.act(self.hidden_conv(x))\n            x = self.output_conv(x)\n            return x\n```\nI trained it with a learning rate that decayed from 3e-1 to 3e-3 over 50k epochs, and the results look like this:\n![[Pasted image 20230608082528.png]]\nSo it did a somewhat reasonable job. But I noticed that the learning rate decay is both very important and not so trivial to get right. You can see at the beginning the variance in the loss is very high, indicating that perhaps too large of a step is being taken and at the end it is very low, indicating that perhaps the learning rate is too low. \nI wonder if there are any schedulers that attempt to maintain a constant variance (in log space) in the loss function. To me that sounds like a good way to get a signal about how big of a step size to take in the gradients. Wait no that makes no sense. As the model trained the loss function variance would not decrease. I guess maybe this works to find a good learning rate rather than to adjust it over time. The loss functions is most definitely not a random variable though, here is the loss over time zoomed in to the middle of the above training run:\n![[Pasted image 20230608083101.png]]\nExtremely periodic. I wonder if this has to do with the adam 'momentum'.\n### Constant variance - good for picking?\nSo from the above loss function over time it looks like halfway between 3e-1 and 3e-3 is a good learning rate. Here is what happens to the loss function if you use 3e-2 for the whole training run:\n![[Pasted image 20230608083513.png]]\nThe variance of the learning rate goes up! So maybe I am onto something here!\nLike I said though, the loss is not a random variable. This is what things looks like at the tail end:\n![[Pasted image 20230608083617.png]]\nnot sure what the dealio with this is. I noticed that I was training on the same 10k examples over and over so I made it a different 10k each time. Here is the exact same training run, generating different samples for each forward pass:\n![[Pasted image 20230608084027.png]]\n...Yeah there you go. Overfitting is happening somehow. I assumed this wouldn't happen since the model has like 200 parameters in it and the input is a perfect random variable but I guess not. This still seems to exhibit the learning rate going up phenomenon though.\n\n## Experiment: Constant variance:\nHere is the loss and the variance in the loss plotted as a function of epoch. The loss is calculated as the standardd deviation of the last 500 epochs. It looks like this:\n![[Pasted image 20230609082039.png]]\nThis intuitively makes sense. The std is high at the beginning (because the std of a straight but sloped line is high) and then goes don until the first fast learning is done. Then it goes up gradually with time, as I observed before. The red vertical line is at 500, the width of the variance-estimating filter.\nLet's try and control the variance to 0.075. Here's how it went:\n![[Pasted image 20230609081805.png]]\nVery poorly. It seems that the natural output of the model has a variance of at least 0.075 and so even if the learning rate is crushed to 0 then the variance still stays high. I didn't expect that one...\nThis perhaps explains why I don't see anyone else doing this. \n### Variance within the model\nThere is a glimmer of hope for this idea still. If we know the variance within the model then we could perhaps subtract that out from the variance due to the too-high learning rate and then use that to adjust the learning rate. We have a batch size of 10k here, so we can get a quite accurate estimate of the models variance over time without too much extra computation.\n\nHere is the variance in the model calculated as follows:\n```python\n        x = torch.randn(40000, 3)\n        y_model = model(x)\n        y_gt = fn(x)\n        loss = F.mse_loss(y_model, y_gt)\n        loss.backward()\n        model_stds.append(torch.std(torch.log10((y_model - y_gt)**2)).cpu().item())\n```\nOver time:\n![[Pasted image 20230609084041.png]]\nSo it doesn't really change much over the course of the run. Note that it's way higher than the variance of the losses here. This is because the variance of the losses above is calculated as std(log10(mean(errors))) whereas the model variance is std(log10(errors)). Regardless the main point here is that the models error spread in log space (% error spread) stays pretty constant over the training run.\n## Takeaway\n- The measured variance of the loss curve over time is the combination of the natural variance in the models output and the additional variance due to updating the models weights according to the learning rate.\n- As a model becomes better trained, the spread of its errors may in fact go _up_ which is unintuitive to me.","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230610-N-body-again":{"title":"","content":"[[20230610 inv x squared a deep dive|Previously, on NN adventures:]] I figured out that optimising the ratio of the input to the output was what was needed. Let's use that information and go back to training N body simulations. Taking the [[20230610 inv x squared a deep dive#Different loss function?|Exact same]] loss function and whacking it into the N body training loop (the one where we are just trying to pass the input to the output), the loss looks like this:\n![[Pasted image 20230610094721.png]]\nNot great. Stuff just flies around in the sim as per usual, too. Looks like the learning rate is too high though. \nChanging things so there is only one hidden layer and reducing the learning rate to 3e-5 and I get this:\n![[Pasted image 20230610095423.png]]\n...Now that's more promising. But no, stuff just flies around in the simulator as per normal. I think I could do with a scheduler here. That took quite a few minutes to train, and at the end there it looked like the learning rate was still too high.\nHere's the scheduler:\n```python\n    batch_size = 5000\n    oom_decay = 3\n    epochs = 10000\n    learning_rate_start = 1e-2\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_start)\n    scheduler = ExponentialLR(optimizer, gamma=np.power(10, -oom_decay / epochs))\n```\nAnd the results:\n![[Pasted image 20230610100043.png]]\nBoom. 2 OOM improvement in the loss with 1/6 the training time. Noice.\nIn the simulation we can actually see that the bodies kind of interact with each other. I noticed in the above graph things kinda slowed down a bunch at the end there, so trained for 10x longer with the same scheduler. And I got this:\n![[Pasted image 20230610100902.png]]\nHMMMMMM. That is some nice perfectly scheduled learning right there (I think). Another 3 OOM improvement. Let's take a look in the simulator:\n![[Screencast from 06-10-2023 101107 AM.webm]]\n!!!\nFinally. Some modicum of success. Time to remove the output from the input lol.\n### A note on training speed.\nIt look 100e3 iterations of a batch size of 4e3 for this model with like 1000 parameters in it to learn the identity function. This really really does not bode well for learning anything more complex with short development cycles. \n### First results with new fitness function:\nHere is what happens training over 1e6 iterations using a learning rate decaying from 1e-3-\u003e1e-6:\n![[Pasted image 20230610185747.png]]\n...Yep, not great. This is quite similar to [[20230604 N body particulars#\"Quick\" experiment maybe we just need more flops?|what I got before]] really (note of course that the absolute magnitude of the loss here is not comparable).\n#### Gradient speed\nMaybe what's going on here is that although we are optimising for the right thing here (percentage error) we are doing so in a way that produces a super weak gradient on account of the log. This is a bit of a incoherent notion that I don't really understand.\n- If the gradient is weak, why not just multiply it by a higher learning rate? Perhaps because the variance in the model is not correspondingly weak, and so the signal to noise ratio is poor here?\n- If we have a fitness function with a stronger gradient, isn't that basically the same as going back to mean squared error again? Is it a linear thing between \"correct fitness function that takes ratio but gives weak signal\" and \"strong fitness function that gives good signal but prioritises fixing spiky bits in the loss landscape at the expense of everything else\", or are the two independent and we can find a function that performs well one both accounts?\nI don't really know what if any of these things are true. Maybe this is where one of those literature searches would be good. One of my favourite papers \"Learning to simulate complex physics with graph neural networks\" has this to say on the topic:\n![[Pasted image 20230610190612.png]]\nThey were doing fluid simulations and suchlike. I think though that what they were doing might actually be a bit easier than this though. Intuitively I would expect the dynamic range of the problem to be quite a bit lower. Water particles only interact with what's right next to them and do so with a (relatively) low range of forces. So they might have just not run into this problem.\n### Quick replication attempt.\n[here](https://arxiv.org/pdf/1910.07291.pdf) is a paper that does the three body problem - exactly the same as what I have been trying to do. Prolly should have looked this up earlier but oh well. Their structure is also super simple - a 128 wide by 10 deep MLP. let's whack that into pytorch and see how it goes.\nHere is the loss function:\n![[Pasted image 20230610211605.png]]\nGyarbage! We know from above that you need like 1e-6-\u003e1e-8 loss to get good results, this isn't even close to that. I'm getting pretty strong \"dataset is high variance and that's why it isn't training\" vibes from that loss function too. \n## Next steps\nSo from here I can:\n- Fudge the N body simulation so that it's smoother, akin to having an epsilon of 1e-2 [[20230610 inv x squared a deep dive#Background#Experiments varying epsilon| like this]] to see if it makes things easier to train. This will verify that it's the spikyness that is what's causing the issue.\n- Try to find a better loss function, since I got such great improvements from that route already\n- Train on a tiny subset of the data to try to overfit, and then generalize from there.\n\nThe last option is easiest, so let's try that next:\n## Train on 10 timesteps of one simulation.\nHere is the loss curve for training on 10 simulation steps of a single initial state only:\n![[Pasted image 20230610215854.png]]\nSo that seems somewhat reasonable. Let's bump it up to 10 trajectories each with 10 simulation steps:\n![[Pasted image 20230610220101.png]]\nSo we can see that already that's enough to cook the loss!\n\n## Train with a different fitness function. \nI updated the fitness function to the one [[20230610 inv x squared a deep dive#Going deeper|here]], and then trained it on the 128 wide 10 deep architecture from before for about 8 hours with a learning rate decaying from 3e-3 to 2e-6. \nDataset was _two_ bodies this time, 50e3 trajectories of 1000 timesteps each.\nHere are the results:\n![[Pasted image 20230612172952.png]]\nwell, it seems to have converged on something...\nLet's check it out in the sim:\n![[Screencast from 06-12-2023 053202 PM.webm]]\nIt verks!\nIncredible. It doesn't work that well, but it does recognisably solve the problem. Amazing. Only took like a month. Now to do the same thing, but with _three_ bodies. \nAnd here are the results for that:\n![[Pasted image 20230613080604.png]]\n...Seems to converge with an error about 10x higher, oh well. Let's zoom in on one of these spikes of error:\n![[Pasted image 20230613080704.png]]\nso it looks like the model sometimes gets updated in a very poor direction, then has to spend a long time recovering from this before it has a chance to get back to where it was. Even though the batch size is like 8000, I suspect that the cause of this is one example within the batch having a truly stupendous error that throws everything out. I guess this could be from two causes:\n- Early in the training process the model has not adapted well, and so occasionally guesses very wrong.\n- Early in the training process the learning rate is high, so the model weights get thrown into a bad area of the loss function.\nThe latter sounds more likely to me. If this is the failure mode of the model however, one thing that we could do is do something like \n```python\nfor epoch in range(num_epochs):\n\tmodel(data)...blah blah train\n\tif(curr_loss \u003e prev_loss * 10): continue\n```\nThis might be a good idea but I think it is also papering over the issue. Before I go and do something like that we should go and understand in great and excruciating detail why it is that everything is so profoundly fat tailed. I think that this is most likely a lesson that will translate well into future efforts.\nFor example if our ground truth is a simulation, maybe we can gradually  increase the 'peakiness' of the training data as a function of time (i.e. gradually decrease epsilon [[20230610 inv x squared a deep dive|like I did here]]) which might make things train faster. That seems like something that could generalise well. It also seems like something that could paint you into a corner where you could only train on data that could be smoothed in this way too.\nGPT tells me that this kind of thing is called 'Curriculum learning'.\n### Quick experiment: batch normalisation.\nHere is the result of the same 10 layer network, only the first 7 layers are batch norm:\n![[Pasted image 20230613204142.png]]\nbasically exactly the same (take note of x axis). \n## Exploring the error\nI set a breakpoint in vscode for when the error went up by more than a factor of 100, and got a breakpoint around 300e3. Here is what the ratio losses look like across the batch size of 8000:\n![[Pasted image 20230613205906.png]]\nWhat kind of absolutely atrocious distribution is that?\nHere are what things look like for the fitness function before that, the [[20230610 inv x squared a deep dive#^381054|two sided log]]:\n![[Pasted image 20230613210249.png]]\nwell I'm not going to say that's great, but it looks much better than the previous one. It's clear with this too though that the loss is dominated by these outliers. inspecting them, they seem to be important as this is where the n bodies are undergoing high accelerations. Maybe if we optimised for the 0-\u003e95th percentile of losses this would work out better though and even though we would not be training on such extreme cases the model would still learn better. So many experiments!\n\n## Bringing the two training notions together\nI have had two ideas about how to train these spiky functions:\n- Gradually increase the spikiness of the training data over time by increasing the epsilon in 1/x^2 or similar. \n- Reject some outlier losses to stop egregious model updates\nBut don't you see! Those are the same! If we we gradually update the weights over the training period from the 0th to 100th percentile of the losses, then it will by definition be learning on the easiest (smoothest) examples first!\nSomeone must have thought of this already...\n## Results\nHere is the loss curve from training in such a way that over the course of the training set the loss is calculated from a gradually increasing fraction of the errors, like so:\n```python\n        def my_loss(target, pred):\n            min_batch_ratio = 0.1\n            percentile = (epoch / epochs) * (1 - min_batch_ratio) + min_batch_ratio\n            ratio = (pred - target) / (1 + target.abs())\n            ratio_batch = torch.mean(ratio, dim=(-1, -2))\n            ratio_percentile = torch.quantile(torch.abs(ratio_batch), percentile)\n            ratio_batch = ratio_batch[ratio_batch.abs() \u003c ratio_percentile]\n            return  ratio_batch.abs().mean()\n        loss = F.l1_loss(my_loss(data_end, out), torch.zeros(1))\n```\n![[Pasted image 20230614075059.png]]\nWell it certainly looks like something happened there. But in the simulation the bodies just fly apart. At least there were no spikes during training. Let's take a look at what happens with the exact same setup and loss function, only difference is percentile is set to 1 always:\n![[Pasted image 20230614075623.png]]\nI suppose this isn't really valid since the first net never even trained at all on the hard examples really. So I changed the percentile calculation to this:\n```python\n            min_batch_ratio = 0.1\n            percentile = 2 * (epoch / epochs) * (1 - min_batch_ratio) + min_batch_ratio\n            percentile = min(percentile, 1.0)\n```\nso that it would train on all the dataset for the last half of the training set.\n![[Pasted image 20230614080045.png]]\nSo the final loss here is actually quite a bit better than the no-curriculum alternative, it looks like.\nThe results in the simulation are a bit interesting, they looks like this:\n![[Screencast from 06-14-2023 080236 AM.webm]]\n## What if we did the opposite?\nMaybe the problem is not that the datset is super fat tailed, making it difficult to train on. Maybe the problem is that the training data is 99% \"objects in motion stay in motion\" and 1% \"actual gravitation\".\nSo what if we trained the net on a dataset where the bodies where experiencing high accelerations?\nHere is the result of training on the ~90th percentile examples with the highest accelerations (most newtons law, least \"objects in motion\"), learning rate decaying from 3e-3-\u003e3e-6. \n![[Pasted image 20230614220615.png]]\nmore garbage. I think I'll give up on nbodies for now, too hard. The whole thing was supposed to be a learning exercise anyway and I think it's run its course there.","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230610-inv-x-squared-a-deep-dive":{"title":"","content":"# Background\n[[20230608 Learning rate|Recently]] I have been trying to train on this function:\n```python\n    def fn(x, epsilon):\n        out = x[:, -1] * x[:, -2] / (epsilon + x[:, -3]**2)\n```\nUsing a very simple net structure like this one:\n```python\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        hidden_size = 100\n        self.input_conv = Linear(3, hidden_size)\n        self.hidden_conv = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, 1) \n        self.act = ReLU()\n\n    def forward(self, x):\n        x = self.act(self.input_conv(x))\n        x = self.act(self.hidden_conv(x))\n        x = self.output_conv(x)\n        return x\n```\nWith rather mixed results, to say the least. On thing that I noticed is that the choice of epsilon matters a huge amount here. This is very relevant to my gravitation simulations since of course gravitation involves the calculation of an inverse square of the  distance between bodies. So if I can't train a net to approximate this function, I can't expect it to do well.\n\n## Experiments varying epsilon\nHere are the results of training a net with different values of epsilon. Learning rate 3e-4, batch size 40e3:\n![[Pasted image 20230610080730.png]]\n...So you can see here that if epsilon approaches any reasonable value stuff falls apart very quickly. Not only is the error high but the model stops actually being able to learn at all. This is what the error histograms look like:\n![[Pasted image 20230610081024.png]]\nInterestingly when you get a small enough epsilon, the median error of the model is actually _higher_ than the median error of two randomly selected inputs! This suggests to me that the fitness function is bad, but we shall experiment on that later.\n### Piecewise linear. \nSince the activation function here is a Relu and there is only one hidden layer the model basically has to do a piecewise linear approximation. Let's try training it on a deeper network and see if that makes a difference:\n```python\n# Create network class\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        hidden_size = 100\n        self.input_conv = Linear(3, hidden_size)\n        self.hidden_conv = Linear(hidden_size, hidden_size)\n        self.hidden_conv2 = Linear(hidden_size, hidden_size)\n        self.hidden_conv3 = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, 1) \n        self.act = ReLU()\n\n    def forward(self, x):\n        x = self.act(self.input_conv(x))\n        x = self.act(self.hidden_conv(x))\n        x = self.act(self.hidden_conv2(x))\n        x = self.act(self.hidden_conv3(x))\n        x = self.output_conv(x)\n        return x\n```\naaaand it's not much different:\n![[Pasted image 20230610081700.png]]\nAlthough the loss of the 1e-4 epsilon actually does start going down, the median error of the model is still higher than two random points. I notice on the higher two epsilons the learning curves have signs of too high of a learning rate (those spiky bits) so I re-ran with 1e-4 learning rate, but that did not make that much of a difference.\n## Different loss function?\n(In this section I went back to the one-hidden-layer model)\nThe loss function that I have been using is mean squared error, cause I figured this was a fitting problem and those weirdo loggy loss functions are for cat detectors. Perhaps not though. I think what is happening here is the sharp point of the function where the denominator goes to 0 is dominating the loss curve. So if we optimised for  the percentage error, or the ratio of the true / desired output then things would perhaps perform better. \nHere is a fitness function along those lines:\n```python\n        loss = F.mse_loss(torch.log(1 + torch.abs(y_model - y_gt)), torch.zeros_like(y_model))\n```\nAnd here is how it performs:\n![[Pasted image 20230610091150.png]]\nSuccess! The model actually trains and when we look at the histogram of the losses, we can see that the median model mean squared error is actually less than a random error!\nThe above loss function seems kind of hacky. I think that this one truly does represent the ratio of the input to output, whilst still preserving sign and whatnot:\n```python\n        def two_sided_log(x): return torch.sign(x) * torch.log(1 + torch.abs(x))\n        loss = F.mse_loss(two_sided_log(y_model), two_sided_log(y_gt))\n```\n\n^381054\n\nThis is what we get training on just the 1e-4 model:\n![[Pasted image 20230610092928.png]]\nAmazing!\nAnd a new visualisation: Let's test the model on all ones, except for the denominator which ranges linearly from -1 to 1. We can think of this as a kind of partial derivative of the model with respect to the denominator I suppose:\n![[Pasted image 20230610093019.png]]\nLooks reasonable. Note the log scale on the graph, the model is indeed fitting to percentage error. We can see the parts where the linear approximations are happening.\nHere's what the model looks like after 50e3 training runs. This is a closeup of the above graph. We can see here that the model is doing a bunch of linear approximations. I don't think this is an artifact of the plotting that was used:\n![[Pasted image 20230610093943.png]]\n### Sanity check\nHere is the output of the regular mse loss trained model with the same visualisation:\n![[Pasted image 20230610093300.png]]\nHot garbage. I think my reasons are correct here. The error around x == 0 is actually a bit lower than the previously trained model (verified with mouseover in matplotlib). It's just that this marginally lower absolute error here comes at the cost of hugely larger error everywhere else.\nSanity check: sane.\n## Going deeper\nI had [[20230610 N body again|more troubles]] with the actual problem at hand, so I am back here. What about this fitness function:\n```python\n        loss = F.l1_loss((y_model - y_gt) / (1 + y_gt.abs()), torch.zeros_like(y_gt))\n```\nIt's explicitly optimizing for the percentage error rather than via some mathematical curiosity. This is the error after 50k training runs:\n![[Pasted image 20230612081332.png]]\nWe can see the median log(MSE) is like -5 now, which is like 2.5OOM better than above. ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230610-invx2-a-deep-dive":{"title":"","content":"# Background\n[[20230608 Learning rate|Recently]] I have been trying to train on this function:\n```python\n    def fn(x, epsilon):\n        out = x[:, -1] * x[:, -2] / (epsilon + x[:, -3]**2)\n```\nUsing a very simple net structure like this one:\n```python\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        hidden_size = 100\n        self.input_conv = Linear(3, hidden_size)\n        self.hidden_conv = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, 1) \n        self.act = ReLU()\n\n    def forward(self, x):\n        x = self.act(self.input_conv(x))\n        x = self.act(self.hidden_conv(x))\n        x = self.output_conv(x)\n        return x\n```\nWith rather mixed results, to say the least. On thing that I noticed is that the choice of epsilon matters a huge amount here. This is very relevant to my gravitation simulations since of course gravitation involves the calculation of an inverse square of the  distance between bodies. So if I can't train a net to approximate this function, I can't expect it to do well.\n\n## Experiments varying epsilon\nHere are the results of training a net with different values of epsilon. Learning rate 3e-4, batch size 40e3:\n![[Pasted image 20230610080730.png]]\n...So you can see here that if epsilon approaches any reasonable value stuff falls apart very quickly. Not only is the error high but the model stops actually being able to learn at all. This is what the error histograms look like:\n![[Pasted image 20230610081024.png]]\nInterestingly when you get a small enough epsilon, the median error of the model is actually _higher_ than the median error of two randomly selected inputs! This suggests to me that the fitness function is bad, but we shall experiment on that later.\n### Piecewise linear. \nSince the activation function here is a Relu and there is only one hidden layer the model basically has to do a piecewise linear approximation. Let's try training it on a deeper network and see if that makes a difference:\n```python\n# Create network class\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        hidden_size = 100\n        self.input_conv = Linear(3, hidden_size)\n        self.hidden_conv = Linear(hidden_size, hidden_size)\n        self.hidden_conv2 = Linear(hidden_size, hidden_size)\n        self.hidden_conv3 = Linear(hidden_size, hidden_size)\n        self.output_conv = Linear(hidden_size, 1) \n        self.act = ReLU()\n\n    def forward(self, x):\n        x = self.act(self.input_conv(x))\n        x = self.act(self.hidden_conv(x))\n        x = self.act(self.hidden_conv2(x))\n        x = self.act(self.hidden_conv3(x))\n        x = self.output_conv(x)\n        return x\n```\naaaand it's not much different:\n![[Pasted image 20230610081700.png]]\nAlthough the loss of the 1e-4 epsilon actually does start going down, the median error of the model is still higher than two random points. I notice on the higher two epsilons the learning curves have signs of too high of a learning rate (those spiky bits) so I re-ran with 1e-4 learning rate, but that did not make that much of a difference.\n## Different loss function?\n(In this section I went back to the one-hidden-layer model)\nThe loss function that I have been using is mean squared error, cause I figured this was a fitting problem and those weirdo loggy loss functions are for cat detectors. Perhaps not though. I think what is happening here is the sharp point of the function where the denominator goes to 0 is dominating the loss curve. So if we optimised for  the percentage error, or the ratio of the true / desired output then things would perhaps perform better. \nHere is a fitness function along those lines:\n```python\n        loss = F.mse_loss(torch.log(1 + torch.abs(y_model - y_gt)), torch.zeros_like(y_model))\n```\nAnd here is how it performs:\n![[Pasted image 20230610091150.png]]\nSuccess! The model actually trains and when we look at the histogram of the losses, we can see that the median model mean squared error is actually less than a random error!\nThe above loss function seems kind of hacky. I think that this one truly does represent the ratio of the input to output, whilst still preserving sign and whatnot:\n```python\n        def two_sided_log(x): return torch.sign(x) * torch.log(1 + torch.abs(x))\n        loss = F.mse_loss(two_sided_log(y_model), two_sided_log(y_gt))\n```\n\n^381054\n\nThis is what we get training on just the 1e-4 model:\n![[Pasted image 20230610092928.png]]\nAmazing!\nAnd a new visualisation: Let's test the model on all ones, except for the denominator which ranges linearly from -1 to 1. We can think of this as a kind of partial derivative of the model with respect to the denominator I suppose:\n![[Pasted image 20230610093019.png]]\nLooks reasonable. Note the log scale on the graph, the model is indeed fitting to percentage error. We can see the parts where the linear approximations are happening.\nHere's what the model looks like after 50e3 training runs. This is a closeup of the above graph. We can see here that the model is doing a bunch of linear approximations. I don't think this is an artifact of the plotting that was used:\n![[Pasted image 20230610093943.png]]\n### Sanity check\nHere is the output of the regular mse loss trained model with the same visualisation:\n![[Pasted image 20230610093300.png]]\nHot garbage. I think my reasons are correct here. The error around x == 0 is actually a bit lower than the previously trained model (verified with mouseover in matplotlib). It's just that this marginally lower absolute error here comes at the cost of hugely larger error everywhere else.\nSanity check: sane.\n## Going deeper\nI had [[20230610 N body again|more troubles]] with the actual problem at hand, so I am back here. What about this fitness function:\n```python\n        loss = F.l1_loss((y_model - y_gt) / (1 + y_gt.abs()), torch.zeros_like(y_gt))\n```\nIt's explicitly optimizing for the percentage error rather than via some mathematical curiosity. This is the error after 50k training runs:\n![[Pasted image 20230612081332.png]]\nWe can see the median log(MSE) is like -5 now, which is like 2.5OOM better than above. ","lastmodified":"2024-07-04T16:16:27.992231093Z","tags":null},"/20230616-Learning-to-simulate":{"title":"","content":"One of the papers that I like the most on this journey of getting nets to simulate stuff is [this one](https://sites.google.com/view/learning-to-simulate/home?authuser=0). The results are kinda cool but more importantly the code and data is available. I tried for many hours but could not get the code to run on the gpu. Too many tensorflow and driver compatibility problems as the code used an old version of tensorflow.\nNot a problem. I shall simply reimplement it myself in pytorch. Something something education!\n\n# Exploring the dataset\nI first downloaded the [WaterDrop](https://sites.google.com/view/learning-to-simulate/home?authuser=0#h.p_AMiqgaqebAtR) dataset. It's a could of gigs. Let's take a look at the statistics of the particle positions, vels, and accelerations for a single example:\n![[Pasted image 20230616084802.png]]\nCompare this to the statistics [[20230604 N body particulars#Results|here]] and it actually looks basically the same. Maybe the n body problem is actually pretty representative after all...\n\n\n## Single trajectory\nAs a first order of business let's train a model on a single trajectory with the simplest possible model:\n```python\nclass WaterManual(torch.nn.Module):\n\n    def __init__(self, num_features: int):\n        super().__init__()\n        self.hidden_size = int(num_features * 2)\n        self.input_conv = Linear(num_features, self.hidden_size)\n\n        self.hidden_conv1 = Linear(self.hidden_size, self.hidden_size)\n        self.hidden_conv2 = Linear(self.hidden_size, self.hidden_size)\n        self.output_conv = Linear(self.hidden_size, num_features) \n\n        # pytorch leaky rely activation:\n        self.act = LeakyReLU()\n\n\n    def forward(self, x):\n        if x.ndim == 2:\n            x = x.unsqueeze(0) # batch size 1\n        orig_shape = x.shape\n\n        x = x.reshape([x.shape[0], -1])   # Flatten input features\n\n        x = self.input_conv(x)\n        x = self.act(self.hidden_conv1(x))\n        x = self.act(self.hidden_conv2(x))\n        x = self.output_conv(x)\n\n        x = x.reshape(orig_shape)\n        return x.squeeze()\n```\nA basic MLP with two hidden layers. The examples in the dataset all have different sizes but this isn't a problem for this contrived and overfit example.\n\n## Training\nHere is the result of training on a single trajectory with two hidden layers:\n![[Pasted image 20230617191225.png]]\nAbsolutely textbook.\nAnd here is what it looks like when the model does projection:\n![[Screencast from 06-18-2023 085242 AM.webm]]\nI am stunned. The model was trained to predict the positions at t+1 from time t but here I made the model predict all 1000 sequential steps in succession, so the divergence here is the accumulated error. This is an _astoundingly_ easy problem compared to what I was dealing with before.\n\n## Losses between timesteps:\nJust for comparison here is what happens when you diff adjacent timesteps and plot the mean squared error for the first 1000 datasets:\n![[Pasted image 20230618092542.png]]\nSo a model that has a mse of 1e-7 is doing ok, but could be better. We can see that there is quite a bit lower error in the y axis. This is a dataset of drops of water falling down so I assume that this is just the drop being close to stationary at the start.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230701-DIY-fluids":{"title":"","content":"The [[20230616 Learning to simulate|previous]] simulation efforts worked all very well and good but I want a way to have some super small toy problems (say with 10 particles) that behave similarly to the sims from the paper. No problem, we shall simply write our own:\n```python\n\ndef fluid_step(state: torch.Tensor):\n    # The simulation takes places within a box of size BOX_SIZE x BOX_SIZE in the positive quadrant\n    dt = 1\n    gravity_str = 1e-4\n    repel_str = 1e-8\n    wall_str = 1e-6\n    # state is a B x N x 4 tensor, where  B is the batch size, N is the number of particles\n    # and the last dimension is [x, y, vx, vy]\n    orig_shape = state.shape\n    if len(state.shape) == 2:  # add batch dim if necessary\n        state = state.unsqueeze(0)\n\n    x_diff = (state[:, :, X_IDX].unsqueeze(-2) - state[:, :, X_IDX].unsqueeze(-1))  # B * N * N\n    y_diff = (state[:, :, Y_IDX].unsqueeze(-2) - state[:, :, Y_IDX].unsqueeze(-1))  # B * N * N\n    x_diff_sq = x_diff ** 2 # B * N * N\n    y_diff_sq = y_diff ** 2 # B * N * N\n    # x_diff_sq += 1e-9  # avoid divide by zero in range_\n    range_ = torch.sqrt(x_diff_sq + y_diff_sq)\n    relative_displacement = (range_ - PARTICLE_SIZE) / PARTICLE_SIZE\n    exp_scale = torch.log(torch.tensor(0.01)) / INTERACTION_RADIUS\n    repel_mag = relative_displacement ** 3  * torch.exp(exp_scale * torch.abs(relative_displacement))\n    # repel_mag = 1 / relative_displacement \n    # repel_mag = x_diff_sq + y_diff_sq\n\n    # Add in the inter-particle repulsion:\n    repel_direction = torch.stack([\n        (x_diff / (range_ + 1e-9)),\n        (y_diff / (range_ + 1e-9)),\n    ], dim=1)  # B * 2 * N * N\n    N = state.shape[1]\n    repel_direction = repel_direction.masked_fill(torch.eye(N, dtype=torch.bool).unsqueeze(0).unsqueeze(0), 0)\n    mutual_repel = repel_mag.unsqueeze(1) * repel_direction\n    mutual_repel = mutual_repel.sum(dim=-2)  # B * 2 * N\n    mutual_repel = -mutual_repel.transpose(-1, -2)  # B * N * 2\n\n    # add in repulsion from the walls:\n    wall_dist = torch.stack([\n        torch.stack(\n        [  # horizontal walls\n            state[:, :, X_IDX],\n            state[:, :, X_IDX] - BOX_SIZE,\n        ], dim=-1),\n        torch.stack(\n        [ # vertical walls\n            state[:, :, Y_IDX],\n            state[:, :, Y_IDX] - BOX_SIZE,\n        ], dim=-1),\n    ], dim=-1)  # B * N * 2 * 2\n    wall_dist_inv = torch.exp(-1e1 * torch.abs(wall_dist)) / wall_dist**3  # cube to maintain sign\n    # remove nans:\n    wall_dist_inv[torch.isinf(wall_dist_inv)] = 0\n    wall_repel = wall_dist_inv.sum(dim=-2)\n\n    # add in gravity:\n    gravity = torch.zeros_like(mutual_repel)\n    gravity[:, :, 1] = -gravity_str\n    \n    accel = mutual_repel * repel_str + wall_repel * wall_str + gravity\n    # no nan's allowed:\n    assert not torch.isnan(accel).any()\n\n    # update velocities:\n    state[:, :, 2:4] += dt * accel\n    # update positions:\n    state[:, :, 0:2] += dt * state[:, :, 2:4]\n\n    # make the fluid particles stop when they hit the walls.\n    out_x_p = (state[:, :, X_IDX] \u003e= BOX_SIZE)\n    out_x_n = (state[:, :, X_IDX] \u003c 0)\n    out_x = out_x_p | out_x_n\n    out_y_p = (state[:, :, Y_IDX] \u003e= BOX_SIZE)\n    out_y_n = (state[:, :, Y_IDX] \u003c 0)\n    out_y = out_y_p | out_y_n\n    state[:, :, X_IDX] = state[:, :, X_IDX].masked_fill(out_x_p,  BOX_SIZE)\n    state[:, :, X_IDX] = state[:, :, X_IDX].masked_fill(out_x_n, 0)\n    state[:, :, Y_IDX] = state[:, :, Y_IDX].masked_fill(out_y_p,  BOX_SIZE)\n    state[:, :, Y_IDX] = state[:, :, Y_IDX].masked_fill(out_y_n, 0)\n    state[:, :, VX_IDX] = state[:, :, VX_IDX].masked_fill(out_x, 0)\n    state[:, :, VY_IDX] = state[:, :, VY_IDX].masked_fill(out_y, 0)\n    return state.reshape(orig_shape)\n```\n\n![[Screencast from 07-01-2023 015628 PM.webm]]\nta-da!\nOK it's not that great. main thing missing is the fact the particles pass through each other, and the lack of viscous forces to slow stuff down. Given that particles passing through each other means that there might be a /0 somewhere in the sim and this is the thing  that killed the N body simulation as a learning tool I feel that I may be repeating myself.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230703-Simulation-naval-gazing-intermission":{"title":"","content":"# Stuff done so far\nSo far the approach to this goal of [[20230507 Simulation|Simulating cool things]] has been to iteratively build on successively larger toy problems with the goal of me learning in general about how all this stuff works. The N body stuff and fluid simulations have worked well for this so far but I am coming up to an impasse I think.\nI can see that if I went and reimplemented the fluids stuff from [[20230701 DIY fluids|here]] then it would help me out a bunch with generic pytorch skills but I don't know that it would help that much for the second part of the goal, moving towards doing stuff with chemistry.\n## Other work\nSo I decided to go back and do some more spelunking in the real world to see what I can find. I think that [this paper](https://pubs.rsc.org/en/content/articlepdf/2019/sc/c8sc04228d) is quite interesting. They get what looks to me like pretty good results using not _that_ much data (like 400k reactions or something) and also apparently it only took like a day to train on a titan x which is pretty good.\nAnother paper did some stuff combining text (like LLM stuff) and traditional structure. I learned two interesting concepts from it:\n- Aligning the latent space of a model. So e.g. all images of cats are enforced to transform to the same numbers. This seems like it could be particularly fruitful for combining sources of information. So for example if we enforce that there is one \"big bag of atoms\" somewhere in the model, then all sources of data can project to this since it is the real world. This is kind of how you can project radar to a point cloud and use monocular depth estimation to project camera to a point cloud, and have lidar in a point cloud, then all three sources can be merged together in a super intuitive way.\n- Contrastive learning. Paper is called \"Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing\". In this paper they had two inputs [molecule structure, text] and the contrastive bit ensured that the structure and text of the same molecule was encoded to the same set of numbers and also in addition to this that it was encoded differently to the other molecules. In this way the same stuff was clustered together and different stuff clustered differently.\nSome discussions were also had about good next steps and so I think a super-toy problem that might be done would be e.g. the classification of alkanes/alkenes into \"valid\" and \"invalid\" sets, where e.g. CH4 is valid and CH4CH3 is 'invalid'. That should be done pretty quick and then we can move onto something more. The short training time of the task in the above paper gives me hope that these can be iterated on relatively quickly.\n## One other thing\nI have been pondering how to represent these molecules in a simulation. One way you could do it would be to have molecules floating about as discrete things, and model how they change. But what are two molecules, but a disjoint graph? So really the whole simulation is just one big graph where the definition of a 'molecule' is a disjoint subgraph. This seems like it would be a much better representation. Before we get too excited though I think it would be good to go take a look at how all these protein foldy models represent their molecules. Is it also a graph? How are the positions represented?\nOne could imaging that if you wanted to simulate N atoms under a fixed compute budget you could just enforce that there are k edges between the atoms. The model would then be in charge of figuring out that the edges between molecules within an atom were very important (duh) and then also allocate edges towards other important things like dipoles and whatnot. \n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230715-BetaPut":{"title":"","content":"I gave up on the fluid simulation on the basis that it wasn't going to go anywhere even if I could get it to work.\nThe next thing that I want to try is a baby version of alphafold. Instead of the input being the amino acid sequence and hte output being the positions of all of the atoms, the input will be a small molecule SMILES (atomic bonds) and the output will be the positions of the atoms.\n\n# Dataset\nIt seems like the best dataset available for this is the Crystallography Open Database (COD). It has about 500e3 different molecules with their crystal structures determined via x ray diffraction or otherwise. The CIF files it contains have the positions of the atoms an a bunch of other metadata, but importantly they do _not_ have the actual bonds for the molecule in question. So if I want to calculate the 3d positions from the chemical bonds then that rather presents an issue.\nThere is an open source package openbabel that purports to do this and so I ran it against the whole dataset, which took about 10 hours. \nThe dataset contains many things, not just single small molecules with simple bonds. There are ionic compounds, wack compounds, compounds with nobel gasses in them (??), all kinds of stuff. So some exploration and filtering is in order.\n\n# Exploration\nThe quality of this dataset seems to be pretty weird. In addition to this the openbabel tool is _highly_ suspect in its smiles output. \n\n###  Case study: Urea\nThe chemical formula for [Urea](https://www.crystallography.net/cod/2003112.html) is `C H4 N2 O` and it looks like this:\n![[Pasted image 20230717073831.png]]\nYet apparently the smiles string for it is `O=[C]N` which is clearly wrong. In addition to this it's actually present in the database like 20 times (with the same formula each time). Owait, apparently you can omit the hydrogens. I hate it when chemists be doing that.\n\n## Multiple molecule crystals\nMany crystals contain a few different molecules in their structure, and obvious example being water in all the transition metal salts. There are lots of these in the database like [this monstrosity](https://www.crystallography.net/cod/1554640.html) which looks like this:\n![[Pasted image 20230717074405.png]]\nI think it should be possible to detect this using the SMILES string but it looks like there's a convention for this in the atomic formula field of the CIF file, a \",\", like so:\n```\nC42 H36 N4 O2 Pt2, C H2 Cl2\n```\nand so we should be able to detect and reject most of these on that basis.\nNot always, though. [here](https://www.crystallography.net/cod/2022019.html) is an example where that is not the case. Apparently the smiles string for this is `O[C]=O.O`, although I have no idea what that means.\n[Here](https://chemicbook.com/2021/02/13/smiles-strings-explained-for-beginners-part-1.html) is a good webpage on smiles strings, and it says that \".\" indicates disconnected structures which does indeed correctly identify the previous crystal as having two bits.\n```python\n    single_molecule_subset = {k: v for k, v in small_subset.items() if '.' not in v['smiles']}\n```\nSuggests that around 25% of the crystals have more than one molecule in them. \n## Hydrogen\nIt seems that in a SMILES string hydrogens are optional. The string `n1nccnc1N` represents this guy:\n![[Pasted image 20230717082014.png]]\nFor example, which is also `C3 H4 N4`. I guess since it still has all the information then that's fine and any neural net will just learn about explicit hydrogens. The xyz position for this particular example contains 11 entries to the hydrogens are present in the output.\n\n## Bond distances\nSince the goal here will probably be to generate a distance matrix, exploring the variablility of how close atoms are to other atoms seems like a good idea. Here is a table for all \"organic\" compounds with \u003e2 atoms showing the closes atom to each other atom:\n![[Pasted image 20230720085302.png]]\nLooks pretty interesting, the nice few-mode distributions all over the place are I presume indicative of double and single bonds and whatnot. There are also a few supposedly impossible things like the H-H bond. The H-C plot doesn't looks very interesting above but looks like this when you zoom in:\n![[Pasted image 20230722093838.png]]\nwhich is pretty cool. X axis is anstroms.\n### H-H molecule\nAs an exercise into investigating anomalies, let's look at those molecules where the closest atom to a hydrogen was another hydrogen.\n[Here](https://www.crystallography.net/cod/1503863.html) is one example of such a compound:\n![[Pasted image 20230722094318.png]]\nand [another](https://www.crystallography.net/cod/2232246.html):\n![[Pasted image 20230722094347.png]]\nand [another](https://www.crystallography.net/cod/4109267.html):\n![[Pasted image 20230722094503.png]]\n[One final](https://www.crystallography.net/cod/2232246.html) one which juuust might be a real compound:\n![[Pasted image 20230722100858.png]]\n## O-O bonds\nUnlike the H-H case, O-O bonds can be legit from peroxides or whatever. But most of the cases in this dataset seem to be garbage, [e.g.](https://www.crystallography.net/cod/7055813.html):\n![[Pasted image 20230722102707.png]]\nLooks like a nitrite group was duplicated or something there. [This](https://www.crystallography.net/cod/7112739.html) one here looks like it might be a nitrate (NO3-):\n![[Pasted image 20230722102837.png]]\nUntil you look at a real nitrate and realise that's [not how they be](https://en.wikipedia.org/wiki/Nitroglycerin#/media/File:Nitrogylcerin_(3D_ball-and-stick_model).png):\n![[Pasted image 20230722102914.png]]\n.\n\n## What to do.\nThese errors in the crystallography database are particularly obvious because they are clearly physically impossible. But if there is a high incidence of errors like this then of course that means that errors that are harder to spot are even more prevalent than this, and so this whole database is rather questionable\n\n# Possible reasons for discrepancies.\nHere is a chemical that you would think is totally impossible to screw up: butane:\nhttps://www.crystallography.net/cod/1511809.html\nand yet it only shows two carbon atoms in the unit cell. I asked chatGPT about it and it had this to say:\nhttps://chat.openai.com/share/994735bd-a1eb-4720-a8ea-f77297bc00f8\nso it looks like the CIF file format can show just a subset of the molecule and then apply various symmetry operations to define the full molecule. How frustrating.\nBoth openbabel and gemmi do not take this symmetry into account and apply it to get the full molecule out. the CIF file specifies the symmetries that need to be applied to this sub-molecule to obtain the unit cell of the crystal:\n```\n_symmetry_equiv_pos_as_xyz\n'x, y, z'\n'-x, y+1/2, -z+1/2'\n'-x, -y, -z'\n'x, -y-1/2, z-1/2'\n```\nbut wait, to get the whole molecule we need to apply only one symmetry but there are 4 applied here! That's because the unit cell of butane ice apparently is made up of two butane molecules. So which symmetry group needs to be applied to obtain a regular butane molecule?\nI did find a [CIF checking website](http://checkcif.iucr.org/) online though and for this butane it produces this image:\n![[Pasted image 20230722140320.png]]\nSo it looks like this is possible.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230815-New-instrument-new-results":{"title":"","content":"Now that I have obtained a spectrum analyser, work can continue on the [[20230115 FMV4 bringup|radio]] from earlier. The reason that things stalled before was that I was unable to get a good measurement of the gain of an amplifier. Now I didn't obtain a proper VNA which would have ideal, but I did get a screaming deal on a 10MHz-\u003e4.4GHz spectrum analyser.\nThe analyser only has one input with a max input power of 0dBm though so we'll see how long it lasts before I cook it.\nBecause of this limitation the first order of business is making some attenuators to keep everything in range. Here is the first one:\n![[Pasted image 20230814080044.png]]\n![[Pasted image 20230814080051.png]]\n# Looking at a known signal.\nHere is what the FFT of the nanoVNA is when it's outputting a CW \"750MHz\" signal according to my scope:\n![[Pasted image 20230816074820.png]]\nThis is cause it uses all kinds of harmonics to get the performance at higher frequencies. Here is what the same signal looks like on the spectrum analyzer:\n![[Pasted image 20230816075330.png]]\n\nAnd this is what my VCO (with extra capacitance to try to bring down the frequency) looks like:\n![[Pasted image 20230816081526.png]]\n(note the x axis here)\nwith the spectrum analyser:\n![[Pasted image 20230816081843.png]]\nThe display in the top left (not in pic) agrees with the peak wavelength. But it looks like this is not very good at picking up the harmonics or anything else.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230903-Drone-up-and-flying":{"title":"","content":"\n# So far\nDrone assembled:\n![[Pasted image 20230903101229.png]]\nand flying at about 380g. It flies OK but I think I need to tune the PIDs. Only one problem, on my last flight this happened:\n![[Pasted image 20230903101358.png]]\nAnd now one of the motors doesn't work well (after soldering the motor wire through the via to the pad on the other side of the board). It can spin up no problem at low speed, but at high speed it loses thrust and starts oscillating, I don't know why.\n## Debugging\nHere is an oscilloscope trace of a normal motor phase:\n![[Pasted image 20230903101621.png]]\nWhere you can see that regular trapezoidal pattern. All the motor phases for a normal motor look like this.\nAnd here are the three motor phases for the bad motor:\n![[Pasted image 20230903101838.png]]\nWe can see here that only one of the phases has that trapezoidal shape. All the other ones are plain square waves.\nA further piece of information: the busted motor phase of the bad motor is not fully disconnected: if I desolder it completely the motor doesn't spin up at all. So I wonder if what is happening is that either the p or the n FET of that half bridge is busted. This theory is bolstered by how there is a second via inside the pad of the motor phase that had the pad ripped off. One of the vias is large and I can fit a wire into it to solder to it. The other is small and I can't. I wonder if the small via leads to the other polarity FET.\n...This turns out not to be the case. soldering the motor phase to only one of the vias produces the same effect as soldering to both. Also they are shorted together\n### The moment of failure\nHere is what the motor phases look like when they go from commutation properly to juddering:\n![[Pasted image 20230903112512.png]]\nHere Channel 2 (purple) is the ad motor phase.\nI don't know what this means. I think though that the purple arc might be the back emf more than anything else.\n![[Pasted image 20230903113756.png]]\nI took the propeller off the motor and spun it up to full speed no prolem. This is what the waveform looks like. A bit misshapen, but nothing obviously bad. Occasionally when spinning up the motor with no load, it loses commutation in a manner similar to when it has a propeller attached. Here is an example of that happening:\n![[Pasted image 20230903115027.png]]\n\n#### side note\nThe antenna on that AIO is 32mm long and made of 0.4mm enameled wire.\n\n## The resolution\nAfter some more debugging where I measured the FETs of the half bridge (diode drops and resistance) and found them to be  totally normal I did the obvious thing that I should have done ages ago and swapped the motor to a different ESC. Turns out it was the motor.\n\nI had no idea it was possible for a visually perfect, no grinding when spinning, even resistance between phases motor to give unreliable performance like that. Oh well.\n\n## The crash\nThe drone now looks like this:\n![[Pasted image 20230903202300.png]]\nwhich as far as I could tell came as a result of the controllers freaking out when I tried to pull out of a fast(ish) turn. The PID's had not been tuned at all, so that one is on me I guess. I only had parts spare for one arm but two were broken in this crash, so now might be a good time for a redesign.\n\nOne other thing to note was that I had previously broken off a bunch of the legs so there was no crumple zone. The next design should have more of that I think. The current legs aren't good at absorbing shock too I feel.\n\nIn the next design I'm not sure whether to add more durability or more manufacturability. I think the latter. There's not really any such thing as a durable drone when it's this lightweight though. (or is there? maybe some super thin carbon fiber?)","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230909-Drone-wire-size":{"title":"","content":"# What size should your drone wires be?\n$$\\sqrt[4]{\\frac{i^2 \\cdot \\rho}{\\pi^2 \\cdot e \\cdot d}}\n$$\n- i: Current(A)\n- $\\rho$: conductivity ($\\Omega \\cdot m$ ): Probably copper, 1.77e-8\n- r: radius of wire (m)\n- e: Efficiency of your drone motor+prop combo (watts/kg). A high efficiency drone might be 100w/kg\n- d: Density of conductor (kg/m3): Probably copper, 8960.\n\nThat's it. Any lighter and the motors would be dissipating excess power. Any heavier and the wires will weigh you down. Notice that huge fourth root there - the wire size goes up very slowly!\nDon't forget that the current experienced by a given phase of a motor is battery amps / num motors * 2/3. My optimum wire radius is 0.23mm. When I backcalculate the power dissipated at that diameter with the wire length of my drone I get 200mW which sounds plausible.\n\nHere is the working out for this formula:\n![[Pasted image 20230909135401.png]]\n\nI suppose you could make this analysis more complicated since the efficiency changes with thrust etc. This seems good enough to pick a gauge though.\n\n## It's 2023\n![[Pasted image 20230909140801.png]]\n...goddammit.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230914-Printified-and-plasticised-drone":{"title":"","content":"# Previous design\nWithout any particular rigor or anything else, in my [[20230903 Drone up and flying|previous]] design of drone I went for the Aluminium-honeycomb-Aluminium sandwich structure on the basis that everyone knows that it's the highest strength to weight system that you can get.\nThat may be true, but I think that for my application it's overkill sendcutsend.com's minimum aluminium thickness is 0.6mm, which for a drone that was designed to keep 140g of Li-ion cells in the air is actually total overkill.\n## Less fancy, more print\nInstead, why not just print the whole thing? A couple hours of designing later, and I came up with something where each arm weighs a mere 11g and the frame as a whole weighs 72.9g:\n![[Pasted image 20230917131924.png]]\nContrast this with the old design where (bolts included) each arm weighed 25g. The middle weighed a bit less I think, but still overall the new design is clearly lighter and easier to assemble. \nThe new frame is sized to hold 9\" props, although I actually only have 8040 props right now.\nThis is a pretty decent improvement on the previous system not just because of the absence of Al plating on the top and bottom, but also because of how many fewer bolts are required.\nThe old design had three bolts on the top and the bottom of each side, for a total of 4\\*2\\*8 = 64 bolts for the inside of the frame. In addition to this to keep the honeycomb structure together, there were 4 bolts on the end of each of the arms (so another 16):\n![[Pasted image 20230917132316.png]]\n80 bolts is a _lot_\nThe new design uses 4. One to secure the dovetail joint that each of the arms have. The regular nozzle size for a 3d printer is 0.4mm, and printing each arm with even a single wall of thickness resulted in something like a 20g part. No good at all. Printing with a 0.2mm nozzle gives acceptable results, but means each arm takes like 8 hours to print on my ender 3 v2.\nThe new 11g also includes reinforcement on the interior of the print that I had to put in manually. here is an image of the arm during printing:\n![[Pasted image 20230917133119.png]]\nWhere you can see the regular grid pattern of the infill and my manual support lines radiating out from the dovetail joint. This is absolutely required of course, the arms attachment is pathetically weak without it. There is corresponding reinforcement on the inside of the drone:\n![[Pasted image 20230917133319.png]]\nwhich increased its weight to like 25g (ouch). I don't think that I placed the reinforcement particularly well here, though.\n## Failure modes\nThe new drone definitely performs better - hovering requires about 5.5/6 amps, as opposed to about 7.5 with the previous iteration. Not bad, but not stunning either.\nI'm using [Samsung 40T](https://www.18650batterystore.com/en-au/products/samsung-40t) batteries at the moment (4Ah capacity), which gives me a flight time of like 40 minutes. They have a great discharge rate of 35A, but I don't really need that I think. Something like the [Samsung 50S](https://www.18650batterystore.com/products/samsung-50s-21700-5000mah-25a-battery) which has a 5Ah rating seems more appropriate. I don't know if I'll bother to buy some just yet, though. I still think the propellers warrant some more attention.\n\n## Impact resistance\nI flew the new version of the drone for a total of about half an hour of air time before it died.\nI hit some foliage going sideways slowly at an altitude of about 1.5m. Interestingly the failure mode was that the screw holding in the dovetail joint tore out - I did not expect this!\nYou can see here though that the slicer got a bit excited and decided to turn one of my reinforcing bits into a notch:\n![[Pasted image 20230917140825.png]]\nwhich I am sure did not help its strength. \nSomething to note for the next version, then.\n\n\n## The next version\n\nThis version was printed on a new bambu lab P1P using a 0.4mm nozzle. I have a 0.2mm nozzle but changing it looks to be such a pain that I haven't. With this new printer and nozzle size it takes me 3 hours to print the entire drone as opposed to 7 hours to print one arm. Noice.\n\nHere is what it looks like:\n\n![[Pasted image 20230924201309.png]]\n\nI wrote some notes on how I adjusted the print settings [[20230928 Communicating structural parts for Bambu lab|here]], but although the bambu lab slicer took way more effort to get working I think that the final result is better. The double solid dovetail is far far stronger than what came before it. How much of an actual advantage that is is up for discussion though.\n\nA few minutes into flying this new version I crashed it and the end of the arm crumpled like this:\n\n\n![[Pasted image 20230924201524.png]]\n\nThis actually bent the bottom of the motor because the screws were attached so well to the internal print that the impact with the bottom of the arm bent everything. Maybe I should print the arm side of the dovetail with no reinforcement so that it snaps off there.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230917-Neato-D3-lidar-teardown":{"title":"","content":"# Outside\n![[Pasted image 20230918075520.png]]\n![[Pasted image 20230918075533.png]]\n\n# Inside\nThis is actually upside down with respect to the ground I think:\n\n![[Pasted image 20230918075824.png]]\n\nThe Tx is in an oddly long enclosure. Overall this bears a _striking_ resemblance to an RP-lidar that I've seen previously:\n\n![[Pasted image 20230918080130.png]]\n\n## Baseboard side:\n\n![[Pasted image 20230918080346.png]]\n\nYou can see here a tx led and an rx photodiode. The opposite side has the same thing, so presumably they operate at a bit different wavelength with a bandpass filter on the photodiode. You can buy photodiodes with bandpass filters for pretty cheap for stuff like TV remotes.\n\n## Communications\nI was going to leave the teardown at that but there's actually an extremely convenient and labelled 0.1\" header strip located on the spinning board:\n![[Pasted image 20230918080439.png]]\nI soldered to this and powered it on and it drew around 20mA of current. Spinning the lidar by hand you can see that there are around a dozen encoder pulses per revolution. I suspected that there was a laser safety interlock style thing preventing it from operating any further, so I provided a fake encoder signal via the waveform generator on my scope and the lidar immediately began to draw 200mA, which was very encouraging.\nSadly still no light coming out of the Tx, though. I can connect to the tx with a bench supply from the connector of course and verified that it was outputting in the infrared using a realsense camera (which has no IR filter on it).\n\n\n## Tx (Photons)\n\nHere is he \"VTX\" labelled waveform on oscilloscope:\n\n![[Pasted image 20230917194416.png]]\n\nGreen: fake encoder\nPink: Tx signal\nShining light on the rx with the emitter of a realsense didn't get anything to happen.\nHere is the firing behaviour of  the laser: once on each encoder edge:\n\n![[Pasted image 20230917194545.png]]\n\nNice and simple! This only seems to happen for a limited range of encoder frequencies, and there's also some hysteresis where if you power cycle the unit while applying an encoder signal it might go from no lock-\u003ea lock. I was hoping that when the tx firing synced itself to the encoder edges that would indicate that the firmware was happy and begin firing, but this appears not to be the case. It probably requires an extremely specific encoder frequency to get things to work and I can't be bothered with all that.\n\n# Tx (comms)\nIr picture of data being sent out:\n\n![[Pasted image 20230917202458.png]]\n\nExtremely terrible trace from a photodiode measuringthe tx light:\n\n![[Pasted image 20230917203538.png]]\n\nGiven that it's taking a measurement once per encoder edge it seems pretty clear that it's just sending out the distance it receives each time. Maybe the distance is encoded as a pulse width, maybe it's some kind of serial thing.\n### It's a serial thing\nTaking the thing apart a little further exposes the tx led. The waveform looks like this:\n\n![[Pasted image 20230917204707.png]]\n\nIt's changing all the time, but it's not clear if it's a distance measurement.\n\nAnyway, I still can't get the laser to fire. I'm sure that there's some encoder speed based laser safety thing going on here where if the motor is spinning at the exact right speed the laser will fire and won't otherwise.\n\n# Rx (photons)\nInterestingly the lens has at least two elements to it:\n.\u003cdiv style=\"float: left; padding: 2px 2px 2px 2px;\"\u003e![[Pasted image 20230918081359.png|200]] \u003c/div\u003e\u003cbr\u003e\u003cdiv style=\"float: left; padding: 2px 2px 2px 2px;\"\u003e![[Pasted image 20230918081431.png|200]] \u003c/div\u003e\n\u003cdiv style=\"clear: both;\"\u003e\u003c/div\u003e\nThe actual Photo-whatever itself is stuck behind epoxied on screws and I can't get to it for the moment. The RP-lidar looked like this though:\n\n![[Pasted image 20230918082940.png]]\n\nWhich is a lidar CMOS sensor. Given the angle between the Tx and the Rx (notice they are bent together slightly in above pics) the position of the spot on the sensor indicates how far away something is:\n\n![[Pasted image 20230918083336.png]]\n\nSince a lens is an object that transforms the incoming angle of light to a location at the focal plane.\n\n\n## Power transfer\nhere is the RF coil that transfers power across the gap:\n\n![[Pasted image 20230918081135.png]]\n\nI have attached it here to some coax like so:\n\n![[Pasted image 20230918081215.png]]\n\nSo as to be able to measure the Bode plot using my oscilloscope:\n\n![[Pasted image 20230918073936.png]]\n\n23dB of gain. Something something turns ratio. \n\n![[Pasted image 20230918074257.png]]\n\nThis is indeed a \"real\" measurement, when I take the coils out from each other the peak disappears.\nSanity check measurement where I put in a single frequency at 1.6MHz:\n\n![[Pasted image 20230918074618.png]]\n\nNoice.\nInterestingly, when I take the ferrite core out nothing much seems to change. Maybe that only has an effect under load or something?\n\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230917-Thrust-stand-again":{"title":"","content":"# New current measurement\n[[20230325 Thrust stand|Previously]] I constructed a thrust stand, however the measurements that it spat out were highly suspect and noisy.\nI have a hantek power supply that has a serial port and I thought I would use it to get current measurements so as to get better data. The serial port interface is incredibly bad, it drops packets all the time, is slow to update etc. But it does eventually settle on a correct measurement. And I can use an arduino to send out the pwm signal to the ESC.\n\n# Propellers\nThese are the propellers that I had on hand:\n![[Pasted image 20230917164110.png]]\nSome of them are from master airscrew, the bottom one is from some aliexpress site and the others I printed with a piece of parametric propeller design software I found on thingiverse.\n# Motors\nI only had two motors to be tested:\n- [SunnySky X2204 1480kv](https://sunnyskyusa.com/products/sunnysky-x2204-brushless-motors)\n- [SunnySky X Series V3 X2302](https://sunnyskyusa.com/products/sunnysky-x2302)\nHere is the thrust test stand data for both of them:\n![[Pasted image 20230917164656.png]]\nNow they seem to be measuring more or less correct. Here is the manufacturer data for the 2204 with an 8040 prop again:\n![[Pasted image 20230917164820.png]]\nThe data for the 2302 doesn't look correct though. The manufacturer has it at 13.2g/w with 100g thrust, 8043 prop:\n![[Pasted image 20230917165114.png]]\nweird.\n\n# Even moar propellers\n\nI printed up a nice big batch of propellers:\n\n![[Pasted image 20230924201733.png]]\n\nThat I generated using an iterated version of the script that I think originated [here](https://www.techmonkeybusiness.com/articles/Parametric_Propellers.html). \n\nNone of them seem any good though. In the below plot the above propellers are marked with an 'x' (I didn't measure them all) and the ones from the above dataset have an 'o':\n\n![[Pasted image 20230924202242.png]]\n\nThe format of the printed propellers is 'print\\_{diameter in inches}\\_{pitch in inches}\\_{chord in mm}'\n\nDismal. Just dismal. I had high hopes in particular for the last printed one which was D10 p2. I spent a little bit of extra time adjusting  chord as a function of radius function, as well as increasing the thickness a tad because the other propellers seemed a bit thin and flappy. \n\n![[Pasted image 20230924202504.png]]\n![[Pasted image 20230924202517.png]]\n\nI guess the lift/drag ratio probably just came out terrible.\n\n## Efficiency\nAs I understand it drone propellers operate at low reynolds numbers, mostly because they are tiny compared to e.g. aeroplane wings. I thought that perhaps given that I was 3d printing these I would be able to produce a large hollow prop that was both lightweight (since it's hollow), large diameter and stiff. I think I did do that, it just turns out such a propeller isn't any good. \nChatGPT tells me that as the reynolds number decreases, the relative penalty for thickening a propeller actually increases. So a thick airfoil designed for high reynolds numbers is worse than a thick one designed for low reynolds numbers. That's the opposite to what I would have thought, but it does seem to be true.\n\n### Another off the shelf 8040 propeller\n\n![[Pasted image 20231016080548.png]]","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230920-Communicating-structural-parts-for-Bambu-lab":{"title":"","content":"Note: Actually I'm using OrcaSlicer. There doesn't appear to be much difference in practice.\n\n# Problem\nYou have a structural part that you would like to\n1) Be strong\n2) Be light.\nLike this drone arm, for example:\n\n![[Pasted image 20230922203933.png]]\n\nTaking a closer look at where the drone arm joins the body:\n\n![[Pasted image 20230922204213.png]]\n\nObviously there are going to be very concentrated loads where the dovetail meets the arm. When you slice the arm it looks like this by default in the slicer:\n\n![[Pasted image 20230922204403.png]]\n\n\nThis is clearly wildly inappropriate. \nWe would like to print a bunch of support ribs on the inside so it is nice and strong, like this:\n\n![[Pasted image 20230922204518.png]]\n\n(That's an earlier model with one dovetail)\n\n## Bambu lab/Orca slicer/Prusa slicer 'regions'\nI communicated this to cura slicer no problem by placing voids at the right locations in solidworks. If you try this in Bambu lab it fails miserably, there seems to be some kind of issue printing stl files with inclusions.\n\nThere is a better way though - Bambu lab has provisions where you can [combine different stl files together and give them different properties](https://wiki.bambulab.com/en/software/bambu-studio/how-to-set-slicing-parameters#modifiers).\nYou can two this in one of two ways that are relevant here, where one STL file is the plain drone arm and another are the support ribs or whatever that you wish to add.\n- Have the support STL be a 'negative part'\n- Have the support STL be a 'modifier'.\nFollowing on from what worked in the cura slicer you would think that the first option is what you want. But no. The bambu studio will generate a pile of junk around the bottom of the supports that add weight:\n\n![[Pasted image 20230922205409.png]]\n\nHere we can see both the unnecessary junk and also the new nasty thing - the slicer will tend to route perimeter lines continuously which will split up the support ribs. As far as I can tell both of these things are insurmountable in the 'negative part' mode.\n\nInstead what we can do is have the support STL be a 'modifier', and then have those sections of the arm printed with 100% infill. This works much better. There are two types of infill though - solid infill and sparse infill. If you print with solid infill you will get something like this:\n\n![[Pasted image 20230922205732.png]]\n\nWhere the 'supports' don't actually attach to anything.\nIf you print with 'sparse infill' you can get something like this:\n\n![[Pasted image 20230922210058.png]]\n\nwhich is kind of better, but again not great.\nBased on the above results I added a third modifier STL that just covered the volume of the dovetail since that was the weak point. Here is what that looks like in the slicer and printed out:\n\n![[Pasted image 20230922210618.png]]\nIn red here we can see that the sparse infill still doesn't attach to the part that we want on the dovetail. It does attach quite well however to the actual perimeter wall (orange). And we can see in purple that the 100% infill worked pretty well.\nA side note here for people actually printing - two very relevant settings are the 'minimum sparse infill threshold' and the 'maximum length of the infill anchor':\n![[Pasted image 20230922210957.png]]\nThe former in particular can be set to a very high value on a modifier stl so that the part is converted entirely to solid.\n### Both sparse\n--At this point my notes have caught up with my progress--\nHere is what happens when you make both the supports and the infill area sparse:\n![[Pasted image 20230922212101.png]]\nta-da! This looks very promising - contiguous lines are made between the support struts and the base. I shall print this right away!\n\nAfter printing, the results look like this:\n\n![[Pasted image 20230923190610.png]]\n\nMuch better! when I attached the arm to the base and flexed it to failure it failed via buckling. I actually think I went too far with the reinforcement and need to back it off. The bucking failure occurred I think because this section of the bottom of the arm:\n\n![[Pasted image 20230923190741.png]]\n\nNever actually attached to the wall (which I confirmed in the slicer) and so when it went under compression the bottom tape bit buckled early as it wasn't attached. \n\nAt this point I think that I have things down pretty well and I can do a run of prints and assemble the drone again for flying.\n\nOverall I don't think that I've done that well though - The arm is still like 2g heavier than the one printed with the cura slicer (with 0.2mm nozzle size). The middle is about the same weight, but the cura one was not very well optimised I think. The arms do seem quite a lot stronger though.\n\nI might try printing arms with the 0.2mm nozzle that I bought in a while, but unless you buy the bambu complete hot end assembly thing changing the nozzle is a massive pain as you have to thermal paste the new heater + thermistor on etc.\n\nOne other thing I think I can do is change the cross section of the arm to a vertical ellipse. This will reduce drag from the propellers, reduce material because the cross section is smaller but then also reduce it because the top of the arm won't be flat and as such won't have a big strip of material like this:\n\n![[Pasted image 20230923191413.png]]\n\nwhich is clearly a very inefficient use of filament. I should be able to save 1-2g of material per arm here I think.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20230928-Communicating-structural-parts-for-Bambu-lab":{"title":"","content":"Note: Actually I'm using OrcaSlicer. There doesn't appear to be much difference in practice.\n\n# Problem\nYou have a structural part that you would like to\n1) Be strong\n2) Be light.\nLike this drone arm, for example:\n\n![[Pasted image 20230922203933.png]]\n\nTaking a closer look at where the drone arm joins the body:\n\n![[Pasted image 20230922204213.png]]\n\nObviously there are going to be very concentrated loads where the dovetail meets the arm. When you slice the arm it looks like this by default in the slicer:\n\n![[Pasted image 20230922204403.png]]\n\n\nThis is clearly wildly inappropriate. \nWe would like to print a bunch of support ribs on the inside so it is nice and strong, like this:\n\n![[Pasted image 20230922204518.png]]\n\n(That's an earlier model with one dovetail)\n\n## Bambu lab/Orca slicer/Prusa slicer 'regions'\nI communicated this to cura slicer no problem by placing voids at the right locations in solidworks. If you try this in Bambu lab it fails miserably, there seems to be some kind of issue printing stl files with inclusions.\n\nThere is a better way though - Bambu lab has provisions where you can [combine different stl files together and give them different properties](https://wiki.bambulab.com/en/software/bambu-studio/how-to-set-slicing-parameters#modifiers).\nYou can two this in one of two ways that are relevant here, where one STL file is the plain drone arm and another are the support ribs or whatever that you wish to add.\n- Have the support STL be a 'negative part'\n- Have the support STL be a 'modifier'.\nFollowing on from what worked in the cura slicer you would think that the first option is what you want. But no. The bambu studio will generate a pile of junk around the bottom of the supports that add weight:\n\n![[Pasted image 20230922205409.png]]\n\nHere we can see both the unnecessary junk and also the new nasty thing - the slicer will tend to route perimeter lines continuously which will split up the support ribs. As far as I can tell both of these things are insurmountable in the 'negative part' mode.\n\nInstead what we can do is have the support STL be a 'modifier', and then have those sections of the arm printed with 100% infill. This works much better. There are two types of infill though - solid infill and sparse infill. If you print with solid infill you will get something like this:\n\n![[Pasted image 20230922205732.png]]\n\nWhere the 'supports' don't actually attach to anything.\nIf you print with 'sparse infill' you can get something like this:\n\n![[Pasted image 20230922210058.png]]\n\nwhich is kind of better, but again not great.\nBased on the above results I added a third modifier STL that just covered the volume of the dovetail since that was the weak point. Here is what that looks like in the slicer and printed out:\n\n![[Pasted image 20230922210618.png]]\nIn red here we can see that the sparse infill still doesn't attach to the part that we want on the dovetail. It does attach quite well however to the actual perimeter wall (orange). And we can see in purple that the 100% infill worked pretty well.\nA side note here for people actually printing - two very relevant settings are the 'minimum sparse infill threshold' and the 'maximum length of the infill anchor':\n![[Pasted image 20230922210957.png]]\nThe former in particular can be set to a very high value on a modifier stl so that the part is converted entirely to solid.\n### Both sparse\n--At this point my notes have caught up with my progress--\nHere is what happens when you make both the supports and the infill area sparse:\n![[Pasted image 20230922212101.png]]\nta-da! This looks very promising - contiguous lines are made between the support struts and the base. I shall print this right away!\n\nAfter printing, the results look like this:\n\n![[Pasted image 20230923190610.png]]\n\nMuch better! when I attached the arm to the base and flexed it to failure it failed via buckling. I actually think I went too far with the reinforcement and need to back it off. The bucking failure occurred I think because this section of the bottom of the arm:\n\n![[Pasted image 20230923190741.png]]\n\nNever actually attached to the wall (which I confirmed in the slicer) and so when it went under compression the bottom tape bit buckled early as it wasn't attached. \n\nAt this point I think that I have things down pretty well and I can do a run of prints and assemble the drone again for flying.\n\nOverall I don't think that I've done that well though - The arm is still like 2g heavier than the one printed with the cura slicer (with 0.2mm nozzle size). The middle is about the same weight, but the cura one was not very well optimised I think. The arms do seem quite a lot stronger though.\n\nI might try printing arms with the 0.2mm nozzle that I bought in a while, but unless you buy the bambu complete hot end assembly thing changing the nozzle is a massive pain as you have to thermal paste the new heater + thermistor on etc.\n\nOne other thing I think I can do is change the cross section of the arm to a vertical ellipse. This will reduce drag from the propellers, reduce material because the cross section is smaller but then also reduce it because the top of the arm won't be flat and as such won't have a big strip of material like this:\n\n![[Pasted image 20230923191413.png]]\n\nwhich is clearly a very inefficient use of filament. I should be able to save 1-2g of material per arm here I think.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231003-Drone-PID-tuning":{"title":"","content":"\n![[Pasted image 20231003211250.png]]\n\n![[Pasted image 20231003211258.png]]","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231022-Neural-nets-memory-notes":{"title":"","content":"![[Pasted image 20231022144235.png]]\n\n![[Pasted image 20231022144241.png]]\n\nIt turns out that this is already a thing of course. Terms of art are :\n\n- Differentiable neural computer - This is distinct from the above in that the DNC seems to have its memory initialised for each problem (i.e. it does not start off as a database of knowledge) and it also seems that the memory controller recurses over it.\n- In addition it does the same thing I think from [reading the paper](https://arxiv.org/pdf/1807.08518.pdf) where the attention is applied as a multiplication/dot product/whatever across the entire memory space rather than being truly sparse.\nI think the thing at this point that isn't obvious is how to make a sparse learned attention to even be differentiable.\nOther things to look for here are 'memory augmented transformers'.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231022-faster-filament-extruder.":{"title":"","content":"\nLots of the time it seems that the limiting factor in FDM 3d printing speed is the filament extrusion rate. This is all done by a gearwheel that shoves the filament into the hot bit to melt it. This has a fundamental limitation though in that it has to heat the filament from the outside in.\n\nYou can see people try to get around this with weirdo 3 core melting nonsense and whatnot. Instead of this though I reckon a small magnetron emitting something in the 10s of GHz would be just the trick as it would heat the filament though.\nI don't know how much of an improvement this would give, though. ","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231101-Vesuvius-challenge":{"title":"","content":"I am faffing about with the vesuvius challenge. At the moment this has been limited to getting chatGPT to generate me my very first autoencoder, which is a simple 3d convolutional model:\n\n```python\nclass Autoencoder(nn.Module):\n    def __init__(self, cube_size: int):\n        super(Autoencoder, self).__init__()\n        self.cube_size = cube_size\n\n        # Encoder\n        layers = 3\n        expansion_init = 32\n        self.encs = nn.ModuleList()\n        self.encs.append(nn.Conv3d(1, expansion_init, kernel_size=3, stride=1, padding=1))\n        for i in range(layers):\n           self.encs.append(nn.Conv3d(expansion_init * 2**i, expansion_init * 2**(i+1), kernel_size=3, stride=1, padding=1))\n        final_expansion = expansion_init * 2**layers\n        \n        self.pool = nn.MaxPool3d(2, stride=2)\n        \n        self.final_side_len = cube_size // 2**(layers + 1)\n        assert(self.final_side_len \u003e 0)\n        self.final_channels = cube_size * 2**layers\n        self.final_paramcount = cube_size**3 // (2**(layers+1))\n        print(f\"Final dimensionality before latent space will be {self.final_channels, self.final_side_len, self.final_side_len, self.final_side_len}\")\n        latent_size = 512\n        # Latent vectors mu and logvar\n        self.fc1 = nn.Linear(self.final_paramcount, latent_size)\n        self.fc2 = nn.Linear(self.final_paramcount, latent_size)\n\n        # Decoder\n        self.dec1 = nn.Linear(latent_size, self.final_paramcount)\n        self.decs  = nn.ModuleList()\n        for i in range(layers):\n           self.decs.append(nn.ConvTranspose3d(final_expansion // 2**i, final_expansion // 2**(i+1), kernel_size=2, stride=2))\n        self.decs.append(nn.ConvTranspose3d(final_expansion // 2**layers, 1, kernel_size=2, stride=2))\n\n    def reparameterize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        eps = torch.randn(*mu.size())\n        return mu + std * eps\n\n    def encode(self, x):\n        for enc in self.encs:\n            x = F.relu(enc(x))\n            x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        mu = self.fc1(x)\n        logvar = self.fc2(x)\n        return mu, logvar\n\n    def decode(self, z):\n        z = self.dec1(z)\n        z = z.view(z.size(0), self.final_channels, self.final_side_len, self.final_side_len, self.final_side_len)\n\n        d1, d2, d3, d4 = self.decs\n        z = F.relu(d1(z))\n        z = F.relu(d2(z))\n        z = F.relu(d3(z))\n        z = d4(z)\n\n        z = torch.sigmoid(z)\n        return z\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        decoded = self.decode(z)\n        return decoded, mu, logvar\n        # return self.decode(z), mu, logvar\n```\n^^That's the slightly upgraded variational version. What I have done is tr y to get it to reconstruct arbitrary 32\\*\\*3 cubes of the scroll, picked from a 'safe' middle region:\n![[Pasted image 20231109080424.png]]\nIn the future if I ever get anywhere with this I can do proper masking of where the scroll actually is.\nHere is what the results look like:\n![[Pasted image 20231109080524.png]]\nwhich seems pretty reasonable to me, considering it was reconstructed from 512 parameters.\n\n\n\n\n# Estimating the ground truth:\nThis did not go very well. I adjusted the last output layer of the 3d convolutional kernel so that it output 2 channels rather than 3. The net then output this after a night of training:\n\n![[Pasted image 20231109080312.png]]\n... it appears that everything that is scroll is white and everything that is ground truth is black. The ol' \"here's the mean of your dataset\" trick. There's no real proper reason why it is that I should be training on the reconstruction as well as the ground truth though, so if I just drop that hopefully that will make it better at training on the ground truth.\n\nI have also added a bit of code that trains on patches that at the edge of ink and no ink, so it doesn't bias too much towards 'no ink' since that's most of the dataset:\n```python\n\ndef get_first_gt_x(out_vol: torch.tensor, out_gt: torch.tensor, path=GT1_PATH, edges=True):\n  gc.collect()\n  # out_vol is a N x 64 x 64 x 64 tensor, because the gt is 64 thick.\n  # out_gt is an N x 64  x 64 tensor from the gt image.\n  # n = out_vol.shape[0]\n  batch_sz, d_sz, w_sz, h_sz = out_vol.shape\n\n  start_y = 4600; start_x = 5800\n  end_y = 7000;   end_x = 9300\n  assert(out_vol.shape[0] == out_gt.shape[0])\n\n  with Image.open(os.path.join(path, 'inklabels.png')) as img:\n    gt = np.array(img)\n    gt = torch.from_numpy(gt).to(torch.float32)\n  size = torch.tensor(gt.shape)\n\n  print(f\"loaded gt of shape {gt.shape}\")\n\n  x_out = torch.randint(start_x, end_x, (batch_sz,))\n  y_out  = torch.randint(start_y, end_y, (batch_sz,))\n\n  if edges:  # Only train on stuff with a bit of 0 and a bit of 1\n    torch.set_default_device('cuda')\n    no_edges = gt.clone()\n    # mask off the edge of the image so we don't index beyond it.\n    no_edges[0:w_sz // 2, :] = 0\n    no_edges[-w_sz // 2:, :] = 0\n    no_edges[:, 0:h_sz // 2] = 0\n    no_edges[:, -h_sz // 2:] = 0\n    edge_x = torch.diff(gt, dim=0, append=gt[-1, :].unsqueeze(0))\n    edge_y = torch.diff(gt, dim=1, append=gt[:, -1].unsqueeze(1))\n    edge = torch.logical_or(edge_x, edge_y)\n    edge_locs = torch.argwhere(edge).cuda()\n    n_edges = edge_locs.shape[0]\n    chosen_indices = torch.randint(0, n_edges, (batch_sz,))\n    chosen_corners = edge_locs[chosen_indices]\n    x_out = chosen_corners[:, 0] - w_sz // 2\n    y_out = chosen_corners[:, 1] - h_sz // 2\n\n  for b_idx in range(batch_sz):\n    out_gt[b_idx] = gt[x_out[b_idx]:x_out[b_idx]+w_sz, y_out[b_idx]:y_out[b_idx]+h_sz]\n\n  for z_idx in range(d_sz):\n    layer = load_tif_cached(os.path.join(path, f\"surface_volume/{z_idx:02d}.tif\"), size.tolist(), check=z_idx==0)\n    for b_idx in range(batch_sz):\n      out_vol[b_idx, z_idx] = layer[x_out[b_idx]:x_out[b_idx]+w_sz, y_out[b_idx]:y_out[b_idx]+h_sz]\n    print(f\"loaded layer {z_idx}\")\n```\n\n\n\n## Effects of residual layers:\nThe implementation of the residual layer courtesy of chatgpt as usual (it got the dims wrong though, also as usual):\n```python\nclass ResidualBlock3d(nn.Module):\n    def __init__(self, in_channels, out_channels, conv_layer):\n        super(ResidualBlock3d, self).__init__()\n\n        # Main path layers\n        self.conv1 = conv_layer(in_channels, out_channels, kernel_size=2, stride=2)\n        self.bn1 = nn.BatchNorm3d(out_channels)\n\n        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n\n        # Shortcut path layer - always using 1x1 convolution\n        if isinstance(conv_layer, nn.Conv3d):\n          self.shortcut = conv_layer(in_channels, out_channels, kernel_size=1, stride=2)\n        else:\n          self.shortcut = conv_layer(in_channels, out_channels, kernel_size=2, stride=2)\n\n    def forward(self, x):\n        residual = self.shortcut(x)\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.conv2(out)\n        out += residual\n        out = F.relu(out)\n        return out\n\n...\n\n        self.encs = nn.ModuleList()\n        self.encs.append(nn.Conv3d(1, expansion_init, kernel_size=2, stride=2))\n        for i in range(layers):\n            in_channels = expansion_init * 2**i\n            out_channels = expansion_init * 2**(i+1)\n            # self.encs.append(nn.Conv3d(in_channels, out_channels, kernel_size=2, stride=2))\n            self.encs.append(nn.Sequential(\n                nn.Conv3d(in_channels, out_channels, kernel_size=2, stride=2),\n                nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm3d(out_channels)\n            ))\n...\n        self.decs = nn.ModuleList()\n        for i in range(layers):\n            in_channels = final_expansion // 2**i\n            out_channels =  final_expansion // 2**(i+1)\n            # either this:\n            self.decs.append(nn.Sequential(\n                nn.ConvTranspose3d(in_channels,out_channels, kernel_size=2, stride=2),\n                nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm3d(out_channels)\n            ))\n            # or this\n            # self.decs.append(ResidualBlock3d(in_channels, out_channels, nn.ConvTranspose3d))\n        self.decs.append(nn.ConvTranspose3d(final_expansion // 2**layers, 1, kernel_size=2, stride=2))\n\n```\n\nHere is my net after training with 1000 iterations, no residual layers:\n\n![[Pasted image 20231118181733.png]]\n\nAnd here is 1000 iterations with residual layers:\n``\n![[Pasted image 20231118181259.png]]\n\nYuuuuuge difference!! The net with no residuals looks like it has flatlined, but it actually hasn't. It seems to train about 10x slower is all.\n\n## Overfitting\nI was training the net on 1000 examples, then reloading a new set of 1000 examples from the scroll every 1000 iterations. That leads to a loss curve that looks like this:\n\n![[Pasted image 20231118183538.png]]\n\nWhen I change this to 10000 examples, I get a loss curve that looks like this:\n![[Pasted image 20231118183749.png]]\n\nso you can see that there is no overfitting already, but also the net has like 10x higher loss! it's about as high as when there were no residual layers! is this a coincidence?\nHere is the net trained on a dataset size of 1e4, with no residual layers:\n\n![[Pasted image 20231118184035.png]]\n\n...about the same as with a dataset size of 1e3 from [[20231101 Vesuvius challenge#Effects of residual layers|before]]. This makes me update rather strongly towards \"residual connections are great for overfitting\" and away from \"residual connections are good for avoiding exploding gradients\".\n\n## Training on ink: initial results\nHere is the result of simply switching the target volume from reconstructing the original to reconstructing the ground truth:\n\n![[Pasted image 20231119083517.png]]\n\nLooks like it's doing a reasonable job of remembering the dataset just like before, although remembering the ink seems to be harder. Still though, it shows there is some correlation between what is desired on the input and what is desired on the output so that's nice.\n\nWhen I leave this to train for an hour or so on parts of the dataset that contain only an edge it actually does quite well. But when I plot the results of this:\n\n\n![[Pasted image 20231119135040.png]]\n\n...yeah, if all it sees is an edge, all it's gonna output is an edge.\n\nOne other thing I'm running into here is loading times - significant parts of the training time are spent loading data. So speeding that  up is a good next step I think.\n\n## Attempt at a proper run\nI got rid of the code for training on only data around edges - I put that in because of the [[20231101 Vesuvius challenge#Estimating the ground truth|garbage]] that I got out before. Here is the loss curve for a true sampling of the input, attempting to reconstruct the output:\n![[Pasted image 20231119142023.png]]\n\nThis too is exhibiting weird behaviors: big spikes, and this super long period of plateauing prior to the net 'picking up' the gradient again. \n\n### Results after a few hours training\nI did this over a couple of different restarts so I don't have a good screenshot of the loss over time, but here is the final result:\n\n![[Pasted image 20231119201743.png]]\n\n...Looks pretty good to me!\n\nHere is what it looks like zoomed in on some random blob:\n\n![[Pasted image 20231119201834.png]]\n\n...so you can see that the boundaries of the model are clearly visible. Presumably this would be improve if a bunch of model outputs were averaged with different offsets. It might also be good to examine the loss as a function of the distance from the center of the cube - if there are edge effects it might be a good idea to discard them.\n\n## Attempt at training on ground truth overnight:\n![[Pasted image 20231120071745.png]]\nLooks like it plaeaued super quick there. This started with a learning rate of 3e-5 and went to 3e-7. it used the background thread data loading technique.\n\nAnd here is what that same model looks like trying to guess where the ink is:\n\n![[Pasted image 20231120072029.png]]\n\noh well.\n\n## ???\nHaving all these weird failures to train made me try to go back and replicate my previous successfull results. Here are the results of training overnight a 32 cube reconstruction:\n\n![[Pasted image 20231203100924.png]]\n\nPretty garbage. I wonder if this is because I had a learning rate schedule that started at 3e-4 and went down to 3e-6. So I will load this model where it stopped and try again with a constant rate of 3e-4.\n\nAnd here is \u003c1 hour of training with a learning rate of 3e-4:\n![[Pasted image 20231203120948.png]]\n\nSo I think that this means that the learning rate towards the end was indeed too small.\n\n## Batch size\nI have been training with a batch size of 256, which is well below the max that will fit in my GPU. There are two reasons to increase batch size:\n- Better utilisation of The GPU since the weights loaded from memory can be used many times\n- Better estimation of the gradient\nThe last one mostly seems bogus to me tbh, so I have not been putting effort into filling up the GPU. My intuition here was basically that the estimation of the gradient would go with sqrt (batch size), so instead of having a batch size of (say) 4, you should have a batch size of 1 and increment a small amount 4 times. IRL you still want a batch size \u003e\u003e 1 because of point 1 about GPU utilisation and so what I have been doing is increasing the batch size until `nvidia-smi` said that I was using as much power as I could.\n\nAs a small and highly invalid experiment, here is me setting a breakpoint during training and setting the batch size from 256-\u003e1024.\n\n![[Pasted image 20231203163621.png]]\n\n...it doesn't look like it is having much effect here. Remember in the same time that I do 1 batch-size-1024 iteration I can do 4 of the 256 variant. I'll keep the experiment running for a bit more just to see what happens though.\nGiven that there was no change in the learning rate from 256-\u003e1024 batch size, this clearly means we need to go lower!\n\n![[Pasted image 20231203182743.png]]\n\nAbove I ran with three different batch sizes. It kind of looks like the mean loss changed with the batch size (I don't know how that could be) but the learning rate didn't really.\n\n## Experiment: learning rate\nHere is a learning rate of 3e-4 overnight:\n\n![[Pasted image 20231205080143.png]]\nLooks it like it just keeps learning! I was actually busy for a few days after this so let it run even longer, and the loss just kept on dropping. From the y axis you can see that the absolute level of improvement is not that great though.\n\n## Distribution\nI haven't been normalising the input to my net. It occurs to me that this is a bad idea. here is a histogram of the density across the whole ground truth scroll (after converting from uint16 to float):\n![[Pasted image 20231206213717.png]]\nhonestly I think my instincts are right here and this is a pretty boring distribution that doesn't need anything done to it for a net to be able to understand it.\n\n\n\nexp about classifying on frozen layers.\n![[Pasted image 20231207082844.png]]","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231124-dead-IR-camera":{"title":"","content":"My infiray-go got put in the wash, and then in the dryer. The dryer got hot enough that it broke the rigid flex. Here is what it looked like after my repair efforts:\n\n![[Pasted image 20231124092400.png]]\n![[Pasted image 20231124092423.png]]\n\n## Cracked flex\nThe edge of the flex where it joined the usb module was cracked:\n\n![[Pasted image 20231124092556.png]]\n\nafter repairing:\n\n![[Pasted image 20231124092615.png]]\n\n## Actually broken flex:\nThis is what the edge of the pcb where the flex snapped off looked like:\n\n![[Pasted image 20231124092654.png]]\n\nAfter sanding it down a bit I got to the ground layer:\n\n![[Pasted image 20231124092821.png]]\n\nA bunch more sanding and careful scraping got the edge of the flex cable exposed:\n\n![[Pasted image 20231124093001.png]]\n\nThe flex cable was two layers with a ground plane. I had to peel back the ground plane to be able to connect it to the other side of the PCB:\n\n![[Pasted image 20231124093144.png]]\n\nThen a jig was made to line the two halves up:\n\n![[Pasted image 20231124093223.png]]\n\nThe blob on the right is the first blob of flux. That fixed the flex in place, and then I started soldering from the other end. Here the first wire is placed down:\n\n![[Pasted image 20231124093351.png]]\n\n## Final repair:\n\nAnd here it is all soldered together:\n\n![[Pasted image 20240628191345.png]]\n\n![[Pasted image 20240628191417.png]]\n\nAnd plugged in:\n\n![[Pasted image 20240628191555.png]]\n\nIt actually showed up as a webcam but I wasn't able to get any images :( it was just all black.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231202-Advanced-motherboard-debugging":{"title":"","content":"I just bought a new computer with a big AMD CPU, but the motherboard only outputs VGA and I have no VGA cables anymore. \n\n\nI do have an oscilloscope though.\n\nSo I can simply read the data out of the scope, like so:\n\n![[Pasted image 20231203183837.png]]\n\nThis is what the vsync and hsync lines look like zoomed in:\n\n![[Pasted image 20231203184259.png]]\n\nand what two scan lines of data look like:\n\n![[Pasted image 20231203184343.png]]\n\nThe full code to extract the frame:\n\n```python\nimport siglent_funcs as sf\n\n\ndef load_and_display():\n    directory_path = '/home/asdf/Downloads/'\n    bin_files = glob.glob(os.path.join(directory_path, '*.bin'))\n    fn = max(bin_files, key=os.path.getmtime)\n    print(f\"loading {fn}\")\n\n    with open(fn, 'rb') as f:\n        dt, volts = sf.extract_data(f)\n\n    vsync, hsync, _, color = volts\n\n    vsync_pulse = vsync - np.mean(vsync)\n    vsync_pulse = np.diff(vsync_pulse, append=[vsync_pulse[-1]])\n\n    frame_boundaries, _ = signal.find_peaks(vsync_pulse, height=0.02)\n    assert(frame_boundaries.size == 2)\n    \n    volts = volts[:, frame_boundaries[0]:frame_boundaries[1]]\n    vsync, hsync, _, color = volts\n\n    hsync_pulse = hsync - np.mean(hsync)\n    hsync_pulse = np.diff(hsync_pulse, append=[hsync_pulse[-1]])\n    hline_boundaries, _ = signal.find_peaks(hsync_pulse, height=0.035)\n\n    manual_sz = int(np.median(np.diff(hline_boundaries)))\n    new_sz = volts.shape[1] - volts.shape[1] % manual_sz\n    volts = volts[:, 0:new_sz]\n\n    vsync, hsync, _, color = volts\n    image = color.reshape((-1, manual_sz))\n\n    plt.figure(figsize=(40, 40))\n    plt.imshow(image, interpolation='none', aspect='auto')\n    plt.show()\n\n```\n\nAnd the results:\n\n![[Pasted image 20231203184647.png]]\n\nTa-da!\n\n...It takes like 30sec to get a new image, but much better than nothing. I was able to get video over to the graphics card with it, at least.\n\nIt's also interesting navigating the bios. Lots of the menu items are arranged vertically which then translates to later in time looking at it live on the scope. So to some extent you can know what you are choosing.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20231209-More-Vesuvius-challenge":{"title":"","content":"The [[20231101 Vesuvius challenge|last]] page was getting a little long so here is a new one.\n\nThe main problem with this whole challenge is the super low snr. So far here has what I have done:\n- Got an autoencoder (and VAE) to reconstruct the input for both the flattened papyrus with ground truth and the rolled up scroll.\n- Failed to train a net directly on the ground truth\n- Tried to do a bit of curriculum learning where the net first learned to classify the parts of the scroll where ink was and was not present first. I successfully overfit on those parts of the dataset but that's about it.\n\n## New experiment:\nHere's an idea: add the ground truth ink labels directly into the input of the net! That will make it really easy to train!\nIndeed it does. Now what I shall do is lower the amount of ink that is added progressively as it trains, like so:\n```python\nassert(len(batch_vol.shape) == 4)\ngt_expanded = batch_gt.reshape((batch_gt.shape[0], 1, batch_gt.shape[1], batch_gt.shape[2]))\ngt_expanded = gt_expanded.expand(-1, batch_vol.shape[1], -1, -1) \ninput_ = gt_expanded * gt_mix_fraction + batch_vol * (1 - gt_mix_fraction)\nreconstructed, mu, logvar = model(input_.unsqueeze(1))\n  \n  ...\n  \nwith torch.no_grad():\n\tloss_scroll = nn.MSELoss()(reconstructed, batch_vol).item()\n\tloss_gt = nn.MSELoss()(reconstructed, gt_expanded).item()\n\tif loss_scroll / loss_gt \u003e 5 and epoch \u003e 100 and gt_mix_fraction \u003e 0:\n\t  gt_mix_fraction *= 0.8\n\n```\n\nThis was inspired by how diffusion models are trained to remove noise. If you think of the scroll cube as 'noise', then maybe gradually swapping out the input ground truth for the scroll gradually over time is training the model to denoise things and not just a silly idea.\n\nThis seems to be working as desired in terms of training:\n\n![[Pasted image 20231209114921.png]]\n\nit has gotten down to 0.03 mix fraction after only a few thousand iterations, although the actual output looks like hot garbage:\n\n![[Pasted image 20231209115134.png]]\n\nSo instead I switched it to decrease the mix fraction every time the loss got below a certain hardcoded number:\n\n![[Pasted image 20231209155617.png]]\n\nThis seems even more promising in that the adjustments are much further apart and are having a clear effect, but I don't know that the improvement on the actual task at hand (extracting ground truth) is any better. If I improved my tool or bothered to learn how the actual pytorch tooling worked I could add additional metrics to track over time, but as-is my spot checks for the loss against the original scroll input are that the curve isn't really bending much over time.\n\nAnd here is the loss curve after training overnight:\n![[Pasted image 20231210073848.png]]\n\nThe model is now successfully not using any of the ground truth at all. Super promising!!!\n\nAnd here are the results of running inference across the whole scroll fragment:\n\n![[Pasted image 20231210140913.png]]\n\nZoomed in on the region where the training data was derived from:\n\n![[Pasted image 20231210141254.png]]\n\nDespite being clearly incredibly overfit to the training data to the point of replicating every last imperfection, this is by far and away the most promising result so far!\nperhaps by adding a smidge more of the actual scroll as training data + augmenting the inputs a lot the net will actually learn something.\n\n## 20240115 Augmentation\nI now trained the network on more or less the same thing, but augmented the dataset with rotations. The training looks like this:\n\n![[Pasted image 20240115155042.png]]\n\n\nWhere I trained it for about 16 hours with the automatically decaying ground truth fraction. The fraction got down to 0.03 whereapon I got bored and manually set it to 0. That resulted in the huge spike in the loss over on the right hand side there, so even at 0.03 the network was still clearly basically only looking at the ground truth.\n\nThe conclusion that I draw from this is that when trained without augmentation the training data for the model is small enough that it can be memorised, and when trained with augmentation it can't generalise to the underlying data.\n\nTo be super confident I think I should make some synthetic data with a \"scroll\" made out of noisy text to see if it can recover the original text.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240208-plasma-toroid":{"title":"","content":"\nTrying to build a plasma toroid following this guide:\n\nhttps://docs.google.com/document/d/1AyaO-RaTiaOmyT3-89UxPdrMHEBCCrxb1irZKsVMg_8/edit\nhttps://docs.google.com/document/d/1-jMPQOSs6-Flp181TTa8cNMSs2XumzDEahg9DVD0hKk/edit\n\nHere is the circuit in LT spice:\n\n![[Pasted image 20240208194901.png]]\n\nMy transistor is a CS9N90 (lcsc special):\n\n![[Pasted image 20240208195012.png]]\n\nMy capacitors are only rated to 50V, and so I get a squealing noise, but the circuit does oscillate:\n\n![[Pasted image 20240208195058.png]]\n\nI wonder why it only oscillates for a while... possibly it is the high voltage on the caps (150V!) that causes them to be lower in capacitance and stop the oscillation.\n\nAfter making a bunch of adjustments and the squealing noise mysteriously disappearing the oscillator seems to work fine:\n![[Pasted image 20240209184425.png]]\nHere I have changed the probing though - it seems that just using a divider does not work very well in this situation for some reason. \n- Yellow is the drain of the FET, probed with the clippy bit of a scope probe.\n- Blue is the gate of the FET probed with the clippy bit attached to a 3cm piece of wire hanging off the gate.\n- Green is the gate of the FET probed using a springen sproingen - clearly way better signal integrity.\nIf this oscillator is going to work as it should then there needs to be zero voltage switching of the FET and so good measurements of the drain and the gate are necessary. So I need to make some high voltage probes.\n\n\n# 500R transmission line\nI just learned that the way that 10x oscilloscope probes work is that they have a special lossy transmission line inside them to do the impedance matching between the 9M probe tip and the 1M scope input. \n\nHere is a video on the topic:\nhttps://www.youtube.com/watch?v=OiAmER1OJh4\n\nIf one could make a 10kR transmission line though, you could have a 10k resistance at the scope and a 1M resistance at the probe tip, and then everything would be all matched and work fine.\n\nLooking at the impedance calculator website [here](https://www.allaboutcircuits.com/tools/twisted-pair-impedance-calculator/), it seems that a 500R transmission line is easily achievable (0.22mm diameter wire wrapped about 5mm diameter insulator) but that going higher is very difficult, on acccount of the log here:\n\n![[Pasted image 20240210121956.png]]\n\nThe test setup is to run a square wave out of the signal generator and terminate it at a pcb with a 50R resistor. From there a 500R resistor takes it into the 500R twisted pair line, and a 500R terminating resistor at the scope (with its 1M input impedance).\n\n\nHere is what it looks like all wound up:\n\n![[Pasted image 20240210122924.png]]\n\n![[Pasted image 20240210122351.png]]\n\nHere the reference trace is the 500R line, the green trace is the 50R resistor probed with a normal 10x probe, and the yellow is a standard 50R coax line. I was hoping to see some reflections off the coax line, but I guess not :(\n\nChanging the probing resistor to 50kR gives this:\n\n![[Pasted image 20240210141559.png]]\n\n...There seems to be too much noise pickup for anything useful. When I turn on the toroid oscillator it's totally unusable.\n\n## Back to the circuit\nI went to Home depot and bought a circular fluorescent bulb. The bulb lit up! Then I took apart the circuit and put it back together again. It looks like it is performing much better now:\n\n![[Pasted image 20240210181235.png]]\n\n- Ref: drain (the nice pulse)\n- Green: gate of the FET\n- yellow: some resistor sticking out of one channel of the scope that I am using to trigger.\nSo I am getting pulses at 120V! But now the fluorescent bulb no longer lights up :(. The big rf coil is next to a large aluminium heatsink though, I wonder if it is somehow reacting with that and losing energy.\n\n## Zero voltage switching (ZVS) simulation\nI found [another](https://docs.google.com/document/d/12zzin_l4TYB7Etak3atULsMw10s3H--E5xJSFTTWbV8/edit) good document about the operation of ZVS. Here is what is has to say on the topic of ZVS:\n![[Pasted image 20240212074546.png]]\n\nAnd here is the operation of the circuit in LT spice:\n\n![[Pasted image 20240212074901.png]]\n\nWhat I do not understand here is when the MOSFET goes open. It clearly happens when the gate voltage is just starting to rise up to around 0. But is this because of ZVS, or because that's just how MOSFET's work so of course that happened/\n\n### puzzling observation 1\n\n![[Pasted image 20240212081310.png]]\n\ncircuit at the time of the above screenshot;\n![[Pasted image 20240212081358.png]]\n\n\n\n## New circuit\n\nI made a new circuit that looks like this:\n![[Pasted image 20240219213949.png]]\n\nwhere the FET can be driven open loop - the feedback path is closed. That way hopefully we can observe what the actual resonant frequencies are and check that   ZVS is a thing.\n\n## The drain at open loop.\n\nProbing the drain of the FET looks like this:\n\n![[Pasted image 20240219200610.png]]\n\nWhich is 1MHz - far below the supposed 10MHz of the tank circuit!\n## Impedance\n\nHere is the impedance of the big coil and the 130p cap tank circuit:\n\n![[Pasted image 20240219213023.png]]\n\nwhich looks absolutely perfect - 0 resistance at 11Mhz. Since the tank circuit is disconnected from the main circuit I took the liberty of probing the drain of the FET without the tank circuit attached and got the exact same measurement - so  I guess what is happening here is the input choke is forming a tank with the FET capacitance.\n\n## Voltage in the middle of the tank circuit\n\nHere I have added the main inductor and capacitor back in, and am probing in between the inductor and capacitor:\n![[Pasted image 20240220194627.png]]\nThat looks much more correct. \n\n## Pulse train\nIt turns out if you drive the MOSFET driver at 10MHz with this kind of load it burns out after a few 10s of seconds. So I set up the signal generator to generate a pulse train. Here I have tried pulse trains of frequency 10, 11, 12MHz around the resonant frequency of 11.3MHz.\n\n![[Pasted image 20240222075543.png]]\n\nSo we can see here that being close to resonance is important. how utterly unsurprising.\n\n# Longer turn-on\n\nHere I replaced the FET with a IPA60R080P, which has about half the input capacitance. that makes the waveform at the gate look somewhat sensible. Here is a 1000 cycle turnon transient at 11.3MHz:\n\n![[Pasted image 20240222212138.png]]\n\n- Yellow: gate waveform\n- Green: AWG\n- Cyan: drain\n- purple: between inductor and capacitor.\nThe oscillations in the maximum amplitude of the drain and the resonance circuit are real, and I think that might be some oscillating phase shifts as it gets closer and further away from ZVS. Let's zoom in:\n### Beginning of the turn-on\n\nThe phase shifts look like this:\n\n![[Pasted image 20240222212344.png]]\n\nSo you can see there is about a 25ns delay between when the gate driver goes high (yellow) and when the drain goes low, and a 50ns delay between when the driver goes high and the voltage at the cap starts to drop.\n\n### High drain voltage:\n\n![[Pasted image 20240222212622.png]]\n\n### Low drain voltage\n\n![[Pasted image 20240222212705.png]]\n\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240306-plasma-toroid-2":{"title":"","content":"Instead of having a class whatever oscillator with zero voltage switching nonsense to not blow up the FET, how about a simple push pull half bridge to drive the LC oscillator directly:\n\n![[Pasted image 20240306195043.png]]\n\nSomething a little like this:\n\n![[Pasted image 20240306195108.png]]\n\nThe only trouble I had with this was finding a gate driver that claimed to be able to switch fast enough. [[20240208 plasma toroid#New circuit|previously]] the FET driver would smoke out after a few seconds of operation.\n\nThe PCB looks like this:\n\n![[Pasted image 20240306195458.png]]\n\nAnyway, after lowing up the FET driver once and resoldering, I get this:\n\n![[Pasted image 20240306195239.png]]\n\nGreen is high side FET gate, cyan is low side FET gate, yellow is middle of the half bridge, maths is top FET gate - middle of half bridge (so the gate-source voltage of the top FET). And finally purple is after the inductor.\nSo now all that needs to be done is crank up the frequency to the frequency of the purple oscillations, and bam! plasma toroid.\n\n## \\*Pop\\*\naaand it died. once I changed the resistors r12 and R13 that limited the current from power to ground, it worked for a little bit and then died, killing the top FET and the LMG1210. I resoldered new ones on and replaced the resistors with 1.4R resistors, which will hopefully act like fuses. I also changed the bootstrap cap:\n\n![[Pasted image 20240308072339.png]]\n\nI calculated that I needed 10nF from the datasheet, but it looks like even 50nF is not even close to enough. I wonder why the voltage on the gate of the FET is decaying over time? I desoldered the connection to the gate ofthe FET and measured the resistance to the source, it is open circuit as you would expect.\n\nAfter changing the bootstrap cap to 1uF I get this waveform:\n\n![[Pasted image 20240308072907.png]]\n\n...The _low side_ drive changed to only be 1us long?!??! Time to go read the datasheet...\n\n\n![[Pasted image 20240307204728.png]]\n\n...\n\n...\n\nThe reason why the gate voltage was decaying over time was that I had a 1kR resistor with a 50R resistor as a probe to ground so I could scope the voltage on the gate.\n\n## Higher frequency.\n\nNow things work fine. But after cranking the frequency of the AWG up from 10kHz to 560kHz the top side FET stops being driven halfway through the cycle:\n\n![[Pasted image 20240309122330.png]]\n\nThis time the voltage on the gate is clearly not decaying over time, so it's really not clear what the source of the issue is.\n\nI set up the waveform generator for a 1MHz burst with 35 cycles:\n\n![[Pasted image 20240309123102.png]]\n\nSo clearly it actually is the gate voltage that is sagging here. I noticed also on the thermal camera that the bootstrap diode was getting a workout in:\n\n![[Pasted image 20240309123320.png]]\n\nso this might have something to do with it. Back to the datasheet!\n\n![[Pasted image 20240309125204.png]]\n\n\nThe reverse recovery time of my diode from the pantry (SM4001PL):\n\n![[Pasted image 20240309125135.png]]\n\nhmmm..... I have no other diodes though. I do have a BFR106, a 20GHz NPN transistor. wiring it as a diode does not seem to work well though. Weird considering [this](https://electronics.stackexchange.com/questions/556997/recovery-of-transistor-wired-as-diode) rather good post would suggest that transistors don't have much of a reverse recovery time. I do have some buck converters though, and they do have shottkey diodes in them:\n\n\n![[Pasted image 20240309131307.png]]\n\n![[Pasted image 20240309131523.png]]\n\nBam! continuous operation at 1MHz, no problem.\n\nThe resistors seem to be heating up a tad though:\n\n![[Pasted image 20240309131718.png]]\n\nI want to be _reallly_ sure that everything is working well and there is not shoot through or anything on the circuit.\n\nThe falling edge seems fine, but on the rising edge here there looks like there is negative dead time:\n![[Pasted image 20240309132004.png]]\n\n20ns is the same as what the datasheet says the _maximum_ dead time is. suspicious.\n\n![[Pasted image 20240309132755.png]]\n\n...actually I have things wrong, this looks fine. Although it doesn't quite look like what the datasheet has:\n\n![[Pasted image 20240309132854.png]]\n...actually though it looks like Tphl is about the same as TdHl. Diagram should have a \"not to scale!\".\n\nCranking things all the way up to 11MHz we get this:\n\n![[Pasted image 20240309133602.png]]\n\nso the resistors are at 120C. I paid for the whole thermal range and I'm gonna use it. The bottom FET is at 60C though which is worrying. we aren't even switching any load yet.\n\nSince there are actual resistors that are drawing actual current, we can probe across them to get an idea of when exactly the current is being drawn to see if it is an an appropriate time etc:\n\n![[Pasted image 20240309140946.png]]\n\nThis is a bit complicated but you can see from the difference between the purple and orange traces that there is clearly current flowing on the rising and falling edges of the middle of the two FET's. That's just the expected transient time when the MOSFET is in an intermediary state I guess, not much can be done other than to switch to a GANFET or something.\n\nPreviously the board was just floating in the air. I taped it down to a chunk of aluminium with some thermal paste in the middle, that reduced the temperature of the FET's to 40C. the circuit is already drawing 380mA/5W though. If the mosfets heat up by 20C from drawing 5W, that does not bode well for putting 60W into them. So I reduced the power rail from 12 to 7V going forward, hopefully that will limit the current draw a bunch when attached to the actual coil.\n\n### coax dielectric\n\nThe 0603 100pF capacitors were getting _really_ hot, as were the film caps. So I got 100pF worth of coax cable and added it on instead. It still got a bit warm though, so I don't know that overall it was a huge improvement in terms of increasing the Q of the circuit. It mostly just spread out the heat dissipation I think.\n108pF worth:\n![[Pasted image 20240309161159.png]]\n\n## Failure under high load /?\n\nUnder conditions right next to optimal tuning the circuit starts to turn on/off intermittently like this:\n\n![[Pasted image 20240309172135.png]]\n\nit's not 100% related to frequency or anything, I don't really know what the root cause is. But I notice that the lower gate drive pulse is quite narrow.\n\nZooming in and doing maths gets this:\n\n![[Pasted image 20240309172323.png]]\n\nThat's my interpretation of the high side gate drive. I think what needs to be done now perhaps is to reduce the dead times. \n\nI added a 100k pot in series with the 20k resistor that sets the dead time and swept it back and forth. whilst it did adjust the dead time, it did not seem to make a difference with the above short pulse. Changing the duty cycle of the awg from 50% to 40% did seem to do something though, and after a bit more twiddling I burnt the sma connecter right off the board:\n\n![[Pasted image 20240309181307.png]]\n\noh well.","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240321-Agilent-6675A":{"title":"","content":"\nI bought an Agilent 6675A power supply for $40. 110V 18A supply, tremendous.\n\nI plugged it in, set the voltage to 10V. Got 10V, nice. I changed the voltage to 110V and then got this:\n\n![[Pasted image 20240321210305.png]]\n\n...not so nice. This is the schematic of the above board with what I think blew up crossed out:\n\n![[Pasted image 20240321210354.png]]\n\n...so that's not great. I purchased a replacement MOSFET driver and a not-quite-replacement npn transistor (TIP42C), then reconnected everything and turned it back on. It turns on and I can set the voltage and current, but the front panel says 'Unr' which according to the manual means \"unregulated\". Further investigation revealed that the input 240V 20A fuse had blown, so I replaced it with some 0.2mm copper wire, which apparently has a fusing current of like 6A.\n\nAfter turning on the supply it seemed happier. I changed the voltage to 6V and the power supply said it was in constant voltage mode instead of unregulated mode, nice! Then I turned around to grab the multimeter and the fuse wire I put in absolutely _detonated_ with a loud bang. Not a pop. A bang. This is what the surrounding area looked like afterwards:\n\n![[Pasted image 20240321210829.png]]\n\n...That is a little unnerving. I quickly got out the thermal camera after it went pop to try and catch something red handed, but no luck. Rather than put a piece of wire back and try it all again, I instead went back to the FET board above looking for trouble. This time the pnp Q252 driving the low side FET died. Oh and by the way, the schematic is not the schematic for the board that I have. It's for a later revision of the board that uses MOSFET's rather than IGBT's. Taking the pnp transistor out I see it has failed short.\n\n...Looking at the datasheet for the replacement transistor I got I observe that it has a transition frequency of 3MHz, whereas the originals (according to the schematic, anyway) have a transistion frequency of 80MHz. Given that they were driving the top and bottom of a half bridge, the chances of shoot through are approximately 100%.  So I've ordered a full set of replacement pnp's for 3/4 of the price of the entire power supply.\n\n## Things floating at mains\n\nThe entire FET board is floating at mains. I don't know that it's supposed to do that. It certainly makes probing the board more annoying, this is what happens when I touch the ground lead of my scope to the \"ground\" of the FET board:\n\n![[Pasted image 20240322200918.png]]\n\n...fzzzt.\n\nThis is is the mains input board of the supply:\n\n![[Pasted image 20240322201115.png]]\n\nSo you can see that the system before the rectifying diode is actually at +/- 110 with respect to the chassis. There is a 10k resistor to the chassis on the FET board:\n\n![[Pasted image 20240322201542.png]]\n\nThat is sits at 170C according to the thermal camera. $220^2/10e3 = 4.8W$. That seems about right for the temperature, but surely the designers of the supply did not intend for -RAIL to be floating so high, given how they tied it to ground.\n\n...It turns out that the heatsink is not supposed to sit at ground at all, and that the big plasic clips that hold it in aren't just there to annoy me but in fact serve to float the whole board. The addition of a printer filament box between the heatsink and chassis drops R258's temperature admirably:\n\n![[Pasted image 20240412200658.png]]\n\nIn order to be able to probe things whilst not being electrocuted I also swapped out the recified mains DC output for a bench supply output of 20V.\n## Road to success\n## Bad fmax\nThe [TIP42C](https://www.onsemi.com/pdf/datasheet/tip42c-d.pdf) transistors that I purchased have a gain bandwidth product of 3MHz:\n\n![[Pasted image 20240412200101.png]]\n\nbut the original [MJD45H11](https://assets.nexperia.com/documents/data-sheet/MJD45H11.pdf) transistors have a transition frequency of 80MHz:\n\n![[Pasted image 20240412200208.png]]\n\n...This would seem to be an issue. So I bought some [2SA1186](https://www.digikey.com/en/products/detail/sanken-electric-usa-inc/2SA1186/3661800) ones instead which have a transition frequency of 60MHz, which is hopefully good enough. \n\n## More comparisons\n\nIn preparation for the above transistors arriving I took all the existing ones off the board, and then started probing about to find further differences between the two sides of the circuit. I discovered that the side with the blown PNP transistor also had some bad power transistors:\n\n![[Pasted image 20240412201057.png]]\n\nAnd in addition to that the FET driver that originally died and that I replaced had died again, so I replaced that for a second time also. \n\nAll of this was made possible by comparing the two symmetrical sides of the circuit and comparing waveforms to help reason it out. Without that reference to look at I think this would have taken far too long to figure out and wouldn't have been worth doing.\n\nUnlike what you might expect from looking in the schematic of the manual, the supply actually has two sets of FET's in parallel:\n\n![[Pasted image 20240412201410.png]]\n\nSo I took some working FET's from side B and put them on side A. In total two of the FET's of side A were completely kaput and one of them was functioning merely poorly (the waveform didn't look idential with the other side). After replacing all 3, I got a regulated output voltage! \nThe power board was being supplied with 20V and doesn't seem to want to go above 5.5V or so but I think that's OK and should be fixed when I switch back to mains. This regulated voltage was actually achieved without the pnp transistors at all:\n\n![[Pasted image 20240412202056.png]]\n\nSo I guess they are just there to speed up the edges. I also think that it would be best to add them before actually drawing any load from the supply.\n\n## And now, for a very confusing graph:\nOK so it turns out what looks too good to be true is. Even though the output is being correctly regulated, there is still something clearly wrong with the FET driving still:\n![[Pasted image 20240412212612.png]]\n\nThe high side gate of the side of the schematic that has components blowing up is still clearly not being driven correctly for some reason. The \"high side gate(bad)\" clearly shows this, it is not capable of drivin up to the same as the high side gate on the other side. Here is what the half bridge midpoint looks like:\n\n![[Pasted image 20240412212848.png]]\n\nSo if you take the yellow trace in the top plot - the yellow trace in the bottom plot you get the Vgs of the top FET. and clearly the source of the FET is not floating up to any rail at the time that the high side gate goes high. So perhaps this FET is also dead and not conducting? I do have one more spare power FET, so let's try that.\n\n\n![[Pasted image 20240413114519.png]]\n\n... There we go. I suppose in retrospect it should have been surprising that 3 out of 4 FET's on a half bridge would fail. But I was fooled because some of them failed short circuit and some failed open circuit.  After replacing that last FET everything seemed fine so I put the FET board back on the mains power and nothing blew up. As far as I can tell that means that the unit is working!\n\n## Cleanup: encoder\n\nThe two encoder wheels on the front had gotten banged and the knobs popped off:\n\n![[Pasted image 20240413142738.png]]\n\nInside the encoders look like this:\n\n![[Pasted image 20240413142940.png]]\n\n![[Pasted image 20240413142954.png]]\n\nThe actual wheel is a very solid piece of metal, basically looks like a motor stator. Seems kind of gratuitous to be honest, but then again the encoders survived the 7mm ABS shaft being snapped off, so what do I know?\n\n\n\n# The saga continues\n\nI just [[20240424 Plasma toroid 3 Aluminium|blew up]] the supply again. How annoying. This time it seems that both the regulator and the half bridge are dead:\n\n![[Pasted image 20240425211644.png]]\n\nI think that this is the reason the 3.3R resistor was so hot. There was a short through the failed FET driver.\n\n![[Pasted image 20240425211715.png]]\n\nI have ordered some replacement ","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240406-Thoughts-about-printing.":{"title":"","content":"What we really need is a printer that can deposit just about anything that can survive high temperatures. If we had a printer that could put downs copper, steel, and some kind of insulator then you would be able to print an entire robot straight up.\n\nOne approach to printing that I have not heard about is getting a drop or particle of material, applying a charge to it, then flinging it down with electric fields to put it in the right spot to build up an object. Like a laser printer but 3D. I went and asked ChatGPT a bunch of things and it isn't immediately obvious that it wouldn't work. \n\nSome things that seem important: \n- The charge a sphere gets at a given voltage is proportional to its diameter. So the acceleration it would feel is inversely proportional to its diameter then obviously. We want high accelerations here for high material deposition rates I think.\n- This makes me think that maybe we want to use laser ablation to gassify the material. Then you'd really be able to accelerate it. But the latent heat of vaporisation of copper seems high (5kJ/g, and we want at least 1g/s right?) as opposed to just melting it.\n- Ablating a material would then give you a velocity _distribution_ as opposed to a well controlled velocity from single well defined droplets. \"Laser ablation and its applications\" on the section on space propulsion says that you would get a \"Maxwell-Boltzmann velocity distribution\":\n![[Pasted image 20240406060813.png]]\nI have no idea how narrow that is in practice. It would seem though like what you would end up here is something like an electron microscope set of optics. Electron microscopes have the advantage though that they can just throw away the electrons that they don't want. If a printer did that the entire inside would fill up with trash pretty quick. So a printer would have to accept a) the whole cone angle of ablated material and b) the whole velocity distribution of electrons. \n\na) seems like by far the hardest. It would seem to correspond to ab absurd numerical aperture and almost on that basis alone I want to discard the ablation idea. So it seems like investigating controlled melting of droplets is what is really desired if practical.\n\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240423-thoughts-on-laser-comms.":{"title":"","content":"Idea: put a laser transmmitter and receiver under a fisheye lens, then have a mechanism that translates the laser and receiver under them to direct the beam around. That way you could get uninterceptable laser communications and it would be relatively easy to steer the beam around in an entire hemisphere, because like 10mm of translation would result in a full hemisphere of laser direction.\n\n![[Pasted image 20240423085642.png]]\n\nI suppose it would be a bit like optics stabilization only instead of stabilizing the sensor you are destabilizing a laser tx/rx. \n\n### Construction\nYou could make a PCB voice coil kind of thing that looks like this:\n\n![[Pasted image 20240423085457.png]]\n\nand then that could sit on some 3d printed flexure thingo to provide translation. \n\n### The hard bit\n\nThe hard thing with this I think would be gettingthe tx and the rx pointed in the right direction. One thing that I think might help here would be (for the rx side) actually putting the rx photodiode just straight up on top of an image sensor.\n\n![[Pasted image 20240423085852.png]]\n\nThen when you were trying to steer the rx around you could have a blob detector that would tell you where to point the ","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240424-Plasma-toroid-3-Aluminium":{"title":"","content":"\nNew PCB looks like this and is made of Aluminium:\n\n![[Pasted image 20240425201500.png]]\n\nIt turns out that when you buy an Aluminium PCB and put vias in it, the vias don't actually connect the top layer to the ground plane. I discovered however that the legs of a PCB mount SMA connector can be snapped off and hammered into the 1mm holes, and then soldered to. This makes a fine connection.\n### Retuned circuit:\n\nI use my [[20240321 Agilent 6675A|brand spanking \"new\"]] power supply to power the half bridges. This worked fine but I never seemed to hit resonance for some reason. So I popped the LC off and put it on the VNA, then dialed the variable capacitor in so the resonance was exactly 10MHz:\n\n\n![[Pasted image 20240424214420.png]]\n\nAfter that I tried to solder to the half bridge with the power supply on, and the half bridge blew up. So did the power supply. What a tragedy.\n\n## Fixed power supply, analyse usage\n\nNow I have things back up and running. I noticed that there was a large change (\u003e10deg) in the temp of the MOSFET with a small change in the input frequency from the signal generator. I had initially attributed this to the resonant frequency of the LC, but the fact that only the low side mosfet changed temperature made me suspicious. Here is a screenshot of the half bridge operating at 'low power':\n\n![[Pasted image 20240511082031.png]]\n\n- Yellow: High side gate\n- Blue: Half bridge midpoint\n- Purple: low side gate\n- Green: EM field from a loop nearby\n- Maths: High side gate - Half bridge output (Low side gate voltage)\nAnd at 'High power':\n\n![[Pasted image 20240511082331.png]]\n\nSo it seems there is some kind of shoot through happening. Some more observations:\n- The magnitude of the EM field did actually increase, but not nearly commensurate with the rise in power dissipation (The current from the supply like doubled here)\n- I checked, and there is little time delay between CH1 and CH2 here\n- The higher frequency wibbles most obvious on CH1 are highly dependent on local meat placement.I can almost make the \"shoot through\" disappear from moving my hand around.\n- The voltage on the gates would suggest that there should be no shoot through at all.\n- \n\nSome more experiments. Here is 9.54MHz, where things look completely sane:\n\n![[Pasted image 20240511082850.png]]\n\nAnd 9.44MHz, completely wack:\n\n![[Pasted image 20240511082959.png]]\n\nFurther down at 9.3MHz, slightly more sane (?):\n\n![[Pasted image 20240511083059.png]]\n\nI wonder where this ringing is coming from. If I can solve that this might solve the issue. In the past power supply decoupling at been a wee bit of an issue so I shall probe the power supply rail. That turns out to have 5vpk-pk ripples in it but I think that's more or less par for the course at this kind of di/dt, and there doesn't seem to be an obvious relationship between the ripples and the 80MHz ripples above. Instead I suspect that it is some other LC oscillation in my circuit, though I don't know where it could be coming from. To test this I detuned things down to where it looks like a nice square wave, then tuned the variable capacitor (with pliers, lest I be burned) and this actually seems to be a good strategy. I get 800mVpk-pk on my field here with the FET's sitting at a cruisy 45C. Time to switch over to the big boi power supply and crank the voltage!\n\n![[Pasted image 20240511085032.png]]\n\n## Magnetic field measurement adventures\n\nOne of the things that I noticed correlated well with the increased power consumption was harmonics/ringing happening on the output waveform:\n![[Pasted image 20240513080030.png]]\n\nI it was hard to tell where this was coming from. Moving my hand around over the coil influences the amplitude quite a lot. So I made a magnetic probe thingo (loop of wire) to try and find out where things were coming from. Here are 4 measurements:\n\n### Main coil field\n\n![[Pasted image 20240513080213.png]]\n\n![[Pasted image 20240513080238.png]]\n\n### Perpendicular to main coil field\n\n![[Pasted image 20240513080341.png]]\n\n![[Pasted image 20240513080319.png]]\n\n## Decoupling cap:\n\n![[Pasted image 20240513080455.png]]\n\n![[Pasted image 20240513080420.png]]\n\n### Perpendicular to decoupling cap:\n\n![[Pasted image 20240513080518.png]]\n\n![[Pasted image 20240513080548.png]]\n\n### Power supply current:\n\n![[Pasted image 20240513080939.png]]\n\n![[Pasted image 20240513080913.png]]\n\nThe vscale on the field measurement is the same in all the pics here obviously. So it seems like a bit clue here that the decoupling is somehow the issue. Obviously the current that created the voltage on the output of the half bridge had to come from somewhere and that somewhere was the decoupling cap. So it could technically be caused by something else,and I am just measuring the supply current to it. But I shall investigate in this direction anyway for lack of anything else to do.\n\n## Voltage measurement of decoupling\n\nBecause I did not do things properly, the wires for my decoupling caps are attached with wires to ground and to power:\n\n![[Pasted image 20240513081752.png]]\n### 1: ground to ground\n\n![[Pasted image 20240513081434.png]]\n\n### 2: ground to ground + 10mm of wire\n\n![[Pasted image 20240513081605.png]]\n\n### 3: Power - 10mm of wire\n\n![[Pasted image 20240513081843.png]]\n\n### 4: Power\n\n![[Pasted image 20240513081934.png]]\n\nNote that all of these were measured referenced to a bolt ground hole positioned just under the (1) indicator. Obviously on this PCB the ground abstraction is utterly broken. But, measured with respect to a ground hole just to the upper left of (4) VCC looks about the same.\n","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240522-Plasma-toroid-4-decoupling":{"title":"","content":"[[20240424 Plasma toroid 3 Aluminium#Voltage measurement of decoupling|Previously]] I measured 2 volts peak to peak across a \u003c5mm long piece of wire, and decided that this was a result of \"bad decoupling\" and \"inductance\" and that I should \"decrease my current loops\" and \"make sure the MLCC is placed close to the half bridge\". Well, I did all that:\n\n### Old\n\n![[Pasted image 20240522204041.png]]\n### New\n\n![[Pasted image 20240522203901.png]]\n\nBetter layout, right? Well, here is what the Oscilloscope sees when it measures from point 1 to point 2 above:\n## Measurements\nYou'll notice that these are directly adjacent points on the ground plane:\n### Oscilloscope probe\n\n![[Pasted image 20240522204242.png]]\n\n![[Pasted image 20240522204446.png]]\n\nAnd that there seems to somehow be 2V across this ground plane. I found this rather implausible, and so decided to measure with my current probe:\n### Current probe\n\n![[Pasted image 20240522204306.png]]\n\n![[Pasted image 20240522204339.png]]\n\nHMMMMMM. A strikingly similar graph, I am sure you'll agree. Perhaps my decoupling is completely fine and the scope probe is just acting as a current probe!\n\n![[Pasted image 20240522210000.png]]","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240529-Metal-detection":{"title":"","content":"\nMost of my understanding of metal detectors comes from the highly excellent book \"George Overton, Carl Moreland - Inside the Metal Detector-Geotech Press (2016)\". It is assumed reading.\n\n## Problem\n\nCurrent commercial metal detectors are extremely simple, so much so that it seems likely to me that something can be done to make them dramatically better. They remind me of the radar days of yore when one took an oscillator, fiddled about with it a bit, received a signal, then applied the amplified result to a CRT screen and expected people to detect planes with it.\n\nThe limitation on performance of a modern metal detector much of the time as I understand it is \"signal to ground ratio\". There is some signal coming back from a piece of metal in the ground, but it is mixed in with lots of ground, which can contain magnetic iron oxides and whatnot. The term of art here is \"signal to ground ratio\". If you have a metal detector with some kind of transmit coil like so:\n\n![[Pasted image 20240529211951.png]]\n\nSo the huge volume of the field in the ground compared to the thing you are measuring means that your receiver just measures ground clutter. You can't \"focus\" magnetic fields in any meaningful sense, so this is an inherent limitation of the system.\n\n## Getting around inherent limitations of the system.\n\n### Integration\n\nOne of the things you might think about doing is introducing the notion of the position of the coil. If you know the position of the coil you can integrate the signal over space and do things like try to subtract the ground offset. People already have gross \"ground balance\" stuff to subtract out the overall field, but as I understand it the ground at some point becomes sufficiently heterogeneous that the remaining wiggles in the signal as you move the coil around swamp the signal from the gold. Again, what you are basically doing is taking a huge spatial lowpass filter (30cm wide coil) and moving it over a bunch of much smaller things (rocks and tiny bits of gold). \n\nWhat we need to do conceptually is make the magnetic field into a spike that goes into the ground. \n\n### Field shape alteration\n\nConsider the following setup: instead of one transmit coil, you have two coils next to each other with a receive coil in the middle. Let's ignore for the moment the notion of induction balance. Here is a top down view:\n\n![[Pasted image 20240529212843.png]]\n\nNow let's imagine what the rx would see for two different scenarios: \n- Tx1 and Tx2 have currents going in the same direction (say both clockwise)\n- Tx1 and Tx2 have currents going in the opposite direction (say both anticlockwise)\n\n#### Both positive visualisation:\n\n![[Pasted image 20240529213136.png]]\n#### One positive one negative\n\n![[Pasted image 20240529213035.png]]\n\nLet's imagine now that there is a target in the ground directly between the two tx coils, but down a bit. For the ++ case, the target would see a magnetic field with components mainly in the vertical direction, similar to a normal detector with a single coil. For the +- case, the target would see a magnetic field with components in the horizontal direction only. The field outside the radii of the two coils looks similar in both cases\n\nSo from the point of view of the receiver in the ++ case it would get signal from the target, and in the +- case it should see no signal at all, since the induced currents are perpendicular to the receive coil.\n\nNow, what would you see if you took Rx(++) - Rx(+-). The parts of the receive signal originating outside the extent of the two coils would be mostly cancelled, since the magnetic field looks similar in both cases. The components originating from between the coils would not however!\n\nhere is a diff of the above two vector fields:\n\n![[Pasted image 20240529214136.png]]\n\nWait what. That's just the coil that switched polarity! (a + b) - (a - b) = 2b, duh. I wonder if this actually invalidates anything...\n\n\n# Measurements\n\n### +- case balanced\nHere I have balanced things down to the difference in the second harmonic coming from the signal generator:\n\n![[Pasted image 20240601152200.png]]","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240618-Impedance-network-simulation":{"title":"","content":"# Background\n\n\nThe goal here was to build some kind of metal detector that could operate at a wide range of frequencies. Previous work [[20240529 Metal detection|here]]. It seems rather impractical/impossible(?) to make a coil that actually resonates across a decade+ frequency range of like 1-10kHz, ideally 100kHz. We want such a large frequency range because iron ore and so on has a quite different response vs frequency to gold, and so doing a full frequency sweep should provide a bunch of information.\n### Why resonate?\nIt's obviously possible to put a whole bunch of energy in a tx coil across many frequencies via some kind of class-D amplifier setup. And you could open-circuit the rx coil and measure the voltage across it too, if you wanted. But I don't think that that would be a good way to operate the device. Operating the coil with a capacitor in parallel as a tank circuit at the tx coil frequency is universally how metal detectors are designed, and with good reason I think. It is not so much that the tank circuit provides _gain_ by resonating, but that it presents as a different impedance. It actually absorbs more of the energy in the oscillating magnetic field. So it's not equivalent at all to sticking a super low noise amplifier on the output of the coil.\n\n### Briefly: Why not operate at different frequencies sequentially?\nYou could trivially design a setup that used a switched capacitor network or tapped off the inductor to operate at different frequencies sequentially. You could then build up a picture of what is happening by scanning through the frequencies one after the other, but this would of course take a lot longer. I find this to be against the ideals of the project and refuse on that basis. When I think about what a good metal detector should be doing it is blasting the environment with as much wideband energy as it possibly can on the tx side, and using some kind of multiple coil setup to get even more information a la phased array. But since wideband seems not to be possible, perhaps N-band is.\n\n## Simultaneous multi-frequency inductors:\n\nSo one way to get this to work would be to just have a whole pile of different receive coils all operating at once. That seams infeasible though. If you look at the actual physical size of metal detector coils, they are pretty big. Big enough that stacking 10 of them together probably wouldn't be a super great idea. What if instead of this we could have one very large coil and then operate different subsections of it at different frequencies?\n\nIt would work something like this: Suppose you have a coil, and divide it into two sections, connected in series. The two sections together would resonate at some frequency F, and the subsection at the end would resonate at some frequency 2F. Obviously if you just hooked this up as-is, it wouldn't work.\nBut, what if you inserted a magic device in the middle? A device that let frequency F through, but blocked frequency 2F. Then the smaller section of the coil would be 'invisible' to the larger section, and they could resonate at both frequencies at once! \n\n![[Pasted image 20240628214143.png]]\n\n### What would this look like?\nWell it would look a little bit like a diplexer in the sense that different frequencies go to different places. It would actually need three ports I think, with the third port being used to attach the capacitor for the 2F resonator.\n\nI don't really know how to design such a thing, but how hard could it be to simulate?\n\n# Simulation of a graph of RLC networks.\n\nSo we have N inductors, resistors, and capacitors connected together in a graph. And we want to calculate the impedance between the nodes as a function of frequency. The term for this is 'Nodal analysis', and it involves at some point constructing an 'Admittance matrix'.\n\nThe physical layout of the system can then be described then as an adjacency matrix where the N nodes in our system are connected by resistors and capacitors. Note that for reasons I don't have a great intuition for, _ground does not count as a node_ when doing these kinds of analyses. Instead, a connection from a node i to ground is represented as a connection with itself i.e. an element on the matrix diagonal.\n\nIf $v = ir$ and we define admittance of something to be the inverse of the resistance to be $y = 1/r$. Then $yv = i$, obviously. It transpires then that we can write our Admittance Matrix $Y$ like this:\n$$YV = I$$\nWhere when we have N nodes Y is the NxN admittance matrix, $V$ is the Nx1 voltages of the different nodes, and $I$ is the Nx1 currents in the nodes. If we knew the currents going into and out of the nodes then, we could solve for the voltages like this:\n$$V = Y^{-1}I$$\nOK. This is all lecture note stuff. But recall that we don't have ground as an explicit node here. That means that we can stuff 1A of current into node 0 without having to have a -1A anywhere else as the current will just end up going to ground. So if we say that the input node is node 0 and we have N nodes, then $I = [1, 0, 0...0_n].T$. We know the admittance matrix, we know about `torch.pinv`, and we know what $I$ is! The system is now solveable! Yay!\n\n## Code\n\n### Network representation\nObviously we want to represent the graph of the network by storing the component values (like 100e-9 is a 100nF inductor). So this means that the adjacency matrix is actually a 3xNxN matrix, with the first dimension being [R, L, C]. Then for a given frequency we can calculate the impedances of the different components and put them in parallel (not sum!) across the first dimension.\nIt looks like this:\n```python\ndef calc_impedance(freq, grid):\n    \"\"\"Calculate the impedance matrix from the component grid.\n\n    B * 3 * N * N adjacency matrix for (inductance, capactitance) for a network of N nodes.\n    It is assumed that only one of the adjacency matrix edges is populated.\n    Connections from a node to iself is how connections to ground are represented.\n    Returns a B*N*N impedance matrix for the network.\n    \"\"\"\n    assert(freq.ndim == 2)\n    assert(grid.shape[-1] == grid.shape[-2])\n\n    B, _, N, _ = grid.shape\n    j_omega = (1j * 2 * np.pi * freq).unsqueeze(1)\n    # swap B idx for easier indexing into RLC:\n    Z_lc = torch.zeros((RLC, B, N, N), dtype=torch.cfloat)\n    nonzero = torch.permute(grid != 0, (1, 0, 2, 3))\n    Z_lc[R, nonzero[R]] = grid[:,R][nonzero[R]].cfloat()\n    Z_lc[L, nonzero[L]] = (j_omega * grid[:,L])[nonzero[L]]  # Reactance for inductors\n    Z_lc[C, nonzero[C]] = 1 / ((j_omega * grid[:,C])[nonzero[C]])  # Reactance for capacitors\n\n    # sum the RLC's in parallel:\n    admittance = torch.zeros_like(Z_lc, dtype=torch.cfloat)\n    admittance[Z_lc != 0] = 1 / Z_lc[Z_lc != 0]\n    admittance = admittance.sum(axis=0)\n    # Add the transpose to itself apart from the diagonal elements to make the matrix symmetric.\n    # if an impedance connects node i to node j, it should also connect node j to node i.\n    admittance_sym = admittance + torch.transpose(admittance * (1 - torch.eye(N)), -1, -2)\n\n    Z = torch.zeros((B, N, N), dtype=torch.cfloat)\n    Z[admittance_sym != 0] = 1 / admittance_sym[admittance_sym != 0]\n    return Z\n```\nSo this gives you your Z matrix from which the Y matrix can be constructed. That looks like this:\n```python\n\ndef calc_voltages(Z, I, get_residual=False):\n    \"\"\"\n    Z is B*N*N impedance matrix for the network with N nodes (not including ground).\n    I is B*N length current vector for the network.\n    return V, a N length voltage vector for the network.\n    \"\"\"\n    # broadcasting for convenience:\n    if Z.ndim == 2:\n        Z = Z.unsqueeze(0)\n        return calc_voltages(Z, I, get_residual).squeeze(0)\n    if I.ndim == 1:\n        I = I.unsqueeze(0)\n        return calc_voltages(Z, I, get_residual).squeeze(0)\n    assert Z.ndim == 3 and I.ndim == 2\n\n    Y = torch.zeros_like(Z, dtype=torch.cfloat)\n    Y[Z != 0] = 1 / Z[Z != 0]\n    # linear components, so the matrix should be symmetric\n    # assert ((Y - torch.transpose(Y, -2, -1)).abs().sum() \u003c 1e-6).all()\n\n    # Sum admittances for each node\n    # Y_diag = torch.diag(torch.sum(Y, dim=-1))\n    Y_diag = torch.diag_embed(torch.sum(Y, dim=-1), dim1=-2, dim2=-1)\n\n    # Constructing the network admittance matrix correctly\n    eye_inv = (1 - torch.eye(Y.shape[-1])).unsqueeze(0)\n    Y_network = Y_diag - Y * eye_inv\n\n    # Solve for voltages using the network admittance matrix\n    Y_inv = torch.linalg.pinv(Y_network)\n    # Y_inv = torch.tensor(np.linalg.inv(Y_network.cpu().numpy()))\n    V = Y_inv @ I.unsqueeze(-1).cfloat()\n    residual = ((Y_inv @ Y_network).abs().max(dim=0).values - torch.eye(Y_network.shape[-1])).abs().sum()\n    if residual \u003e 0.1:\n        print(f\"Warning, bad residual! {residual}\")\n    # assert residual \u003c 0.1\n    # print(\"Residual:\", residual.item())\n    if get_residual: return V, residual\n    return V\n```\n\n# Example filter:\n\n### Bandpass filter:\n\nhere is an example bandpass filter from the extremely excellent [LC filter design tool](https://markimicrowave.com/technical-resources/tools/lc-filter-design-tool/). I chose it as it was nice and complicated :)\n![[Pasted image 20240625213530.png]]\n\nThis is what the internal representation looks like. Translated with ChatGPT (which got all the connections wrong):\n```python\ndef setup_inverse_chebyshev_bandpass():\n    grid = torch.zeros(3, 5, 5, dtype=torch.float)\n    grid[R, 0, 0] = 50\n    grid[C, 0, 0] = 1.103e-6   # C1\n    grid[L, 0, 0] = 232.0e-6   # L1\n    grid[C, 0, 1] = 152.3e-9   # C2\n    grid[L, 0, 1] = 915.2e-6   # L2\n    grid[C, 1, 2] = 279.6e-9   # C3\n    grid[L, 1, 2] = 1.680e-3   # L3\n    grid[C, 2, 2] = 2.827e-6   # C4\n    grid[L, 2, 2] = 90.52e-6   # L4\n    grid[C, 2, 3] = 85.42e-9   # C5\n    grid[L, 3, 4] = 2.995e-3   # L5\n    grid[R, 4, 4] = 50\n    I = torch.tensor([1.0, 0.0, 0.0, 0.0, 0.0])\n    return grid, I\n```\n\nAnd then the results look like this:\n\n![[Pasted image 20240628192701.png]]\n\nIt looks very similar! The node of interest here is Node 4, the output node. But the scale seems off, this has a peak of 40dBV somehow. That's because the circuit is 50Ohm terminated and we pushed 1A into it.\n\n# Optimisation\n\nNow that we have a simulation that does a fantastic job of simulating these RLC networks, we can get to work optimising one for the job at hand. Since all the code is written in pytorch, we should be able to just gradient descent our way to the correct solution, right?\n\n## Method 1: gradient descent\n\n```python\ndef optimise_grad_lowpass():\n    grid_gt, I_gt = setup_lowpass()\n    # frequencies = torch.logspace(torch.log10(torch.tensor(1000)), torch.log10(torch.tensor(1e6)), 1000)\n    frequencies = torch.linspace(8e3, 12e3, 100)\n    V_gt = simulate_across_freq(grid_gt, frequencies, I_gt)\n    \n    grid, I = setup_lowpass()\n    I = I.unsqueeze(0)\n    # grid[grid != 0] = torch.randn_like(grid[grid != 0])\n    grid[grid != 0] *= torch.rand(grid[grid != 0].shape) * 1e-2 + 1.0\n    grid.requires_grad = True\n\n    optimizer = torch.optim.SGD([grid], lr=1e-12)\n    losses = []\n    while True:\n        optimizer.zero_grad()\n        V , residual = simulate_across_freq(grid, frequencies, I, get_residual=True)\n        # loss = torch.mean((V - V_gt).abs())\n        # loss = torch.abs(torch.mean(1 - V.abs() / V_gt.abs())) + torch.abs(torch.mean(1 - V_gt.abs() / V.abs())) + residual * 10\n        loss = torch.mean((V.abs() - V_gt.abs()) ** 2) / V_gt.abs().mean() + 100 * residual\n\n        loss.backward()\n        optimizer.step()\n        losses.append(loss.item())\n        print(f\"iter {i}, loss: {loss.item():.3f}, means:{V.abs().mean():.3f}, {V_gt.abs().mean():.3f}, residual: {residual:.3f}\")\n```\nThis code absolutely refuses to converge or do anything useful. The loss blows up in two iterations with a 1e-12 learning rate. Notice that I initialized the matrix to something useful.\nOne thing I noticed was that the optimisation process here had a tendency to produce matrices that did not invert very well. That is, $AA^{-1}  != I$. I had the brilliant idea of adding this residual to the loss function so that it would produce an invertable matrix alongside one that satisfied the other properties but that didn't help.\n\n## Method 2: Genetic algorithm\n\n```python\n\ndef optimise_genetic_lowpass():\n    grid_gt, I_gt = setup_highpass()\n    Gsz = grid_gt.shape[-1]\n    nf = 10\n    frequencies = torch.linspace(7e3, 15e3, nf)\n    V_gt = simulate_across_freq(grid_gt, frequencies, I_gt).squeeze().abs()\n    \n    grid, I = grid_gt.clone(), I_gt.clone()\n    gsz = grid.shape[-1]\n\n    popsz = 100\n    grid_pop = torch.tile(grid.unsqueeze(0), [popsz, 1] + [1] * grid.ndim)\n    grid_pop[grid_pop != 0] = torch.rand(grid_pop[grid_pop != 0].shape) + 0.1\n\n\n    I_pop = torch.tile(I.unsqueeze(0), [popsz, nf] + [1] * I.ndim)\n    frequencies_pop = torch.tile(frequencies.unsqueeze(0), [popsz, 1])\n    frequencies_flat = einops.rearrange(frequencies_pop, 'n f -\u003e (n f) 1')\n    I_flat = einops.rearrange(I_pop, 'n f g -\u003e (n f) g')\n\n    def vis(frequencies, V_gt, V_meas, grid_pop, grid_gt):\n        plt.figure(figsize=(7, 21))\n        plt.subplot(311)\n        plt.plot(frequencies, V_gt)\n\n    old_grids = []\n    errors = []\n    best_errors = []\n    while True:\n        grid_expanded = torch.tile(grid_pop, [1, nf, 1, 1, 1])\n        grid_flat = einops.rearrange(grid_expanded, 'n f a b1 b2 -\u003e (n f) a b1 b2', n=popsz, f=nf, a=RLC, b1=gsz, b2=gsz)\n        Z = calc_impedance(frequencies_flat, grid_flat)\n        V_meas = calc_voltages(Z, I_flat).abs()\n        V_pop = einops.rearrange(V_meas, '(n f) g 1 -\u003e n f g', n=popsz, f=nf, g=gsz)\n        r1 = (V_pop / V_gt.unsqueeze(0)).mean(dim=(-1, -2)) # Should be average across freq, dot against nodes we care about\n        r2 = (V_gt.unsqueeze(0) / V_pop).mean(dim=(-1, -2))\n        error = (r1 + r2) / 2\n\n        order = torch.argsort(error, dim=0)\n        error_sorted = error[order]\n        grid_pop = grid_pop[order]\n\n        best_error = error_sorted[0]\n        es = [f\"{x:.3f}\" for x in error_sorted[0:10]]\n        print(f\"best error min: {error_sorted.min()}, e:{es}\")\n        frac = 2\n        nkeep = popsz // frac; assert popsz % frac == 0\n        grid_pop = torch.tile(grid_pop[:nkeep], [frac, 1, 1, 1, 1])\n\n        error_scale = min(1, best_error)\n        valid = grid_pop[nkeep:] != 0\n        # mutation = torch.abs(torch.randn_like(grid_pop[nkeep:][valid]) * error_scale)\n        mutation = (torch.rand(size=grid_pop[nkeep:][valid].shape)* 1.5 + 0.5) * error_scale\n        mask = torch.randint(0, 10, mutation.shape) \u003c 4\n        mutation[~mask] = 1\n        grid_pop[nkeep:][valid] *= mutation\n\n        if len(errors) \u003e 10 and np.std(np.array(errors)[-10:]) \u003c 1e-5:\n            if best_error \u003c 1.1:\n                print(\"ding\")\n            print(\"converged, refreshing\")\n            old_grids.append(grid_pop.clone())\n            grid_pop[grid_pop != 0] = 10 ** (-12 * torch.rand(grid_pop[grid_pop != 0].shape) )\n            errors = []\n            best_errors.append(best_error)\n        errors.append(best_error)\n\n```\n\nThis had much more success. It converged in a few seconds for an RC filter to the correct values. But, for a more complicated net like a highpass filter it kept converging to values that weren't very good. It seems as though it keeps getting stuck in a local minimum. So at the bottom of the loop there when I detect that the optimisation process has stopped I restart with fresh random values. It only takes a few seconds to converge so many starting points can be tested. \n## Overnight run\n\nI did an overnight run of the highpass filter:\n```python\ndef setup_highpass():\n    grid = torch.zeros(RLC, 3, 3, dtype=torch.float)\n    grid[R, 0, 0] = 50\n    grid[L, 0, 0] = 693.9e-6  # L1\n    grid[C, 0, 1] = 232.1e-9  # C2\n    grid[L, 1, 1] = 402.9e-6  # L3\n    grid[C, 1, 2] = 232.1e-9  # C4\n    grid[L, 2, 2] = 693.9e-6  # L5\n    grid[R, 2, 2] = 50\n    I = torch.tensor([1.0, 0.0, 0.0])\n    return grid, I\n```\nWhich gave me this histogram of errors. Each datapoint is one run of the optimisation process, so you can see that there are a couple of discrete different losses that get converged on.\n\n![[Pasted image 20240628075349.png]]\n\nIt looks like there are a few runs here that converged to the right answer! The minimum error here was 1.0002.\n\n## Comparison Table\nHere is a table of the actual grid of impedances for the ground truth and what the net managed to converge to. They are pretty much the same:\n\n| Best Convergence |          |          | Ground Truth |          |          |\n| ---------------- | -------- | -------- | ------------ | -------- | -------- |\n| Resistance       |          |          |              |          |          |\n| 4.95e+01         | 0.00e+00 | 0.00e+00 | 5.00e+01     | 0.00e+00 | 0.00e+00 |\n| 0.00e+00         | 0.00e+00 | 0.00e+00 | 0.00e+00     | 0.00e+00 | 0.00e+00 |\n| 0.00e+00         | 0.00e+00 | 5.01e+01 | 0.00e+00     | 0.00e+00 | 5.00e+01 |\n| Inductance       |          |          |              |          |          |\n| 7.23e-04         | 0.00e+00 | 0.00e+00 | 6.94e-04     | 0.00e+00 | 0.00e+00 |\n| 0.00e+00         | 4.11e-04 | 0.00e+00 | 0.00e+00     | 4.03e-04 | 0.00e+00 |\n| 0.00e+00         | 0.00e+00 | 7.20e-04 | 0.00e+00     | 0.00e+00 | 6.94e-04 |\n| Capacitance      |          |          |              |          |          |\n| 0.00e+00         | 2.20e-07 | 0.00e+00 | 0.00e+00     | 2.32e-07 | 0.00e+00 |\n| 0.00e+00         | 0.00e+00 | 2.31e-07 | 0.00e+00     | 0.00e+00 | 2.32e-07 |\n| 0.00e+00         | 0.00e+00 | 0.00e+00 | 0.00e+00     | 0.00e+00 | 0.00e+00 |\n### 8 hour work run of more complicated filter\n\nHere I tried a run over a ~10 hour workday, a much more complicated filter from [[20240618 Impedance network simulation#Bandpass filter|above]]. That gave me this histogram of converged errors:\n#### Histogram of converged errors:\n![[Pasted image 20240628191837.png]]\n\nThis one seems like a much more continuous distribution, not quite so many discrete modes. It also never converges to the right answer, with a pretty high minimum error.\n\nThis isn't looking so crash hot. I suppose it makes sense that this kind of landscape of L's an C's would be a minefield of local minima and that it would be difficult to converge on the global minima. I don't necessarily _need_ the global minima for my application but the miserable failure here hardly bodes well...","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/20240701-Fluxgate-magnetometer":{"title":"","content":"A good introduction and guide on how to make a fluxgate magnetometer can be found in the [Wireless world magazine, 1991](https://www.worldradiohistory.com/UK/Wireless-World/90s/Wireless-World-1991-09.pdf). I didn't really follow the guide but if you read it you'll get the general idea.\n\n# Version 1\nThe idea of winding a toroid sounded too hard to me so I made two separate linear coils and connected them with some magic magnetic tape. Here are the two windings before I added the sense coil:\n\n![[Pasted image 20240701184124.png]]\n\nAnd here is what it looks like \"fully assembled\":\n\n![[Pasted image 20240701184432.png]]\n\nI drove it straight out of the signal generator and amazingly it worked out of the box. It's quite sensitive and was able to detect my twiddling of a bar magnet like 5 meters away!\nThis is quite significant as it represents the first time I have ever built an electronic device and had it (1) work on the first try and (2) had it be more sensitive than expected. I suppose it makes sense now how they were able to get them good enough in WWII to detect submarines from a plane.\n\nThe limit on the detection though was the 0 level. Even when I aligned the sensor such that it was normal to the ambient magnetic field, there was still quite a large signal measured on the scope. Reading around a bit (\"Magnetic sensors and magnetometers\" is a sensible book) it seems that one of the main reasons to use a toroid is that it evens out the variations in manufacturing that are the result of these residual errors. \n\nSince the magnetometers measurement comes from the asymmetry in how each side of the device magnetises/demagnetises, it makes sense that this would be worth switching the design.\n\n# Version 2\n\nSo, time to suck it up and wind a toroid. The book also mentioned that one way to get low variation in your wound toroid is to wind it such that there windings are just touching along the inner race, since then the wire diameter is what sets the pitch. Good advice but that results in far more windings than is required in practice and I realised just after I started winding that I could have printed some notches in my 3D print which would have also defined the winding spacing and not required me to wind 7m of wire through a 35mmID toroid. Oh well.\n\n### Toroid construction\n\nHere is the inside of the toroid. I put two strips of metal ~2.75mm wide (hand cut with scissors, naturally) into the toroid which was sized to just fit the length of the strip.\n![[Pasted image 20240701184920.png]]\n\nAnd here it is all wound together:\n\n![[Pasted image 20240701185051.png]]\n\n...Not exactly a precision device, is it? But the 3d printed outer sense coil winding is critical. By rotating the inner toroid with respect to the outer one, I can move it to a point that minimizes the measurement when the sensor is perpendicular to the earths field. This makes quite a bit of difference.\n\n### Zero field\n\nHere is the output of the sensor, showing the maximum, minimum, and zero measurements achievable here on earth:\n\n![[Pasted image 20240701185559.png]]\n\nSo that's (3.2 - -2.5) / 55e-6 = 100mV/uT. That's 103kV/tesla, which sounds good. That's also 10000 gamma/volt, and the above magazine article calibrates it to a maximum of 100 gamma/volt, or 100x more sensitive.\n\n### Magazine schematic:\n\n![[Pasted image 20240701190306.png]]\n\n![[Pasted image 20240701190311.png]]\n\n![[Pasted image 20240701190324.png]]\n\n## Gating and filtering\n\nHere's an idea: The signal has 0 DC level. So what we really want to do here is rectify it. But, the signal is small. So instead we can just grab the section of the signal that has the spike in it, and average around that!\n\nLike this:\n\n![[Pasted image 20240701190754.png]]\n\nta-da! Done using an SI2302 analog switch, aka a mosfet as recommended by the Art of Electronics:\n\n![[Pasted image 20240701190843.png]]\n\nIt introduces a huge amount of charge injection but I'm going to wave my hands and say it's fine since the + and - section average to 0 anyway. Filtering this chopped signal and zooming into the noise floor, we get:\n\n![[Pasted image 20240701193547.png]]\n\nWhich sure does look an awful lot like mains. So I guess we have reached the noise floor of this particular environment.\n\n## Alternative to gating and filtering\n\nI got annoyed at the above gating because of the charge injection that I couldn't get rid of. I tried adding a complementary pmos and when that didn't work gave up. Instead, how about rectifying the signal? It would need to be amplified first but that's OK as my boards with a bunch of amplifiers came in.\n\nHere one is:\n\n### Amplifier\n![[Pasted image 20240702204618.png]]\n\nIt has a 10MHz gain bandwidth product (TP2311) so that looks about right.\n\n![[Pasted image 20240702212131.png]]\n\nhere is what the magnetometer looks like detecting a 1KHz sine wave:\n\n![[Pasted image 20240702212010.png]]\n\nThe magnetometer is being driven at 70kHz.\n\n### Bandpass filter\n\n![[Pasted image 20240702214700.png]]\n\n![[Pasted image 20240702214711.png]]\n\n...Not great.\n\n## Using magnetometer to sense 11kHz magnetic field.\n\nThis is starting to get a bit tricky. I angled the magnetometer such that it was not receiving much magnetic field. Then I strapped a coil to it, and excited the coil at 11kHz (to fit inside the above bandpass later).\n\nSetup:\n![[Pasted image 20240703082710.png]]\n\nThere are three states here in the FFT plot:\n1) No excitation, minimum magnetic field. This  resulted in a peak at basically only 50kHz\n2) No excitation, max magnetic field. Strong peaks at 100 and 200kHz appear in proportion to the strength of the field\n3) Exciting with external field. Base 11kHz modulation appears, but there is a much stronger peak at 100kHz +/- 11kHz. This is also in direct proportion to the volts going into the coil, and is also independent of the external magnetic field.\n![[Pasted image 20240703081957.png]]\n\nI had initially thought here that the strongest signal would show up at the base excitation freqency:\n![[Pasted image 20240703082409.png]]\n\nBut from the above FFT it appears that this is not actually the case. ","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/Fluxgate-magnetometer":{"title":"","content":"A good introduction and guide on how to make a fluxgate magnetometer can be found in the [Wireless world magazine, 1991](https://www.worldradiohistory.com/UK/Wireless-World/90s/Wireless-World-1991-09.pdf). I didn't really follow the guide but if you read it you'll get the general idea.\n\n# Version 1\nThe idea of winding a toroid sounded too hard to me so I made two separate linear coils and connected them with some magic magnetic tape. Here are the two windings before I added the sense coil:\n\n![[Pasted image 20240701184124.png]]\n\nAnd here is what it looks like \"fully assembled\":\n\n![[Pasted image 20240701184432.png]]\n\nI drove it straight out of the signal generator and amazingly it worked out of the box. It's quite sensitive and was able to detect my twiddling of a bar magnet like 5 meters away!\nThis is quite significant as it represents the first time I have ever built an electronic device and had it (1) work on the first try and (2) had it be more sensitive than expected. I suppose it makes sense now how they were able to get them good enough in WWII to detect submarines from a plane.\n\nThe limit on the detection though was the 0 level. Even when I aligned the sensor such that it was normal to the ambient magnetic field, there was still quite a large signal measured on the scope. Reading around a bit (\"Magnetic sensors and magnetometers\" is a sensible book) it seems that one of the main reasons to use a toroid is that it evens out the variations in manufacturing that are the result of these residual errors. \n\nSince the magnetometers measurement comes from the asymmetry in how each side of the device magnetises/demagnetises, it makes sense that this would be worth switching the design.\n\n# Version 2\n\nSo, time to suck it up and wind a toroid. The book also mentioned that one way to get low variation in your wound toroid is to wind it such that there windings are just touching along the inner race, since then the wire diameter is what sets the pitch. Good advice but that results in far more windings than is required in practice and I realised just after I started winding that I could have printed some notches in my 3D print which would have also defined the winding spacing and not required me to wind 7m of wire through a 35mmID toroid. Oh well.\n\n### Toroid construction\n\nHere is the inside of the toroid. I put two strips of metal ~2.75mm wide (hand cut with scissors, naturally) into the toroid which was sized to just fit the length of the strip.\n![[Pasted image 20240701184920.png]]\n\nAnd here it is all wound together:\n\n![[Pasted image 20240701185051.png]]\n\n...Not exactly a precision device, is it? But the 3d printed outer sense coil winding is critical. By rotating the inner toroid with respect to the outer one, I can move it to a point that minimizes the measurement when the sensor is perpendicular to the earths field. This makes quite a bit of difference.\n\n### Zero field\n\nHere is the output of the sensor, showing the maximum, minimum, and zero measurements achievable here on earth:\n\n![[Pasted image 20240701185559.png]]\n\nSo that's (3.2 - -2.5) / 55e-6 = 100mV/uT. That's 103kV/tesla, which sounds good. That's also 10000 gamma/volt, and the above magazine article calibrates it to a maximum of 100 gamma/volt, or 100x more sensitive.\n\n### Magazine schematic:\n\n![[Pasted image 20240701190306.png]]\n\n![[Pasted image 20240701190311.png]]\n\n![[Pasted image 20240701190324.png]]\n\n## Gating and filtering\n\nHere's an idea: The signal has 0 DC level. So what we really want to do here is rectify it. But, the signal is small. So instead we can just grab the section of the signal that has the spike in it, and average around that!\n\nLike this:\n\n![[Pasted image 20240701190754.png]]\n\nta-da! Done using an SI2302 analog switch, aka a mosfet as recommended by the Art of Electronics:\n\n![[Pasted image 20240701190843.png]]\n\nIt introduces a huge amount of charge injection but I'm going to wave my hands and say it's fine since the + and - section average to 0 anyway. Filtering this chopped signal and zooming into the noise floor, we get:\n\n![[Pasted image 20240701193547.png]]\n\nWhich sure does look an awful lot like mains. So I guess we have reached the noise floor of this particular environment.\n\n## Alternative to gating and filtering\n\nI got annoyed at the above gating because of the charge injection that I couldn't get rid of. I tried adding a complementary pmos and when that didn't work gave up. Instead, how about rectifying the signal? It would need to be amplified first but that's OK as my boards with a bunch of amplifiers came in.\n\nHere one is:\n\n### Amplifier\n![[Pasted image 20240702204618.png]]\n\nIt has a 10MHz gain bandwidth product (TP2311) so that looks about right.\n\n![[Pasted image 20240702212131.png]]\n\nhere is what the magnetometer looks like detecting a 1KHz sine wave:\n\n![[Pasted image 20240702212010.png]]\n\nThe magnetometer is being driven at 70kHz.\n\n### Bandpass filter\n\n![[Pasted image 20240702214700.png]]\n\n![[Pasted image 20240702214711.png]]\n\n...Not great.\n\n## Using magnetometer to sense 11kHz magnetic field.\n\nThis is starting to get a bit tricky. I angled the magnetometer such that it was not receiving much magnetic field. Then I strapped a coil to it, and excited the coil at 11kHz (to fit inside the above bandpass later).\n\nSetup:\n![[Pasted image 20240703082710.png]]\n\nThere are three states here in the FFT plot:\n1) No excitation, minimum magnetic field. This  resulted in a peak at basically only 50kHz\n2) No excitation, max magnetic field. Strong peaks at 100 and 200kHz appear in proportion to the strength of the field\n3) Exciting with external field. Base 11kHz modulation appears, but there is a much stronger peak at 100kHz +/- 11kHz. This is also in direct proportion to the volts going into the coil, and is also independent of the external magnetic field.\n![[Pasted image 20240703081957.png]]\n\nI had initially thought here that the strongest signal would show up at the base excitation freqency:\n![[Pasted image 20240703082409.png]]\n\nBut from the above FFT it appears that this is not actually the case. ","lastmodified":"2024-07-04T16:16:27.996231096Z","tags":null},"/index_base":{"title":"Harry dB notes","content":"\n# Topics\n## FM radio\n\n- [[20220301 fm - Loop the loop.md]]\n- [[20220319 fm -  We have a lock.md]]\n- [[20220322 - Look at that Bode.md]]\n- [[20220428 FM v2 bringup.md]]\n- [[20220529 positive phaseshift.md]]\n- [[20220617 XOR.md]]\n- [[20220701 Inductance measurements.md]]\n- [[20220710 Reference loop filter.md]]\n- [[20220711 Diff amp FET Follower.md]]\n- [[20220809 NAND is better than XOR.md]]\n\n## Blindar\n- [[20220816 Blindar.md]]\n- [[20220902_blindar_cancellation.md]]\n- [[20220918 I2S woes.md]]\n- [[20220923 blindar prototype notes.md]]\n- [[20221009 Lidar+imu.md]]\n\n## Misc\n- [[20220412 Advantech debugging.md]]\n- [[20220421 Cross polarized microscopy.md]]\n- [[20220825 microwave tesla coil.md]]\n- [[20220310 Fox hunt notes.md]]\n- [[20220402 mouse measurements.md]]\n\n## Full autogenerated list:\n\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/CJK-+-Latex-Support-%E6%B5%8B%E8%AF%95":{"title":"CJK + Latex Support ()","content":"\n## Chinese, Japanese, Korean Support\n\n\n      .\n\n\n\n## Latex\n\nBlock math works with two dollar signs `$$...$$`\n\n$$f(x) = \\int_{-\\infty}^\\infty\n    f\\hat(\\xi),e^{2 \\pi i \\xi x}\n    \\,d\\xi$$\n\t\nInline math also works with single dollar signs `$...$`. For example, Euler's identity but inline: $e^{i\\pi} = -1$\n\nAligned equations work quite well:\n\n$$\n\\begin{aligned}\na \u0026= b + c \\\\ \u0026= e + f \\\\\n\\end{aligned}\n$$\n\nAnd matrices\n\n$$\n\\begin{bmatrix}\n1 \u0026 2 \u0026 3 \\\\\na \u0026 b \u0026 c\n\\end{bmatrix}\n$$\n\n## RTL\nMore information on configuring RTL languages like Arabic in the [config](notes/config.md) page.\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/callouts":{"title":"Callouts","content":"\n## Callout support\n\nQuartz supports the same Admonition-callout syntax as Obsidian.\n\nThis includes\n- 12 Distinct callout types (each with several aliases)\n- Collapsable callouts\n\nSee [documentation on supported types and syntax here](https://help.obsidian.md/How+to/Use+callouts#Types).\n\n## Showcase\n\n\u003e [!EXAMPLE] Examples\n\u003e\n\u003e Aliases: example\n\n\u003e [!note] Notes\n\u003e\n\u003e Aliases: note\n\n\u003e [!abstract] Summaries \n\u003e\n\u003e Aliases: abstract, summary, tldr\n\n\u003e [!info] Info \n\u003e\n\u003e Aliases: info, todo\n\n\u003e [!tip] Hint \n\u003e\n\u003e Aliases: tip, hint, important\n\n\u003e [!success] Success \n\u003e\n\u003e Aliases: success, check, done\n\n\u003e [!question] Question \n\u003e\n\u003e Aliases: question, help, faq\n\n\u003e [!warning] Warning \n\u003e\n\u003e Aliases: warning, caution, attention\n\n\u003e [!failure] Failure \n\u003e\n\u003e Aliases: failure, fail, missing\n\n\u003e [!danger] Error\n\u003e\n\u003e Aliases: danger, error\n\n\u003e [!bug] Bug\n\u003e\n\u003e Aliases: bug\n\n\u003e [!quote] Quote\n\u003e\n\u003e Aliases: quote, cite\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/config":{"title":"Configuration","content":"\n## Configuration\nQuartz is designed to be extremely configurable. You can find the bulk of the configuration scattered throughout the repository depending on how in-depth you'd like to get.\n\nThe majority of configuration can be found under `data/config.yaml`. An annotated example configuration is shown below.\n\n```yaml {title=\"data/config.yaml\"}\n# The name to display in the footer\nname: Harry dB\n\n# whether to globally show the table of contents on each page\n# this can be turned off on a per-page basis by adding this to the\n# front-matter of that note\nenableToc: true\n\n# whether to by-default open or close the table of contents on each page\nopenToc: false\n\n# whether to display on-hover link preview cards\nenableLinkPreview: true\n\n# whether to render titles for code blocks\nenableCodeBlockTitle: true \n\n# whether to render copy buttons for code blocks\nenableCodeBlockCopy: true \n\n# whether to render callouts\nenableCallouts: true\n\n# whether to try to process Latex\nenableLatex: true\n\n# whether to enable single-page-app style rendering\n# this prevents flashes of unstyled content and improves\n# smoothness of Quartz. More info in issue #109 on GitHub\nenableSPA: true\n\n# whether to render a footer\nenableFooter: true\n\n# whether backlinks of pages should show the context in which\n# they were mentioned\nenableContextualBacklinks: true\n\n# whether to show a section of recent notes on the home page\nenableRecentNotes: false\n\n# whether to display an 'edit' button next to the last edited field\n# that links to github\nenableGitHubEdit: true\nGitHubLink: https://github.com/jackyzha0/quartz/tree/hugo/content\n\n# whether to use Operand to power semantic search\n# IMPORTANT: replace this API key with your own if you plan on using\n# Operand search!\nenableSemanticSearch: false\noperandApiKey: \"REPLACE-WITH-YOUR-OPERAND-API-KEY\"\n\n# page description used for SEO\ndescription:\n  Host your second brain and digital garden for free. Quartz features extremely fast full-text search,\n  Wikilink support, backlinks, local graph, tags, and link previews.\n\n# title of the home page (also for SEO)\npage_title:\n  \"Harry dB notes\"\n\n# links to show in the footer\nlinks:\n```\n\n### Code Block Titles\nTo add code block titles with Quartz:\n\n1. Ensure that code block titles are enabled in Quartz's configuration:\n\n    ```yaml {title=\"data/config.yaml\", linenos=false}\n    enableCodeBlockTitle: true\n    ```\n\n2. Add the `title` attribute to the desired [code block\n   fence](https://gohugo.io/content-management/syntax-highlighting/#highlighting-in-code-fences):\n\n      ```markdown {linenos=false}\n       ```yaml {title=\"data/config.yaml\"}\n       enableCodeBlockTitle: true  # example from step 1\n       ```\n      ```\n\n**Note** that if `{title=\u003cmy-title\u003e}` is included, and code block titles are not\nenabled, no errors will occur, and the title attribute will be ignored.\n\n### HTML Favicons\nIf you would like to customize the favicons of your Quartz-based website, you \ncan add them to the `data/config.yaml` file. The **default** without any set \n`favicon` key is:\n\n```html {title=\"layouts/partials/head.html\", linenostart=15}\n\u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n```\n\nThe default can be overridden by defining a value to the `favicon` key in your \n`data/config.yaml` file. For example, here is a `List[Dictionary]` example format, which is\nequivalent to the default:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon:\n  - { rel: \"shortcut icon\", href: \"icon.png\", type: \"image/png\" }\n#  - { ... } # Repeat for each additional favicon you want to add\n```\n\nIn this format, the keys are identical to their HTML representations.\n\nIf you plan to add multiple favicons generated by a website (see list below), it\nmay be easier to define it as HTML. Here is an example which appends the \n**Apple touch icon** to Quartz's default favicon:\n\n```yaml {title=\"data/config.yaml\", linenos=false}\nfavicon: |\n  \u003clink rel=\"shortcut icon\" href=\"icon.png\" type=\"image/png\"\u003e\n  \u003clink rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"\u003e\n```\n\nThis second favicon will now be used as a web page icon when someone adds your \nwebpage to the home screen of their Apple device. If you are interested in more \ninformation about the current and past standards of favicons, you can read \n[this article](https://www.emergeinteractive.com/insights/detail/the-essentials-of-favicons/).\n\n**Note** that all generated favicon paths, defined by the `href` \nattribute, are relative to the `static/` directory.\n\n### Graph View\nTo customize the Interactive Graph view, you can poke around `data/graphConfig.yaml`.\n\n```yaml {title=\"data/graphConfig.yaml\"}\n# if true, a Global Graph will be shown on home page with full width, no backlink.\n# A different set of Local Graphs will be shown on sub pages.\n# if false, Local Graph will be default on every page as usual\nenableGlobalGraph: false\n\n### Local Graph ###\nlocalGraph:\n    # whether automatically generate a legend\n    enableLegend: false\n    \n    # whether to allow dragging nodes in the graph\n    enableDrag: true\n    \n    # whether to allow zooming and panning the graph\n    enableZoom: true\n    \n    # how many neighbours of the current node to show (-1 is all nodes)\n    depth: 1\n    \n    # initial zoom factor of the graph\n    scale: 1.2\n    \n    # how strongly nodes should repel each other\n    repelForce: 2\n\n    # how strongly should nodes be attracted to the center of gravity\n    centerForce: 1\n\n    # what the default link length should be\n    linkDistance: 1\n    \n    # how big the node labels should be\n    fontSize: 0.6\n    \n    # scale at which to start fading the labes on nodes\n    opacityScale: 3\n\n### Global Graph ###\nglobalGraph:\n\t# same settings as above\n\n### For all graphs ###\n# colour specific nodes path off of their path\npaths:\n  - /moc: \"#4388cc\"\n```\n\n\n## Styling\nWant to go even more in-depth? You can add custom CSS styling and change existing colours through editing `assets/styles/custom.scss`. If you'd like to target specific parts of the site, you can add ids and classes to the HTML partials in `/layouts/partials`. \n\n### Partials\nPartials are what dictate what gets rendered to the page. Want to change how pages are styled and structured? You can edit the appropriate layout in `/layouts`.\n\nFor example, the structure of the home page can be edited through `/layouts/index.html`. To customize the footer, you can edit `/layouts/partials/footer.html`\n\nMore info about partials on [Hugo's website.](https://gohugo.io/templates/partials/)\n\nStill having problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n\n## Language Support\n[CJK + Latex Support ()](notes/CJK%20+%20Latex%20Support%20().md) comes out of the box with Quartz.\n\nWant to support languages that read from right-to-left (like Arabic)? Hugo (and by proxy, Quartz) supports this natively.\n\nFollow the steps [Hugo provides here](https://gohugo.io/content-management/multilingual/#configure-languages) and modify your `config.toml`\n\nFor example:\n\n```toml\ndefaultContentLanguage = 'ar'\n[languages]\n  [languages.ar]\n    languagedirection = 'rtl'\n    title = ''\n    weight = 1\n```\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/custom-Domain":{"title":"Custom Domain","content":"\n### Registrar\nThis step is only applicable if you are using a **custom domain**! If you are using a `\u003cYOUR-USERNAME\u003e.github.io` domain, you can skip this step.\n\nFor this last bit to take effect, you also need to create a CNAME record with the DNS provider you register your domain with (i.e. NameCheap, Google Domains).\n\nGitHub has some [documentation on this](https://docs.github.com/en/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site), but the tldr; is to\n\n1. Go to your forked repository (`github.com/\u003cYOUR-GITHUB-USERNAME\u003e/quartz`) settings page and go to the Pages tab. Under \"Custom domain\", type your custom domain, then click **Save**.\n2. Go to your DNS Provider and create a CNAME record that points from your domain to `\u003cYOUR-GITHUB-USERNAME.github.io.` (yes, with the trailing period).\n\n\t![Example Configuration for Quartz](/notes/images/google-domains.png)*Example Configuration for Quartz*\n3. Wait 30 minutes to an hour for the network changes to kick in.\n4. Done!","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/editing":{"title":"Editing Content in Quartz","content":"\n## Editing \nQuartz runs on top of [Hugo](https://gohugo.io/) so all notes are written in [Markdown](https://www.markdownguide.org/getting-started/).\n\n### Folder Structure\nHere's a rough overview of what's what.\n\n**All content in your garden can found in the `/content` folder.** To make edits, you can open any of the files and make changes directly and save it. You can organize content into any folder you'd like.\n\n**To edit the main home page, open `/content/_index.md`.**\n\nTo create a link between notes in your garden, just create a normal link using Markdown pointing to the document in question. Please note that **all links should be relative to the root `/content` path**. \n\n```markdown\nFor example, I want to link this current document to `notes/config.md`.\n[A link to the config page](notes/config.md)\n```\n\nSimilarly, you can put local images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\nYou can also use wikilinks if that is what you are more comfortable with!\n\n### Front Matter\nHugo is picky when it comes to metadata for files. Make sure that your title is double-quoted and that you have a title defined at the top of your file like so. You can also add tags here as well.\n\n```yaml\n---\ntitle: \"Example Title\"\ntags:\n- example-tag\n---\n\nRest of your content here...\n```\n\n### Obsidian\nI recommend using [Obsidian](http://obsidian.md/) as a way to edit and grow your digital garden. It comes with a really nice editor and graphical interface to preview all of your local files.\n\nThis step is **highly recommended**.\n\n\u003e  Step 3: [How to setup your Obsidian Vault to work with Quartz](notes/obsidian.md)\n\n## Previewing Changes\nThis step is purely optional and mostly for those who want to see the published version of their digital garden locally before opening it up to the internet. This is *highly recommended* but not required.\n\n\u003e  Step 4: [Preview Quartz Changes](notes/preview%20changes.md)\n\nFor those who like to live life more on the edge, viewing the garden through Obsidian gets you pretty close to the real thing.\n\n## Publishing Changes\nNow that you know the basics of managing your digital garden using Quartz, you can publish it to the internet!\n\n\u003e  Step 5: [Hosting Quartz online!](notes/hosting.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/hosting":{"title":"Deploying Quartz to the Web","content":"\n## Hosting on GitHub Pages\nQuartz is designed to be effortless to deploy. If you forked and cloned Quartz directly from the repository, everything should already be good to go! Follow the steps below.\n\n### Enable GitHub Actions\nBy default, GitHub disables workflows from running automatically on Forked Repostories. Head to the 'Actions' tab of your forked repository and Enable Workflows to setup deploying your Quartz site!\n\n![Enable GitHub Actions](notes/images/github-actions.png)*Enable GitHub Actions*\n\n### Enable GitHub Pages\n\nHead to the 'Settings' tab of your forked repository and go to the 'Pages' tab.\n\n1. (IMPORTANT) Set the source to deploy from `master` (and not `hugo`) using `/ (root)`\n2. Set a custom domain here if you have one!\n\n![Enable GitHub Pages](/notes/images/github-pages.png)*Enable GitHub Pages*\n\n### Pushing Changes\nTo see your changes on the internet, we need to push it them to GitHub. Quartz is a `git` repository so updating it is the same workflow as you would follow as if it were just a regular software project.\n\n```shell\n# Navigate to Quartz folder\ncd \u003cpath-to-quartz\u003e\n\n# Commit all changes\ngit add .\ngit commit -m \"message describing changes\"\n\n# Push to GitHub to update site\ngit push origin hugo\n```\n\nNote: we specifically push to the `hugo` branch here. Our GitHub action automatically runs everytime a push to is detected to that branch and then updates the `master` branch for redeployment.\n\n### Setting up the Site\nNow let's get this site up and running. Never hosted a site before? No problem. Have a fancy custom domain you already own or want to subdomain your Quartz? That's easy too.\n\nHere, we take advantage of GitHub's free page hosting to deploy our site. Change `baseURL` in `/config.toml`. \n\nMake sure that your `baseURL` has a trailing `/`!\n\n[Reference `config.toml` here](https://github.com/jackyzha0/quartz/blob/hugo/config.toml)\n\n```toml\nbaseURL = \"https://\u003cYOUR-DOMAIN\u003e/\"\n```\n\nIf you are using this under a subdomain (e.g. `\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz`), include the trailing `/`. **You need to do this especially if you are using GitHub!**\n\n```toml\nbaseURL = \"https://\u003cYOUR-GITHUB-USERNAME\u003e.github.io/quartz/\"\n```\n\nChange `cname` in `/.github/workflows/deploy.yaml`. Again, if you don't have a custom domain to use, you can use `\u003cYOUR-USERNAME\u003e.github.io`.\n\nPlease note that the `cname` field should *not* have any path `e.g. end with /quartz` or have a trailing `/`.\n\n[Reference `deploy.yaml` here](https://github.com/jackyzha0/quartz/blob/hugo/.github/workflows/deploy.yaml)\n\n```yaml {title=\".github/workflows/deploy.yaml\"}\n- name: Deploy  \n  uses: peaceiris/actions-gh-pages@v3  \n  with:  \n\tgithub_token: ${{ secrets.GITHUB_TOKEN }} # this can stay as is, GitHub fills this in for us!\n\tpublish_dir: ./public  \n\tpublish_branch: master\n\tcname: \u003cYOUR-DOMAIN\u003e\n```\n\nHave a custom domain? [Learn how to set it up with Quartz ](notes/custom%20Domain.md).\n\n### Ignoring Files\nOnly want to publish a subset of all of your notes? Don't worry, Quartz makes this a simple two-step process.\n\n [Excluding pages from being published](notes/ignore%20notes.md)\n\n---\n\nNow that your Quartz is live, let's figure out how to make Quartz really *yours*!\n\n\u003e Step 6:  [Customizing Quartz](notes/config.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/ignore-notes":{"title":"Ignoring Notes","content":"\n### Quartz Ignore\nEdit `ignoreFiles` in `config.toml` to include paths you'd like to exclude from being rendered.\n\n```toml\n...\nignoreFiles = [  \n    \"/content/templates/*\",  \n    \"/content/private/*\", \n    \"\u003cyour path here\u003e\"\n]\n```\n\n`ignoreFiles` supports the use of Regular Expressions (RegEx) so you can ignore patterns as well (e.g. ignoring all `.png`s by doing `\\\\.png$`).\nTo ignore a specific file, you can also add the tag `draft: true` to the frontmatter of a note.\n\n```markdown\n---\ntitle: Some Private Note\ndraft: true\n---\n...\n```\n\nMore details in [Hugo's documentation](https://gohugo.io/getting-started/configuration/#ignore-content-and-data-files-when-rendering).\n\n### Global Ignore\nHowever, just adding to the `ignoreFiles` will only prevent the page from being access through Quartz. If you want to prevent the file from being pushed to GitHub (for example if you have a public repository), you need to also add the path to the `.gitignore` file at the root of the repository.","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/obsidian":{"title":"Obsidian Vault Integration","content":"\n## Setup\nObsidian is the preferred way to use Quartz. You can either create a new Obsidian Vault or link one that your already have.\n\n### New Vault\nIf you don't have an existing Vault, [download Obsidian](https://obsidian.md/) and create a new Vault in the `/content` folder that you created and cloned during the [setup](notes/setup.md) step.\n\n### Linking an existing Vault\nThe easiest way to use an existing Vault is to copy all of your files (directory and hierarchies intact) into the `/content` folder.\n\n## Settings\nGreat, now that you have your Obsidian linked to your Quartz, let's fix some settings so that they play well.\n\n1. Under Options \u003e Files and Links, set the New link format to always use Absolute Path in Vault.\n2. Go to Settings \u003e Files \u0026 Links \u003e Turn \"on\" automatically update internal links.\n\n![Obsidian Settings](/notes/images/obsidian-settings.png)*Obsidian Settings*\n\n## Templates\nInserting front matter everytime you want to create a new Note gets annoying really quickly. Luckily, Obsidian supports templates which makes inserting new content really easily.\n\n**If you decide to overwrite the `/content` folder completely, don't remove the `/content/templates` folder!**\n\nHead over to Options \u003e Core Plugins and enable the Templates plugin. Then go to Options \u003e Hotkeys and set a hotkey for 'Insert Template' (I recommend `[cmd]+T`). That way, when you create a new note, you can just press the hotkey for a new template and be ready to go!\n\n\u003e  Step 4: [Preview Quartz Changes](notes/preview%20changes.md)","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/philosophy":{"title":"Quartz Philosophy","content":"\n\u003e [One] who works with the door open gets all kinds of interruptions, but [they] also occasionally gets clues as to what the world is and what might be important.  Richard Hamming\n\n## Why Quartz?\nHosting a public digital garden isn't easy. There are an overwhelming number of tutorials, resources, and guides for tools like [Notion](https://www.notion.so/), [Roam](https://roamresearch.com/), and [Obsidian](https://obsidian.md/), yet none of them have super easy to use *free* tools to publish that garden to the world.\n\nI've personally found that\n1. It's nice to access notes from anywhere\n2. Having a public digital garden invites open conversations\n3. It makes keeping personal notes and knowledge *playful and fun*\n\nI was really inspired by [Bianca](https://garden.bianca.digital/) and [Joel](https://joelhooks.com/digital-garden)'s digital gardens and wanted to try making my own.\n\n**The goal of Quartz is to make hosting your own public digital garden free and simple.** You don't even need your own website. Quartz does all of that for you and gives your own little corner of the internet.\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/preview-changes":{"title":"Preview Changes","content":"\nIf you'd like to preview what your Quartz site looks like before deploying it to the internet, here's exactly how to do that!\n\nNote that both of these steps need to be completed.\n\n## Install `hugo-obsidian`\nThis step will generate the list of backlinks for Hugo to parse. Ensure you have [Go](https://golang.org/doc/install) (\u003e= 1.16) installed.\n\n```bash\n# Install and link `hugo-obsidian` locally\ngo install github.com/jackyzha0/hugo-obsidian@latest\n```\n\nIf you are running into an error saying that `command not found: hugo-obsidian`, make sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize hugo-obsidian as an executable.\n\nAfterwards, start the Hugo server as shown above and your local backlinks and interactive graph should be populated!\n\n##  Installing Hugo\nHugo is the static site generator that powers Quartz. [Install Hugo with \"extended\" Sass/SCSS version](https://gohugo.io/getting-started/installing/) first. Then,\n\n```bash\n# Navigate to your local Quartz folder\ncd \u003clocation-of-your-local-quartz\u003e\n\n# Start local server\nmake serve\n\n# View your site in a browser at http://localhost:1313/\n```\n\n\u003e  Step 5: [Hosting Quartz online!](notes/hosting.md)","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/search":{"title":"Search","content":"\nQuartz supports two modes of searching through content.\n\n## Full-text\nFull-text search is the default in Quartz. It produces results that *exactly* match the search query. This is easier to setup but usually produces lower quality matches.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: false\n```\n\n## Natural Language\nNatural language search is powered by [Operand](https://operand.ai/). It understands language like a person does and finds results that best match user intent. In this sense, it is closer to how Google Search works.\n\nNatural language search tends to produce higher quality results than full-text search.\n\nHere's how to set it up.\n\n1. Create an Operand Account on [their website](https://operand.ai/).\n2. Go to Dashboard \u003e Settings \u003e Integrations.\n3. Follow the steps to setup the GitHub integration. Operand needs access to GitHub in order to index your digital garden properly!\n4. Head over to Dashboard \u003e Objects and press `(Cmd + K)` to open the omnibar and select 'Create Collection'.\n\t1. Set the 'Collection Label' to something that will help you remember it.\n\t2. You can leave the 'Parent Collection' field empty.\n5. Click into your newly made Collection.\n\t1. Press the 'share' button that looks like three dots connected by lines.\n\t2. Set the 'Interface Type' to `object-search` and click 'Create'.\n\t3. This will bring you to a new page with a search bar. Ignore this for now.\n6. Go back to Dashboard \u003e Settings \u003e API Keys and find your Quartz-specific Operand API key under 'Other keys'.\n\t1. Copy the key (which looks something like `0e733a7f-9b9c-48c6-9691-b54fa1c8b910`).\n\t2. Open `data/config.yaml`. Set `enableSemanticSearch` to `true` and `operandApiKey` to your copied key.\n\n```yaml {title=\"data/config.yaml\"}\n# the default option\nenableSemanticSearch: true\noperandApiKey: \"0e733a7f-9b9c-48c6-9691-b54fa1c8b910\"\n```\n7. Make a commit and push your changes to GitHub. See the [[notes/hosting|hosting]] page if you haven't done this already.\n\t1. This step is *required* for Operand to be able to properly index your content. \n\t2. Head over to Dashboard \u003e Objects and select the collection that you made earlier\n8. Press `(Cmd + K)` to open the omnibar again and select 'Create GitHub Repo'\n\t1. Set the 'Repository Label' to `Quartz`\n\t2. Set the 'Repository Owner' to your GitHub username\n\t3. Set the 'Repository Ref' to `master`\n\t4. Set the 'Repository Name' to the name of your repository (usually just `quartz` if you forked the repository without changing the name)\n\t5. Leave 'Root Path' and 'Root URL' empty\n9. Wait for your repository to index and enjoy natural language search in Quartz! Operand refreshes the index every 2h so all you need to do is just push to GitHub to update the contents in the search.","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/setup":{"title":"Setup","content":"\n## Making your own Quartz\nSetting up Quartz requires a basic understanding of `git`. If you are unfamiliar, [this resource](https://resources.nwplus.io/2-beginner/how-to-git-github.html) is a great place to start!\n\n### Forking\n\u003e A fork is a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.\n\nNavigate to the GitHub repository for the Quartz project:\n\n [Quartz Repository](https://github.com/jackyzha0/quartz)\n\nThen, Fork the repository into your own GitHub account. If you don't have an account, you can make on for free [here](https://github.com/join). More details about forking a repo can be found on [GitHub's documentation](https://docs.github.com/en/get-started/quickstart/fork-a-repo).\n\n### Cloning\nAfter you've made a fork of the repository, you need to download the files locally onto your machine. Ensure you have `git`, then type the following command replacing `YOUR-USERNAME` with your GitHub username.\n\n```shell\ngit clone https://github.com/YOUR-USERNAME/quartz\n```\n\n## Editing\nGreat! Now you have everything you need to start editing and growing your digital garden. If you're ready to start writing content already, check out the recommended flow for editing notes in Quartz.\n\n\u003e  Step 2: [Editing Notes in Quartz](notes/editing.md)\n\nHaving problems? Checkout our [FAQ and Troubleshooting guide](notes/troubleshooting.md).\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [Chloe's Garden](https://garden.chloeabrasada.online/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary ](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinter](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/troubleshooting":{"title":"Troubleshooting and FAQ","content":"\nStill having trouble? Here are a list of common questions and problems people encounter when installing Quartz.\n\nWhile you're here, join our [Discord](https://discord.gg/cRFFHYye7t) :)\n\n### Does Quartz have Latex support?\nYes! See [CJK + Latex Support ()](notes/CJK%20+%20Latex%20Support%20().md) for a brief demo.\n\n### Can I use \\\u003cObsidian Plugin\\\u003e in Quartz?\nUnless it produces direct Markdown output in the file, no. There currently is no way to bundle plugin code with Quartz.\n\nThe easiest way would be to add your own HTML partial that supports the functionality you are looking for.\n\n### My GitHub pages is just showing the README and not Quartz\nMake sure you set the source to deploy from `master` (and not `hugo`) using `/ (root)`! See more in the [hosting](/notes/hosting) guide\n\n### Some of my pages have 'January 1, 0001' as the last modified date\nThis is a problem caused by `git` treating files as case-insensitive by default and some of your posts probably have capitalized file names. You can turn this off in your Quartz by running this command.\n\n```shell\n# in the root of your Quartz (same folder as config.toml)\ngit config core.ignorecase true\n\n# or globally (not recommended)\ngit config --global core.ignorecase true\n```\n\n### Can I publish only a subset of my pages?\nYes! Quartz makes selective publishing really easy. Heres a guide on [excluding pages from being published](notes/ignore%20notes.md).\n\n### Can I host this myself and not on GitHub Pages?\nYes! All built files can be found under `/public` in the `master` branch. More details under [hosting](notes/hosting.md).\n\n### `command not found: hugo-obsidian`\nMake sure you set your `GOPATH` correctly! This will allow your terminal to correctly recognize `hugo-obsidian` as an executable.\n\n```shell\n# Add the following 2 lines to your ~/.bash_profile\nexport GOPATH=/Users/$USER/go\nexport PATH=$GOPATH/bin:$PATH\n\n# In your current terminal, to reload the session\nsource ~/.bash_profile\n```\n\n### How come my notes aren't being rendered?\nYou probably forgot to include front matter in your Markdown files. You can either setup [Obsidian](notes/obsidian.md) to do this for you or you need to manually define it. More details in [the 'how to edit' guide](notes/editing.md).\n\n### My custom domain isn't working!\nWalk through the steps in [the hosting guide](notes/hosting.md) again. Make sure you wait 30 min to 1 hour for changes to take effect.\n\n### How do I setup Google Analytics?\nYou can edit it in `config.toml` and either use a V3 (UA-) or V4 (G-) tag.\n\n### How do I change the content on the home page?\nTo edit the main home page, open `/content/_index.md`.\n\n### How do I change the colours?\nYou can change the theme by editing `assets/custom.scss`. More details on customization and themeing can be found in the [customization guide](notes/config.md).\n\n### How do I add images?\nYou can put images anywhere in the `/content` folder.\n\n```markdown\nExample image (source is in content/notes/images/example.png)\n![Example Image](/content/notes/images/example.png)\n```\n\n### My Interactive Graph and Backlinks aren't up to date\nBy default, the `linkIndex.json` (which Quartz needs to generate the Interactive Graph and Backlinks) are not regenerated locally. To set that up, see the guide on [local editing](notes/editing.md)\n\n### Can I use React/Vue/some other framework?\nNot out of the box. You could probably make it work by editing `/layouts/_default/single.html` but that's not what Quartz is designed to work with. 99% of things you are trying to do with those frameworks you can accomplish perfectly fine using just vanilla HTML/CSS/JS.\n\n## Still Stuck?\nQuartz isn't perfect! If you're still having troubles, file an issue in the GitHub repo with as much information as you can reasonably provide. Alternatively, you can message me on [Twitter](https://twitter.com/_jzhao) and I'll try to get back to you as soon as I can.\n\n [Submit an Issue](https://github.com/jackyzha0/quartz/issues)","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null},"/notes/updating":{"title":"Updating","content":"\nHaven't updated Quartz in a while and want all the cool new optimizations? On Unix/Mac systems you can run the following command for a one-line update! This command will show you a log summary of all commits since you last updated, press `q` to acknowledge this. Then, it will show you each change in turn and press `y` to accept the patch or `n` to reject it. Usually you should press `y` for most of these unless it conflicts with existing changes you've made! \n\n```shell\nmake update\n```\n\nOr, if you don't want the interactive parts and just want to force update your local garden (this assumed that you are okay with some of your personalizations been overriden!)\n\n```shell\nmake update-force\n```\n\nOr, manually checkout the changes yourself.\n\n\u003e [!warning] Warning!\n\u003e\n\u003e If you customized the files in `data/`, or anything inside `layouts/`, your customization may be overwritten!\n\u003e Make sure you have a copy of these changes if you don't want to lose them.\n\n\n```shell\n# add Quartz as a remote host\ngit remote add upstream git@github.com:jackyzha0/quartz.git\n\n# index and fetch changes\ngit fetch upstream\ngit checkout -p upstream/hugo -- layouts .github Makefile assets/js assets/styles/base.scss assets/styles/darkmode.scss config.toml data \n```\n","lastmodified":"2024-07-04T16:16:28.644231399Z","tags":null}}