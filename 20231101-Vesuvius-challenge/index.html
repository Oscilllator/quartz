<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="I am faffing about with the vesuvius challenge. At the moment this has been limited to getting chatGPT to generate me my very first autoencoder, which is a simple 3d convolutional model:"><title>Harry dB notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://Oscilllator.github.io/quartz//icon.png><link href=https://Oscilllator.github.io/quartz/styles.708c2658f93e3a9d323a1f9fded8f4b2.min.css rel=stylesheet><link href=https://Oscilllator.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://Oscilllator.github.io/quartz/js/darkmode.9b46d81b9b161bfac149d66dfa6b3812.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://Oscilllator.github.io/quartz/js/popover.9b72b70bd35617d0635e9d15463662b2.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://Oscilllator.github.io/quartz/",fetchData=Promise.all([fetch("https://Oscilllator.github.io/quartz/indices/linkIndex.53fe61487b8ecb243a9e2ef7e4ff546d.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://Oscilllator.github.io/quartz/indices/contentIndex.0e4f36f72df90c58396f727dca6095e0.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://Oscilllator.github.io/quartz",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://Oscilllator.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/Oscilllator.github.io\/quartz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://Oscilllator.github.io/quartz/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://Oscilllator.github.io/quartz/>Harry dB notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/20231101%20Vesuvius%20challenge.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#effects-of-residual-layers>Effects of residual layers:</a></li><li><a href=#overfitting>Overfitting</a></li><li><a href=#training-on-ink-initial-results>Training on ink: initial results</a></li><li><a href=#attempt-at-a-proper-run>Attempt at a proper run</a><ol><li><a href=#results-after-a-few-hours-training>Results after a few hours training</a></li></ol></li><li><a href=#attempt-at-training-on-ground-truth-overnight>Attempt at training on ground truth overnight:</a></li><li><a href=#heading>???</a></li><li><a href=#batch-size>Batch size</a></li><li><a href=#experiment-learning-rate>Experiment: learning rate</a></li><li><a href=#distribution>Distribution</a></li></ol></nav></details></aside><p>I am faffing about with the vesuvius challenge. At the moment this has been limited to getting chatGPT to generate me my very first autoencoder, which is a simple 3d convolutional model:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Autoencoder</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>cube_size</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Autoencoder</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cube_size</span> <span class=o>=</span> <span class=n>cube_size</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Encoder</span>
</span></span><span class=line><span class=cl>        <span class=n>layers</span> <span class=o>=</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl>        <span class=n>expansion_init</span> <span class=o>=</span> <span class=mi>32</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>expansion_init</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>           <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=n>expansion_init</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=n>i</span><span class=p>,</span> <span class=n>expansion_init</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>final_expansion</span> <span class=o>=</span> <span class=n>expansion_init</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=n>layers</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pool</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool3d</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span> <span class=o>=</span> <span class=n>cube_size</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>layers</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>final_channels</span> <span class=o>=</span> <span class=n>cube_size</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=n>layers</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>final_paramcount</span> <span class=o>=</span> <span class=n>cube_size</span><span class=o>**</span><span class=mi>3</span> <span class=o>//</span> <span class=p>(</span><span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>layers</span><span class=o>+</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Final dimensionality before latent space will be </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>final_channels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>latent_size</span> <span class=o>=</span> <span class=mi>512</span>
</span></span><span class=line><span class=cl>        <span class=c1># Latent vectors mu and logvar</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>final_paramcount</span><span class=p>,</span> <span class=n>latent_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>final_paramcount</span><span class=p>,</span> <span class=n>latent_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Decoder</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dec1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>latent_size</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_paramcount</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decs</span>  <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>           <span class=bp>self</span><span class=o>.</span><span class=n>decs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>ConvTranspose3d</span><span class=p>(</span><span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=n>i</span><span class=p>,</span> <span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>),</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>ConvTranspose3d</span><span class=p>(</span><span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=n>layers</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>reparameterize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>std</span> <span class=o>=</span> <span class=n>logvar</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span><span class=o>.</span><span class=n>exp_</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>eps</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=o>*</span><span class=n>mu</span><span class=o>.</span><span class=n>size</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>mu</span> <span class=o>+</span> <span class=n>std</span> <span class=o>*</span> <span class=n>eps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>enc</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>enc</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pool</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mu</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logvar</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>z</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dec1</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>z</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_channels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>final_side_len</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>d1</span><span class=p>,</span> <span class=n>d2</span><span class=p>,</span> <span class=n>d3</span><span class=p>,</span> <span class=n>d4</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decs</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>d1</span><span class=p>(</span><span class=n>z</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>d2</span><span class=p>(</span><span class=n>z</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>d3</span><span class=p>(</span><span class=n>z</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>d4</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>z</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reparameterize</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>decoded</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>decoded</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span>
</span></span><span class=line><span class=cl>        <span class=c1># return self.decode(z), mu, logvar</span>
</span></span></code></pre></td></tr></table></div></div><p>^^That&rsquo;s the slightly upgraded variational version. What I have done is tr y to get it to reconstruct arbitrary 32**3 cubes of the scroll, picked from a &lsquo;safe&rsquo; middle region:
<img src="/quartz/Pasted image 20231109080424.png" width=auto>
In the future if I ever get anywhere with this I can do proper masking of where the scroll actually is.
Here is what the results look like:
<img src="/quartz/Pasted image 20231109080524.png" width=auto>
which seems pretty reasonable to me, considering it was reconstructed from 512 parameters.</p><a href=#estimating-the-ground-truth><h1 id=estimating-the-ground-truth><span class=hanchor arialabel=Anchor># </span>Estimating the ground truth:</h1></a><p>This did not go very well. I adjusted the last output layer of the 3d convolutional kernel so that it output 2 channels rather than 3. The net then output this after a night of training:</p><p><img src="/quartz/Pasted image 20231109080312.png" width=auto>
&mldr; it appears that everything that is scroll is white and everything that is ground truth is black. The ol&rsquo; &ldquo;here&rsquo;s the mean of your dataset&rdquo; trick. There&rsquo;s no real proper reason why it is that I should be training on the reconstruction as well as the ground truth though, so if I just drop that hopefully that will make it better at training on the ground truth.</p><p>I have also added a bit of code that trains on patches that at the edge of ink and no ink, so it doesn&rsquo;t bias too much towards &rsquo;no ink&rsquo; since that&rsquo;s most of the dataset:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_first_gt_x</span><span class=p>(</span><span class=n>out_vol</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>,</span> <span class=n>out_gt</span><span class=p>:</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>,</span> <span class=n>path</span><span class=o>=</span><span class=n>GT1_PATH</span><span class=p>,</span> <span class=n>edges</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>gc</span><span class=o>.</span><span class=n>collect</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=c1># out_vol is a N x 64 x 64 x 64 tensor, because the gt is 64 thick.</span>
</span></span><span class=line><span class=cl>  <span class=c1># out_gt is an N x 64  x 64 tensor from the gt image.</span>
</span></span><span class=line><span class=cl>  <span class=c1># n = out_vol.shape[0]</span>
</span></span><span class=line><span class=cl>  <span class=n>batch_sz</span><span class=p>,</span> <span class=n>d_sz</span><span class=p>,</span> <span class=n>w_sz</span><span class=p>,</span> <span class=n>h_sz</span> <span class=o>=</span> <span class=n>out_vol</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>start_y</span> <span class=o>=</span> <span class=mi>4600</span><span class=p>;</span> <span class=n>start_x</span> <span class=o>=</span> <span class=mi>5800</span>
</span></span><span class=line><span class=cl>  <span class=n>end_y</span> <span class=o>=</span> <span class=mi>7000</span><span class=p>;</span>   <span class=n>end_x</span> <span class=o>=</span> <span class=mi>9300</span>
</span></span><span class=line><span class=cl>  <span class=k>assert</span><span class=p>(</span><span class=n>out_vol</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>==</span> <span class=n>out_gt</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=s1>&#39;inklabels.png&#39;</span><span class=p>))</span> <span class=k>as</span> <span class=n>img</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>gt</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>gt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>gt</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>size</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>gt</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;loaded gt of shape </span><span class=si>{</span><span class=n>gt</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>x_out</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>start_x</span><span class=p>,</span> <span class=n>end_x</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_sz</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>  <span class=n>y_out</span>  <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>start_y</span><span class=p>,</span> <span class=n>end_y</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_sz</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>edges</span><span class=p>:</span>  <span class=c1># Only train on stuff with a bit of 0 and a bit of 1</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>set_default_device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>no_edges</span> <span class=o>=</span> <span class=n>gt</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=c1># mask off the edge of the image so we don&#39;t index beyond it.</span>
</span></span><span class=line><span class=cl>    <span class=n>no_edges</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=n>w_sz</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>no_edges</span><span class=p>[</span><span class=o>-</span><span class=n>w_sz</span> <span class=o>//</span> <span class=mi>2</span><span class=p>:,</span> <span class=p>:]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>no_edges</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>:</span><span class=n>h_sz</span> <span class=o>//</span> <span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>no_edges</span><span class=p>[:,</span> <span class=o>-</span><span class=n>h_sz</span> <span class=o>//</span> <span class=mi>2</span><span class=p>:]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=n>edge_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>diff</span><span class=p>(</span><span class=n>gt</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>append</span><span class=o>=</span><span class=n>gt</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>edge_y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>diff</span><span class=p>(</span><span class=n>gt</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>append</span><span class=o>=</span><span class=n>gt</span><span class=p>[:,</span> <span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>edge</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>logical_or</span><span class=p>(</span><span class=n>edge_x</span><span class=p>,</span> <span class=n>edge_y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>edge_locs</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argwhere</span><span class=p>(</span><span class=n>edge</span><span class=p>)</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>n_edges</span> <span class=o>=</span> <span class=n>edge_locs</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>chosen_indices</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>n_edges</span><span class=p>,</span> <span class=p>(</span><span class=n>batch_sz</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>    <span class=n>chosen_corners</span> <span class=o>=</span> <span class=n>edge_locs</span><span class=p>[</span><span class=n>chosen_indices</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>x_out</span> <span class=o>=</span> <span class=n>chosen_corners</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=n>w_sz</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=n>y_out</span> <span class=o>=</span> <span class=n>chosen_corners</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=n>h_sz</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>b_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>batch_sz</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>out_gt</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>gt</span><span class=p>[</span><span class=n>x_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]:</span><span class=n>x_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]</span><span class=o>+</span><span class=n>w_sz</span><span class=p>,</span> <span class=n>y_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]:</span><span class=n>y_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]</span><span class=o>+</span><span class=n>h_sz</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>z_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>d_sz</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>layer</span> <span class=o>=</span> <span class=n>load_tif_cached</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;surface_volume/</span><span class=si>{</span><span class=n>z_idx</span><span class=si>:</span><span class=s2>02d</span><span class=si>}</span><span class=s2>.tif&#34;</span><span class=p>),</span> <span class=n>size</span><span class=o>.</span><span class=n>tolist</span><span class=p>(),</span> <span class=n>check</span><span class=o>=</span><span class=n>z_idx</span><span class=o>==</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>b_idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>batch_sz</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>out_vol</span><span class=p>[</span><span class=n>b_idx</span><span class=p>,</span> <span class=n>z_idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>layer</span><span class=p>[</span><span class=n>x_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]:</span><span class=n>x_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]</span><span class=o>+</span><span class=n>w_sz</span><span class=p>,</span> <span class=n>y_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]:</span><span class=n>y_out</span><span class=p>[</span><span class=n>b_idx</span><span class=p>]</span><span class=o>+</span><span class=n>h_sz</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;loaded layer </span><span class=si>{</span><span class=n>z_idx</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><a href=#effects-of-residual-layers><h2 id=effects-of-residual-layers><span class=hanchor arialabel=Anchor># </span>Effects of residual layers:</h2></a><p>The implementation of the residual layer courtesy of chatgpt as usual (it got the dims wrong though, also as usual):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ResidualBlock3d</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>conv_layer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>ResidualBlock3d</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Main path layers</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>conv_layer</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Shortcut path layer - always using 1x1 convolution</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>conv_layer</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>):</span>
</span></span><span class=line><span class=cl>          <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>conv_layer</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>conv_layer</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>residual</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>+=</span> <span class=n>residual</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>out</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>expansion_init</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>in_channels</span> <span class=o>=</span> <span class=n>expansion_init</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=n>i</span>
</span></span><span class=line><span class=cl>            <span class=n>out_channels</span> <span class=o>=</span> <span class=n>expansion_init</span> <span class=o>*</span> <span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># self.encs.append(nn.Conv3d(in_channels, out_channels, kernel_size=2, stride=2))</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>encs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>))</span>
</span></span><span class=line><span class=cl><span class=o>...</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decs</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>in_channels</span> <span class=o>=</span> <span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=n>i</span>
</span></span><span class=line><span class=cl>            <span class=n>out_channels</span> <span class=o>=</span>  <span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># either this:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>decs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>ConvTranspose3d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm3d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># or this</span>
</span></span><span class=line><span class=cl>            <span class=c1># self.decs.append(ResidualBlock3d(in_channels, out_channels, nn.ConvTranspose3d))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>ConvTranspose3d</span><span class=p>(</span><span class=n>final_expansion</span> <span class=o>//</span> <span class=mi>2</span><span class=o>**</span><span class=n>layers</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>Here is my net after training with 1000 iterations, no residual layers:</p><p><img src="/quartz/Pasted image 20231118181733.png" width=auto></p><p>And here is 1000 iterations with residual layers:
``
<img src="/quartz/Pasted image 20231118181259.png" width=auto></p><p>Yuuuuuge difference!! The net with no residuals looks like it has flatlined, but it actually hasn&rsquo;t. It seems to train about 10x slower is all.</p><a href=#overfitting><h2 id=overfitting><span class=hanchor arialabel=Anchor># </span>Overfitting</h2></a><p>I was training the net on 1000 examples, then reloading a new set of 1000 examples from the scroll every 1000 iterations. That leads to a loss curve that looks like this:</p><p><img src="/quartz/Pasted image 20231118183538.png" width=auto></p><p>When I change this to 10000 examples, I get a loss curve that looks like this:
<img src="/quartz/Pasted image 20231118183749.png" width=auto></p><p>so you can see that there is no overfitting already, but also the net has like 10x higher loss! it&rsquo;s about as high as when there were no residual layers! is this a coincidence?
Here is the net trained on a dataset size of 1e4, with no residual layers:</p><p><img src="/quartz/Pasted image 20231118184035.png" width=auto></p><p>&mldr;about the same as with a dataset size of 1e3 from <a href=/quartz/20231101-Vesuvius-challenge#effects-of-residual-layers rel=noopener class=internal-link data-src=/quartz/20231101-Vesuvius-challenge>before</a>. This makes me update rather strongly towards &ldquo;residual connections are great for overfitting&rdquo; and away from &ldquo;residual connections are good for avoiding exploding gradients&rdquo;.</p><a href=#training-on-ink-initial-results><h2 id=training-on-ink-initial-results><span class=hanchor arialabel=Anchor># </span>Training on ink: initial results</h2></a><p>Here is the result of simply switching the target volume from reconstructing the original to reconstructing the ground truth:</p><p><img src="/quartz/Pasted image 20231119083517.png" width=auto></p><p>Looks like it&rsquo;s doing a reasonable job of remembering the dataset just like before, although remembering the ink seems to be harder. Still though, it shows there is some correlation between what is desired on the input and what is desired on the output so that&rsquo;s nice.</p><p>When I leave this to train for an hour or so on parts of the dataset that contain only an edge it actually does quite well. But when I plot the results of this:</p><p><img src="/quartz/Pasted image 20231119135040.png" width=auto></p><p>&mldr;yeah, if all it sees is an edge, all it&rsquo;s gonna output is an edge.</p><p>One other thing I&rsquo;m running into here is loading times - significant parts of the training time are spent loading data. So speeding that up is a good next step I think.</p><a href=#attempt-at-a-proper-run><h2 id=attempt-at-a-proper-run><span class=hanchor arialabel=Anchor># </span>Attempt at a proper run</h2></a><p>I got rid of the code for training on only data around edges - I put that in because of the <a href=/quartz/20231101-Vesuvius-challenge#estimating-the-ground-truth rel=noopener class=internal-link data-src=/quartz/20231101-Vesuvius-challenge>garbage</a> that I got out before. Here is the loss curve for a true sampling of the input, attempting to reconstruct the output:
<img src="/quartz/Pasted image 20231119142023.png" width=auto></p><p>This too is exhibiting weird behaviors: big spikes, and this super long period of plateauing prior to the net &lsquo;picking up&rsquo; the gradient again.</p><a href=#results-after-a-few-hours-training><h3 id=results-after-a-few-hours-training><span class=hanchor arialabel=Anchor># </span>Results after a few hours training</h3></a><p>I did this over a couple of different restarts so I don&rsquo;t have a good screenshot of the loss over time, but here is the final result:</p><p><img src="/quartz/Pasted image 20231119201743.png" width=auto></p><p>&mldr;Looks pretty good to me!</p><p>Here is what it looks like zoomed in on some random blob:</p><p><img src="/quartz/Pasted image 20231119201834.png" width=auto></p><p>&mldr;so you can see that the boundaries of the model are clearly visible. Presumably this would be improve if a bunch of model outputs were averaged with different offsets. It might also be good to examine the loss as a function of the distance from the center of the cube - if there are edge effects it might be a good idea to discard them.</p><a href=#attempt-at-training-on-ground-truth-overnight><h2 id=attempt-at-training-on-ground-truth-overnight><span class=hanchor arialabel=Anchor># </span>Attempt at training on ground truth overnight:</h2></a><p><img src="/quartz/Pasted image 20231120071745.png" width=auto>
Looks like it plaeaued super quick there. This started with a learning rate of 3e-5 and went to 3e-7. it used the background thread data loading technique.</p><p>And here is what that same model looks like trying to guess where the ink is:</p><p><img src="/quartz/Pasted image 20231120072029.png" width=auto></p><p>oh well.</p><a href=#heading><h2 id=heading><span class=hanchor arialabel=Anchor># </span>???</h2></a><p>Having all these weird failures to train made me try to go back and replicate my previous successfull results. Here are the results of training overnight a 32 cube reconstruction:</p><p><img src="/quartz/Pasted image 20231203100924.png" width=auto></p><p>Pretty garbage. I wonder if this is because I had a learning rate schedule that started at 3e-4 and went down to 3e-6. So I will load this model where it stopped and try again with a constant rate of 3e-4.</p><p>And here is &lt;1 hour of training with a learning rate of 3e-4:
<img src="/quartz/Pasted image 20231203120948.png" width=auto></p><p>So I think that this means that the learning rate towards the end was indeed too small.</p><a href=#batch-size><h2 id=batch-size><span class=hanchor arialabel=Anchor># </span>Batch size</h2></a><p>I have been training with a batch size of 256, which is well below the max that will fit in my GPU. There are two reasons to increase batch size:</p><ul><li>Better utilisation of The GPU since the weights loaded from memory can be used many times</li><li>Better estimation of the gradient
The last one mostly seems bogus to me tbh, so I have not been putting effort into filling up the GPU. My intuition here was basically that the estimation of the gradient would go with sqrt (batch size), so instead of having a batch size of (say) 4, you should have a batch size of 1 and increment a small amount 4 times. IRL you still want a batch size &#187; 1 because of point 1 about GPU utilisation and so what I have been doing is increasing the batch size until <code>nvidia-smi</code> said that I was using as much power as I could.</li></ul><p>As a small and highly invalid experiment, here is me setting a breakpoint during training and setting the batch size from 256->1024.</p><p><img src="/quartz/Pasted image 20231203163621.png" width=auto></p><p>&mldr;it doesn&rsquo;t look like it is having much effect here. Remember in the same time that I do 1 batch-size-1024 iteration I can do 4 of the 256 variant. I&rsquo;ll keep the experiment running for a bit more just to see what happens though.
Given that there was no change in the learning rate from 256->1024 batch size, this clearly means we need to go lower!</p><p><img src="/quartz/Pasted image 20231203182743.png" width=auto></p><p>Above I ran with three different batch sizes. It kind of looks like the mean loss changed with the batch size (I don&rsquo;t know how that could be) but the learning rate didn&rsquo;t really.</p><a href=#experiment-learning-rate><h2 id=experiment-learning-rate><span class=hanchor arialabel=Anchor># </span>Experiment: learning rate</h2></a><p>Here is a learning rate of 3e-4 overnight:</p><p><img src="/quartz/Pasted image 20231205080143.png" width=auto>
Looks it like it just keeps learning! I was actually busy for a few days after this so let it run even longer, and the loss just kept on dropping. From the y axis you can see that the absolute level of improvement is not that great though.</p><a href=#distribution><h2 id=distribution><span class=hanchor arialabel=Anchor># </span>Distribution</h2></a><p>I haven&rsquo;t been normalising the input to my net. It occurs to me that this is a bad idea. here is a histogram of the density across the whole ground truth scroll (after converting from uint16 to float):
<img src="/quartz/Pasted image 20231206213717.png" width=auto>
honestly I think my instincts are right here and this is a pretty boring distribution that doesn&rsquo;t need anything done to it for a net to be able to understand it.</p><p>exp about classifying on frozen layers.
<img src="/quartz/Pasted image 20231207082844.png" width=auto></p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz// data-ctx="20231101 Vesuvius challenge.md" data-src=/ class=internal-link>Harry dB notes</a></li><li><a href=/quartz/20231101-Vesuvius-challenge/ data-ctx=garbage data-src=/20231101-Vesuvius-challenge class=internal-link></a></li><li><a href=/quartz/20231209-More-Vesuvius-challenge/ data-ctx=last data-src=/20231209-More-Vesuvius-challenge class=internal-link></a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://Oscilllator.github.io/quartz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Harry dB using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://Oscilllator.github.io/quartz/>Home</a></li></ul></footer></div></div></body></html>