<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Problem It would be good to stick a recorder in a forest to monitor bird calls. That way you could get population density estimates and so on and so forth."><title>Harry dB notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://Oscilllator.github.io/quartz//icon.png><link href=https://Oscilllator.github.io/quartz/styles.708c2658f93e3a9d323a1f9fded8f4b2.min.css rel=stylesheet><link href=https://Oscilllator.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://Oscilllator.github.io/quartz/js/darkmode.9b46d81b9b161bfac149d66dfa6b3812.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://Oscilllator.github.io/quartz/js/popover.9b72b70bd35617d0635e9d15463662b2.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://Oscilllator.github.io/quartz/",fetchData=Promise.all([fetch("https://Oscilllator.github.io/quartz/indices/linkIndex.c46d447fca4f33673a1e3ddc0953920e.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://Oscilllator.github.io/quartz/indices/contentIndex.8c9fad13856868267e14a98ea140794e.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://Oscilllator.github.io/quartz",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://Oscilllator.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/Oscilllator.github.io\/quartz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://Oscilllator.github.io/quartz/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://Oscilllator.github.io/quartz/>Harry dB notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/20230118%20Bird%20call%20identification.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#problem-splitting-recordings>Problem: splitting recordings</a><ol><li></li></ol></li><li><a href=#problem-crow_t--crow_t1->Problem: $crow_t == crow_{t+1}$ ??</a></li></ol><ol><li><a href=#simplest-case-first>Simplest case first</a><ol><li><a href=#how-many-birds>How many birds?</a></li></ol></li><li><a href=#more-assumptions>More assumptions</a></li></ol></nav></details></aside><a href=#problem><h1 id=problem><span class=hanchor arialabel=Anchor># </span>Problem</h1></a><p>It would be good to stick a recorder in a forest to monitor bird calls. That way you could get population density estimates and so on and so forth. There are
<a href=https://www.macaulaylibrary.org/2021/06/22/behind-the-scenes-of-sound-id-in-merlin/ rel=noopener>some existing</a> approaches that do this already but they all require labelled data, which is pretty sparse and of course limits you to stuff you have already seen.
The question is whether or not you can train a system to be able to identify bird calls <em>without</em> human labelled data. I think this might be possible.</p><a href=#idea-multiple-microphone-math><h1 id=idea-multiple-microphone-math><span class=hanchor arialabel=Anchor># </span>Idea: Multiple Microphone Math</h1></a><p>The overarching idea here is that by placing many microphones in a section of forest bird calls will be audible from multiple microphones and hence locatable in space and amplitude since the position of the microphones are known (think gps satellites in known locations solving for receivers in unknown locations).
This means that for a given call the microphones will receive bird call recordings that are a bit different in time, volume, and background noise. However as the organiser of this system we know that the bird call recordings belong to the same bird making the same call. So whilst we don&rsquo;t know necessarily what the bird is in these recordings, we do know that it is the same one.</p><p>Note that if there are fewer bird calls then there are microphones it&rsquo;s possible to solve uniquely for the location of the bird and extract the bird call itself from the other bird calls and background noise. This would help a great deal I think in creating clean recordings for training.
Once you have a large set of these clean recordings you can then easily simulate many bird calls at once by mixing your pristine recordings together to create a big synthetic bird chorous, and then train your net on this. Then you can go back to the real mucky bird chorouses and run the identification for real.
You&rsquo;ll need buckets of data for this I suspect, but that&rsquo;s exactly what a system like this is supposed to provide.</p><a href=#problem-splitting-recordings><h2 id=problem-splitting-recordings><span class=hanchor arialabel=Anchor># </span>Problem: splitting recordings</h2></a><p>What gets recorded will of course be N streams of audio from the N microphones. This needs to be split into discrete chunks around bird calls. Undoubtedly this will require piles and piles of disgusting heuristics but once again our multiple receivers will help here.
A proposal: find a loud identifiable bit of the recording via a simple threshold or something. With all the microphones you can then locate this recording in space <em>and create a synthetic microphone that listens only to that point in space</em>. This is very cool but also understandably makes it much easier to tell when the call started and stopped since it solves the problem of the end of one call overlapping with the start of another that you don&rsquo;t really have any way to solve with a single microphone.</p><a href=#20230703-note><h4 id=20230703-note><span class=hanchor arialabel=Anchor># </span>20230703 note</h4></a><p>Maybe what we want here is &ldquo;contrastive&rdquo; learning?</p><a href=#problem-crow_t--crow_t1-><h2 id=problem-crow_t--crow_t1-><span class=hanchor arialabel=Anchor># </span>Problem: $crow_t == crow_{t+1}$ ??</h2></a><p>The above notes show how to locate, separate and label a call that happens at a certain time by a certain bird. But it does not give insight as to how a bird that calls on two separate occasions gets labelled the same thing both times. I do not know how to solve this. I think that with a sufficient number of examples it&rsquo;s pretty likely that different occurrences of the same call will end up in similar places in the embedding space, so maybe a traditional clustering algorithm could be used?
This is I think the biggest flaw with this method, though. I&rsquo;m sure that there are many many examples of how to do this in the literature though since this problem is the same problem as identifying different pronounciations of the same word in a speech dataset, and there&rsquo;s loads of research one speech recognition.</p><a href=#more-maths><h1 id=more-maths><span class=hanchor arialabel=Anchor># </span>More maths</h1></a><a href=#simplest-case-first><h2 id=simplest-case-first><span class=hanchor arialabel=Anchor># </span>Simplest case first</h2></a><p>Let me try and get down some problem statements first. Consider the simplest scenario: there is a single bird that sends a single pulse of sound to a bunch of microphones.</p><p><img src="/quartz/Pasted image 20230119044226.png" width=auto>
Remembering that distance is the same as time here what we observe in this case is that microphone $M_1$ hears something, then $M_2$, then $M_3$. So the input to our system/our observation is $[0, d_1 - d_2, d_1 - d_3]$. Call the microphone array $M = [M_1&mldr;M_3]$. Since we know the positions in M I do believe we are one linear equation away for writing down the location of the bird $B$ which one can solve in a least squares fashion in numpy.
If you write down the matrices in the right way you can just keep adding more $M$ and $B$ provided that $M$ is sufficiently bigger than $B$. I&rsquo;m sure you could put down like 10 microphones in practice, so that&rsquo;s enough to get quite a few birdcalls.</p><a href=#how-many-birds><h3 id=how-many-birds><span class=hanchor arialabel=Anchor># </span>How many birds?</h3></a><p>The above is how to calculate where the birds are given how many of them exist, but not how many of them there are. I think you could do this iteratively by looking at how well the solution fits when you assume one bird, then two, then three etc. This will be greatly confused by bird calls with quite different volumes, and also by background noise.</p><a href=#more-assumptions><h2 id=more-assumptions><span class=hanchor arialabel=Anchor># </span>More assumptions</h2></a><ul><li>When a bird is far away it might be audible to only a subset of the microphones.</li><li>Do birds call whilst moving?</li><li>The positional accuracy here prolly won&rsquo;t be that great what with all the trees and stuff. So birds that are close together will cause problems.</li><li>Perhaps real recordings just have so many sources all the time that it&rsquo;s hard to get enough single-call data to train on.</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz// data-ctx="20230118 Bird call identification.md" data-src=/ class=internal-link>Harry dB notes</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://Oscilllator.github.io/quartz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Harry dB using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2024</p><ul><li><a href=https://Oscilllator.github.io/quartz/>Home</a></li></ul></footer></div></div></body></html>