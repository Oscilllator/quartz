<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="The [[20231101 Vesuvius challenge|last]] page was getting a little long so here is a new one.
The main problem with this whole challenge is the super low snr."><title>Harry dB notes</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://Oscilllator.github.io/quartz//icon.png><link href=https://Oscilllator.github.io/quartz/styles.708c2658f93e3a9d323a1f9fded8f4b2.min.css rel=stylesheet><link href=https://Oscilllator.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://Oscilllator.github.io/quartz/js/darkmode.9b46d81b9b161bfac149d66dfa6b3812.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/util.9825137f5e7825e8553c68ce39ac9e44.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script src=https://Oscilllator.github.io/quartz/js/popover.9b72b70bd35617d0635e9d15463662b2.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/code-title.b35124ad8db0ba37162b886afb711cbc.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/clipboard.c20857734e53a3fb733b7443879efa61.min.js></script>
<script src=https://Oscilllator.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const BASE_URL="https://Oscilllator.github.io/quartz/",fetchData=Promise.all([fetch("https://Oscilllator.github.io/quartz/indices/linkIndex.ec65c2069f89287a71292a94747798b2.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://Oscilllator.github.io/quartz/indices/contentIndex.444460d0484ed3d7ae90616fd158f99d.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://Oscilllator.github.io/quartz",!0,!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://Oscilllator.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/Oscilllator.github.io\/quartz\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://Oscilllator.github.io/quartz/js/full-text-search.24827f874defbbc6d529926cbfcfb493.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://Oscilllator.github.io/quartz/>Harry dB notes</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/20231209%20More%20Vesuvius%20challenge.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#new-experiment>New experiment:</a></li><li><a href=#20240115-augmentation>20240115 Augmentation</a></li></ol></nav></details></aside><p>The <a href=/quartz/20231101-Vesuvius-challenge rel=noopener class=internal-link data-src=/quartz/20231101-Vesuvius-challenge>last</a> page was getting a little long so here is a new one.</p><p>The main problem with this whole challenge is the super low snr. So far here has what I have done:</p><ul><li>Got an autoencoder (and VAE) to reconstruct the input for both the flattened papyrus with ground truth and the rolled up scroll.</li><li>Failed to train a net directly on the ground truth</li><li>Tried to do a bit of curriculum learning where the net first learned to classify the parts of the scroll where ink was and was not present first. I successfully overfit on those parts of the dataset but that&rsquo;s about it.</li></ul><a href=#new-experiment><h2 id=new-experiment><span class=hanchor arialabel=Anchor># </span>New experiment:</h2></a><p>Here&rsquo;s an idea: add the ground truth ink labels directly into the input of the net! That will make it really easy to train!
Indeed it does. Now what I shall do is lower the amount of ink that is added progressively as it trains, like so:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>assert</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>batch_vol</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>gt_expanded</span> <span class=o>=</span> <span class=n>batch_gt</span><span class=o>.</span><span class=n>reshape</span><span class=p>((</span><span class=n>batch_gt</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>,</span> <span class=n>batch_gt</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>batch_gt</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>gt_expanded</span> <span class=o>=</span> <span class=n>gt_expanded</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>batch_vol</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> 
</span></span><span class=line><span class=cl><span class=n>input_</span> <span class=o>=</span> <span class=n>gt_expanded</span> <span class=o>*</span> <span class=n>gt_mix_fraction</span> <span class=o>+</span> <span class=n>batch_vol</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>gt_mix_fraction</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>reconstructed</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>logvar</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>input_</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl>  <span class=o>...</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=n>loss_scroll</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()(</span><span class=n>reconstructed</span><span class=p>,</span> <span class=n>batch_vol</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=n>loss_gt</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MSELoss</span><span class=p>()(</span><span class=n>reconstructed</span><span class=p>,</span> <span class=n>gt_expanded</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=n>loss_scroll</span> <span class=o>/</span> <span class=n>loss_gt</span> <span class=o>&gt;</span> <span class=mi>5</span> <span class=ow>and</span> <span class=n>epoch</span> <span class=o>&gt;</span> <span class=mi>100</span> <span class=ow>and</span> <span class=n>gt_mix_fraction</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>	  <span class=n>gt_mix_fraction</span> <span class=o>*=</span> <span class=mf>0.8</span>
</span></span></code></pre></td></tr></table></div></div><p>This was inspired by how diffusion models are trained to remove noise. If you think of the scroll cube as &rsquo;noise&rsquo;, then maybe gradually swapping out the input ground truth for the scroll gradually over time is training the model to denoise things and not just a silly idea.</p><p>This seems to be working as desired in terms of training:</p><p><img src="/quartz/Pasted image 20231209114921.png" width=auto></p><p>it has gotten down to 0.03 mix fraction after only a few thousand iterations, although the actual output looks like hot garbage:</p><p><img src="/quartz/Pasted image 20231209115134.png" width=auto></p><p>So instead I switched it to decrease the mix fraction every time the loss got below a certain hardcoded number:</p><p><img src="/quartz/Pasted image 20231209155617.png" width=auto></p><p>This seems even more promising in that the adjustments are much further apart and are having a clear effect, but I don&rsquo;t know that the improvement on the actual task at hand (extracting ground truth) is any better. If I improved my tool or bothered to learn how the actual pytorch tooling worked I could add additional metrics to track over time, but as-is my spot checks for the loss against the original scroll input are that the curve isn&rsquo;t really bending much over time.</p><p>And here is the loss curve after training overnight:
<img src="/quartz/Pasted image 20231210073848.png" width=auto></p><p>The model is now successfully not using any of the ground truth at all. Super promising!!!</p><p>And here are the results of running inference across the whole scroll fragment:</p><p><img src="/quartz/Pasted image 20231210140913.png" width=auto></p><p>Zoomed in on the region where the training data was derived from:</p><p><img src="/quartz/Pasted image 20231210141254.png" width=auto></p><p>Despite being clearly incredibly overfit to the training data to the point of replicating every last imperfection, this is by far and away the most promising result so far!
perhaps by adding a smidge more of the actual scroll as training data + augmenting the inputs a lot the net will actually learn something.</p><a href=#20240115-augmentation><h2 id=20240115-augmentation><span class=hanchor arialabel=Anchor># </span>20240115 Augmentation</h2></a><p>I now trained the network on more or less the same thing, but augmented the dataset with rotations. The training looks like this:</p><p><img src="/quartz/Pasted image 20240115155042.png" width=auto></p><p>Where I trained it for about 16 hours with the automatically decaying ground truth fraction. The fraction got down to 0.03 whereapon I got bored and manually set it to 0. That resulted in the huge spike in the loss over on the right hand side there, so even at 0.03 the network was still clearly basically only looking at the ground truth.</p><p>The conclusion that I draw from this is that when trained without augmentation the training data for the model is small enough that it can be memorised, and when trained with augmentation it can&rsquo;t generalise to the underlying data.</p><p>To be super confident I think I should make some synthetic data with a &ldquo;scroll&rdquo; made out of noisy text to see if it can recover the original text.</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/quartz// data-ctx="20231209 More Vesuvius challenge.md" data-src=/ class=internal-link>Harry dB notes</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://Oscilllator.github.io/quartz/js/graph.abd4bc2af3869a96524d7d23b76152c7.js></script></div></div><div id=contact_buttons><footer><p>Made by Harry dB using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2024</p><ul><li><a href=https://Oscilllator.github.io/quartz/>Home</a></li></ul></footer></div></div></body></html>